From tmblue at gmail.com  Thu Jan  7 14:26:44 2016
From: tmblue at gmail.com (Tory M Blue)
Date: Thu, 7 Jan 2016 14:26:44 -0800
Subject: [Slony1-general] Slony-I: log switch to sl_log_2 still in progress
	- sl_log_1 not truncated
Message-ID: <CAEaSS0aCUuNmtsekJmG+fgt2EqgA5ArnPnn-Z3ZUT2kza6ixmw@mail.gmail.com>

So I'm backing up in a big way. I know what started it, "adding a new
insert slave which took 13 hours to complete (indexes etc)".. But now it
doesn't appear I am able to catch up. I see the slave doing what it's
suppose to, get a bunch of data, truncate the sl_log files move on. But the
master is having a hard time.

Postgres 9.4.5 and Slony 2.2.3

All other nodes don't have any errors or issues.

this is Node 1 (the master)
node 2 is a slave
node 3-5 are query slaves with only 1 of 3 sets being replicated too.

I have interval at 5 minutes and sync_group_maxsize=50

Any suggestions on where to thump it. At some point this will cause issues
on my master and when I see that starting, I'll have to drop node 2 again,
and when i add it, it will take 13+ hours and I'll be back in the same
position :)

Thanks
Tory



Node:  Old Transactions Kept Open
================================================
Old Transaction still running with age 01:48:00 > 01:30:00

Query: autovacuum: VACUUM


Node: 0 threads seem stuck
================================================
Slony-I components have not reported into sl_components in interval 00:05:00

Perhaps slon is not running properly?

Query:
     select co_actor, co_pid, co_node, co_connection_pid, co_activity,
co_starttime, now() - co_starttime, co_event, co_eventtype
     from "_admissioncls".sl_components
     where  (now() - co_starttime) > '00:05:00'::interval
     order by co_starttime;



Node: 1 sl_log_1 tuples = 219700 > 200000
================================================
Number of tuples in Slony-I table sl_log_1 is 219700 which
exceeds 200000.

You may wish to investigate whether or not a node is down, or perhaps
if sl_confirm entries have not been propagating properly.


Node: 1 sl_log_2 tuples = 1.74558e+07 > 200000
================================================
Number of tuples in Slony-I table sl_log_2 is 1.74558e+07 which
exceeds 200000.

You may wish to investigate whether or not a node is down, or perhaps
if sl_confirm entries have not been propagating properly.


Node: 2 sl_log_2 tuples = 440152 > 200000
================================================
Number of tuples in Slony-I table sl_log_2 is 440152 which
exceeds 200000.

You may wish to investigate whether or not a node is down, or perhaps
if sl_confirm entries have not been propagating properly.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20160107/677d8782/attachment.htm 

From steve at ssinger.info  Thu Jan  7 14:47:04 2016
From: steve at ssinger.info (Steve Singer)
Date: Thu, 7 Jan 2016 17:47:04 -0500 (EST)
Subject: [Slony1-general] Slony-I: log switch to sl_log_2 still in
 progress - sl_log_1 not truncated
In-Reply-To: <CAEaSS0aCUuNmtsekJmG+fgt2EqgA5ArnPnn-Z3ZUT2kza6ixmw@mail.gmail.com>
References: <CAEaSS0aCUuNmtsekJmG+fgt2EqgA5ArnPnn-Z3ZUT2kza6ixmw@mail.gmail.com>
Message-ID: <alpine.DEB.2.02.1601071743020.11931@mini.atlantida>

On Thu, 7 Jan 2016, Tory M Blue wrote:

> 
> So I'm backing up in a big way. I know what started it, "adding a new insert slave which took 13 hours to complete (indexes
> etc)".. But now it doesn't appear I am able to catch up. I see the slave doing what it's suppose to, get a bunch of data,
> truncate the sl_log files move on. But the master is having a hard time.
> 
> Postgres 9.4.5 and Slony 2.2.3
> 
> All other nodes don't have any errors or issues.
> 
> this is Node 1 (the master)
> node 2 is a slave
> node 3-5 are query slaves with only 1 of 3 sets being replicated too.
> 
> I have interval at 5 minutes and sync_group_maxsize=50
> 
> Any suggestions on where to thump it. At some point this will cause issues on my master and when I see that starting, I'll
> have to drop node 2 again, and when i add it, it will take 13+ hours and I'll be back in the same position :)

Bump sync_group_maxsize to be much bigger, I'm not saying that will solve 
the problem but it might help(max allowed is 10,000). I'm also suspect when 
you say your have a sync_interval of 5 minutes, since I thought 60 seconds was the largest 
allowed.



> 
> Thanks
> Tory
> 
> 
> 
> Node: ?Old Transactions Kept Open
> ================================================
> Old Transaction still running with age 01:48:00 > 01:30:00
> 
> Query: autovacuum: VACUUM
> 
> 
> Node: 0 threads seem stuck
> ================================================
> Slony-I components have not reported into sl_components in interval 00:05:00
> 
> Perhaps slon is not running properly?
> 
> Query:
> ? ? ?select co_actor, co_pid, co_node, co_connection_pid, co_activity, co_starttime, now() - co_starttime, co_event,
> co_eventtype
> ? ? ?from "_admissioncls".sl_components
> ? ? ?where ?(now() - co_starttime) > '00:05:00'::interval
> ? ? ?order by co_starttime;
> ??
> 
> 
> Node: 1 sl_log_1 tuples = 219700 > 200000
> ================================================
> Number of tuples in Slony-I table sl_log_1 is 219700 which
> exceeds 200000.
> 
> You may wish to investigate whether or not a node is down, or perhaps
> if sl_confirm entries have not been propagating properly.
> 
> 
> Node: 1 sl_log_2 tuples = 1.74558e+07 > 200000
> ================================================
> Number of tuples in Slony-I table sl_log_2 is 1.74558e+07 which
> exceeds 200000.
> 
> You may wish to investigate whether or not a node is down, or perhaps
> if sl_confirm entries have not been propagating properly.
> 
> 
> Node: 2 sl_log_2 tuples = 440152 > 200000
> ================================================
> Number of tuples in Slony-I table sl_log_2 is 440152 which
> exceeds 200000.
> 
> You may wish to investigate whether or not a node is down, or perhaps
> if sl_confirm entries have not been propagating properly.
> 
> 
>

From tmblue at gmail.com  Thu Jan  7 14:50:24 2016
From: tmblue at gmail.com (Tory M Blue)
Date: Thu, 7 Jan 2016 14:50:24 -0800
Subject: [Slony1-general] Slony-I: log switch to sl_log_2 still in
 progress - sl_log_1 not truncated
In-Reply-To: <alpine.DEB.2.02.1601071743020.11931@mini.atlantida>
References: <CAEaSS0aCUuNmtsekJmG+fgt2EqgA5ArnPnn-Z3ZUT2kza6ixmw@mail.gmail.com>
	<alpine.DEB.2.02.1601071743020.11931@mini.atlantida>
Message-ID: <CAEaSS0ZLoz8pofz9EySn7rZ+U1kXhor+0eNs-f7PF2t-SLvQkw@mail.gmail.com>

On Thu, Jan 7, 2016 at 2:47 PM, Steve Singer <steve at ssinger.info> wrote:

> On Thu, 7 Jan 2016, Tory M Blue wrote:
>
>
>> So I'm backing up in a big way. I know what started it, "adding a new
>> insert slave which took 13 hours to complete (indexes
>> etc)".. But now it doesn't appear I am able to catch up. I see the slave
>> doing what it's suppose to, get a bunch of data,
>> truncate the sl_log files move on. But the master is having a hard time.
>>
>> Postgres 9.4.5 and Slony 2.2.3
>>
>> All other nodes don't have any errors or issues.
>>
>> this is Node 1 (the master)
>> node 2 is a slave
>> node 3-5 are query slaves with only 1 of 3 sets being replicated too.
>>
>> I have interval at 5 minutes and sync_group_maxsize=50
>>
>> Any suggestions on where to thump it. At some point this will cause
>> issues on my master and when I see that starting, I'll
>> have to drop node 2 again, and when i add it, it will take 13+ hours and
>> I'll be back in the same position :)
>>
>
> Bump sync_group_maxsize to be much bigger, I'm not saying that will solve
> the problem but it might help(max allowed is 10,000). I'm also suspect when
> you say your have a sync_interval of 5 minutes, since I thought 60 seconds
> was the largest allowed.
>
> My apologies

cleanup_interval="5 minutes"

my interval is 1000ms
And sync, group cites 100 is the max

# Range:  [0,100], default: 6

sync_group_maxsize=50
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20160107/81014146/attachment.htm 

From steve at ssinger.info  Thu Jan  7 14:59:52 2016
From: steve at ssinger.info (Steve Singer)
Date: Thu, 7 Jan 2016 17:59:52 -0500 (EST)
Subject: [Slony1-general] Slony-I: log switch to sl_log_2 still in
 progress - sl_log_1 not truncated
In-Reply-To: <CAEaSS0ZLoz8pofz9EySn7rZ+U1kXhor+0eNs-f7PF2t-SLvQkw@mail.gmail.com>
References: <CAEaSS0aCUuNmtsekJmG+fgt2EqgA5ArnPnn-Z3ZUT2kza6ixmw@mail.gmail.com>
	<alpine.DEB.2.02.1601071743020.11931@mini.atlantida>
	<CAEaSS0ZLoz8pofz9EySn7rZ+U1kXhor+0eNs-f7PF2t-SLvQkw@mail.gmail.com>
Message-ID: <alpine.DEB.2.02.1601071754040.11931@mini.atlantida>

On Thu, 7 Jan 2016, Tory M Blue wrote:

>       Bump sync_group_maxsize to be much bigger, I'm not saying that will solve the problem but it might help(max
>       allowed is 10,000). I'm also suspect when you say your have a sync_interval of 5 minutes, since I thought 60
>       seconds was the largest allowed.
> 
> My apologies
> 
> cleanup_interval="5 minutes" ?
> 
> my interval is 1000ms
> 
> And sync, group cites 100 is the max
> 
> # Range:? [0,100], default: 6
> 
> sync_group_maxsize=50

Where does that come from?
http://www.slony.info/documentation/2.2/slon-config-interval.html

says the max is 10,000 and the code looks like it agrees.  Try it and see if 
you start to catch up.  Also an analyze on your sl_log_1 and sl_log_2 can't 
hurt.

With a sync_group_size of 20 slon will select the data for at most 20 SYNC's 
at once and apply them (using a select from sl_log_1 ... union select from 
sl_log_2 ...)

With a sync_group_size of 10,000 it can in theory select 10,000 sync's at 
once (but I think it takes a while to work up to that point).

If your bottleneck is the master then it is possible that the selecting from 
sl_log is causing the problem.

Slon can't truncate a log until all the data in that log has been 
replicated and there are only 2 logs.




> 
> 
> 
> 
>

From tmblue at gmail.com  Thu Jan  7 15:13:11 2016
From: tmblue at gmail.com (Tory M Blue)
Date: Thu, 7 Jan 2016 15:13:11 -0800
Subject: [Slony1-general] Slony-I: log switch to sl_log_2 still in
 progress - sl_log_1 not truncated
In-Reply-To: <alpine.DEB.2.02.1601071754040.11931@mini.atlantida>
References: <CAEaSS0aCUuNmtsekJmG+fgt2EqgA5ArnPnn-Z3ZUT2kza6ixmw@mail.gmail.com>
	<alpine.DEB.2.02.1601071743020.11931@mini.atlantida>
	<CAEaSS0ZLoz8pofz9EySn7rZ+U1kXhor+0eNs-f7PF2t-SLvQkw@mail.gmail.com>
	<alpine.DEB.2.02.1601071754040.11931@mini.atlantida>
Message-ID: <CAEaSS0ZYWr5fqpuw+ihB=Qe8MBvqAi-T_YGB7vUJ2WYrYGhVwA@mail.gmail.com>

On Thu, Jan 7, 2016 at 2:59 PM, Steve Singer <steve at ssinger.info> wrote:

> On Thu, 7 Jan 2016, Tory M Blue wrote:
>
>       Bump sync_group_maxsize to be much bigger, I'm not saying that will
>> solve the problem but it might help(max
>>       allowed is 10,000). I'm also suspect when you say your have a
>> sync_interval of 5 minutes, since I thought 60
>>       seconds was the largest allowed.
>>
>> My apologies
>>
>> cleanup_interval="5 minutes"
>>
>> my interval is 1000ms
>>
>> And sync, group cites 100 is the max
>>
>> # Range:  [0,100], default: 6
>>
>> sync_group_maxsize=50
>>
>
> Where does that come from?
> http://www.slony.info/documentation/2.2/slon-config-interval.html
>
> says the max is 10,000 and the code looks like it agrees.  Try it and see
> if you start to catch up.  Also an analyze on your sl_log_1 and sl_log_2
> can't hurt.
>
> With a sync_group_size of 20 slon will select the data for at most 20
> SYNC's at once and apply them (using a select from sl_log_1 ... union
> select from sl_log_2 ...)
>
> With a sync_group_size of 10,000 it can in theory select 10,000 sync's at
> once (but I think it takes a while to work up to that point).
>
> If your bottleneck is the master then it is possible that the selecting
> from sl_log is causing the problem.
>
> Thanks Steve, I had that in my slon.conf, it may have been left over from
many years 10+ of using slon and a much earlier version :) I'll keep
incrementing it and see what happens.

Analyze was quick, but I think you are on to something when you cited that
it may be taking a bit to grab from sl_log1 and thus the snowball.. Can't
say I've ever had this many records backed up, but the idea of dropping
node 2, when i know I'll be in the same situation bothers me :)

2016-01-07 15:10:29 PST clsdb postgres [local] 16066 2016-01-07
15:10:29.128 PSTLOG:  duration: 2096.165 ms  statement: analyze
_cls.sl_log_2;
2016-01-07 15:10:36 PST aclsdb postgres [local] 16066 2016-01-07
15:10:36.162 PSTLOG:  duration: 2426.762 ms  statement: analyze
_cls.sl_log_1

Tory
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20160107/41df5853/attachment-0001.htm 

From krzysztof.jakowczyk at unity.pl  Tue Jan 12 08:21:57 2016
From: krzysztof.jakowczyk at unity.pl (Krzysztof Jakowczyk)
Date: Tue, 12 Jan 2016 17:21:57 +0100
Subject: [Slony1-general] log insert/update query executed on subscriber
Message-ID: <56952825.8040801@unity.pl>

Hello,

Is it possible to log query with parameters executed on subscriber node?
I've tried to add __audit trigger before insert or update, but when
denyaccess trigger is enabled, nothing is logged. Below is my try for
table emp:

CREATE SCHEMA
audit;                                                                                                                                                  


CREATE TABLE audit.slon_audit (
    operation         char(1)   NOT NULL,
    stamp             timestamp NOT NULL,
    userid            text      NOT NULL,
    query             text      NOT NULL
);


CREATE OR REPLACE FUNCTION save_query() RETURNS TRIGGER AS $$
    BEGIN
        IF (TG_OP = 'DELETE') THEN
            INSERT INTO audit.slon_audit SELECT 'D', now(), user, OLD.*;
            RETURN OLD;
        ELSIF (TG_OP = 'UPDATE') THEN
            INSERT INTO audit.slon_audit SELECT 'U', now(), user,
current_query();
            RETURN NEW;
        ELSIF (TG_OP = 'INSERT') THEN
            INSERT INTO audit.slon_audit SELECT 'I', now(), user,
current_query();
            RETURN NEW;
        END IF;
        RETURN NULL;
    END;
$$ LANGUAGE plpgsql;


CREATE TRIGGER __audit
BEFORE INSERT OR UPDATE OR DELETE ON emp
    FOR EACH ROW EXECUTE PROCEDURE save_query();

-- 
Pozdrawiam,

Krzysztof Jakowczyk
Administrator System?w Unix
 
Grupa Unity | ul. Przedmiejska 6-10, 54-201 Wroc?aw
ul. Conrada 55B, 31-357 Krak?w | ul. Z?ota 59, 00-120 Warszawa




From steve at ssinger.info  Tue Jan 12 18:43:22 2016
From: steve at ssinger.info (Steve Singer)
Date: Tue, 12 Jan 2016 21:43:22 -0500 (EST)
Subject: [Slony1-general] log insert/update query executed on subscriber
In-Reply-To: <56952825.8040801@unity.pl>
References: <56952825.8040801@unity.pl>
Message-ID: <alpine.DEB.2.02.1601122141490.11931@mini.atlantida>

On Tue, 12 Jan 2016, Krzysztof Jakowczyk wrote:

> Hello,
>
> Is it possible to log query with parameters executed on subscriber node?
> I've tried to add __audit trigger before insert or update, but when
> denyaccess trigger is enabled, nothing is logged. Below is my try for
> table emp:
>

>
> CREATE TRIGGER __audit
> BEFORE INSERT OR UPDATE OR DELETE ON emp
>    FOR EACH ROW EXECUTE PROCEDURE save_query();

Setting the trigger to fire always should work.

ALTER TABLE foo ENABLE ALWAYS TRIGGER __audit;

http://www.postgresql.org/docs/9.1/interactive/sql-altertable.html



>
> -- 
> Pozdrawiam,
>
> Krzysztof Jakowczyk
> Administrator System?w Unix
> 
> Grupa Unity | ul. Przedmiejska 6-10, 54-201 Wroc?aw
> ul. Conrada 55B, 31-357 Krak?w | ul. Z?ota 59, 00-120 Warszawa
>
>
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general

From krzysztof.jakowczyk at unity.pl  Tue Jan 12 22:52:07 2016
From: krzysztof.jakowczyk at unity.pl (Krzysztof Jakowczyk)
Date: Wed, 13 Jan 2016 07:52:07 +0100
Subject: [Slony1-general] log insert/update query executed on subscriber
In-Reply-To: <alpine.DEB.2.02.1601122141490.11931@mini.atlantida>
References: <56952825.8040801@unity.pl>
	<alpine.DEB.2.02.1601122141490.11931@mini.atlantida>
Message-ID: <5695F417.7020903@unity.pl>

No, it doesn't. Take a look:

# \d emp
      Table "public.emp"
 Column  |  Type   | Modifiers
---------+---------+-----------
 empname | text    | not null
 salary  | integer |
Triggers:
    _b24v2_denyaccess BEFORE INSERT OR DELETE OR UPDATE ON emp FOR EACH
ROW EXECUTE PROCEDURE _b24v2.denyaccess('_b24v2')
Triggers firing always:
    __audit BEFORE INSERT OR DELETE OR UPDATE ON emp FOR EACH ROW
EXECUTE PROCEDURE save_query()


-- with disabled trigger denyaccess
# insert into emp values ('TEST dasdasdas',123123);
INSERT 0 1
# select * from audit.slon_audit;
 operation |           stamp            |  userid 
|                       query                      
-----------+----------------------------+----------+---------------------------------------------------
 I         | 2016-01-13 06:46:15.417799 | postgres | insert into emp
values ('TEST dasdasdas',123123);
(1 row)

-- enabling trigger denyaccess
# alter table emp enable trigger _b24v2_denyaccess;
ALTER TABLE
# insert into emp values ('test2',31337);
ERROR:  Slony-I: Table emp is replicated and cannot be modified on a
subscriber node - role=0
# select * from audit.slon_audit;
 operation |           stamp            |  userid 
|                       query                      
-----------+----------------------------+----------+---------------------------------------------------
 I         | 2016-01-13 06:46:15.417799 | postgres | insert into emp
values ('TEST dasdasdas',123123);
(1 row)


Nothing happend. Any other ideas?

-- 
Pozdrawiam,

Krzysztof Jakowczyk
Administrator System?w Unix
 
Grupa Unity | ul. Przedmiejska 6-10, 54-201 Wroc?aw
ul. Conrada 55B, 31-357 Krak?w | ul. Z?ota 59, 00-120 Warszawa


On 13.01.2016 03:43, Steve Singer wrote:
> On Tue, 12 Jan 2016, Krzysztof Jakowczyk wrote:
>
>> Hello,
>>
>> Is it possible to log query with parameters executed on subscriber node?
>> I've tried to add __audit trigger before insert or update, but when
>> denyaccess trigger is enabled, nothing is logged. Below is my try for
>> table emp:
>>
>
>>
>> CREATE TRIGGER __audit
>> BEFORE INSERT OR UPDATE OR DELETE ON emp
>>    FOR EACH ROW EXECUTE PROCEDURE save_query();
>
> Setting the trigger to fire always should work.
>
> ALTER TABLE foo ENABLE ALWAYS TRIGGER __audit;
>
> http://www.postgresql.org/docs/9.1/interactive/sql-altertable.html
>
>
>
>>
>> -- 
>> Pozdrawiam,
>>
>> Krzysztof Jakowczyk
>> Administrator System?w Unix
>>
>> Grupa Unity | ul. Przedmiejska 6-10, 54-201 Wroc?aw
>> ul. Conrada 55B, 31-357 Krak?w | ul. Z?ota 59, 00-120 Warszawa
>>
>>
>>
>> _______________________________________________
>> Slony1-general mailing list
>> Slony1-general at lists.slony.info
>> http://lists.slony.info/mailman/listinfo/slony1-general



From stephane.schildknecht at postgres.fr  Wed Jan 13 00:17:04 2016
From: stephane.schildknecht at postgres.fr (=?UTF-8?Q?St=c3=a9phane_Schildknecht?=)
Date: Wed, 13 Jan 2016 09:17:04 +0100
Subject: [Slony1-general] log insert/update query executed on subscriber
In-Reply-To: <5695F417.7020903@unity.pl>
References: <56952825.8040801@unity.pl>
	<alpine.DEB.2.02.1601122141490.11931@mini.atlantida>
	<5695F417.7020903@unity.pl>
Message-ID: <56960800.8040904@postgres.fr>

On 13/01/2016 07:52, Krzysztof Jakowczyk wrote:
> No, it doesn't. Take a look:
> 
> # \d emp
>       Table "public.emp"
>  Column  |  Type   | Modifiers
> ---------+---------+-----------
>  empname | text    | not null
>  salary  | integer |
> Triggers:
>     _b24v2_denyaccess BEFORE INSERT OR DELETE OR UPDATE ON emp FOR EACH
> ROW EXECUTE PROCEDURE _b24v2.denyaccess('_b24v2')
> Triggers firing always:
>     __audit BEFORE INSERT OR DELETE OR UPDATE ON emp FOR EACH ROW
> EXECUTE PROCEDURE save_query()
> 
> 
> -- with disabled trigger denyaccess
> # insert into emp values ('TEST dasdasdas',123123);
> INSERT 0 1
> # select * from audit.slon_audit;
>  operation |           stamp            |  userid 
> |                       query                      
> -----------+----------------------------+----------+---------------------------------------------------
>  I         | 2016-01-13 06:46:15.417799 | postgres | insert into emp
> values ('TEST dasdasdas',123123);
> (1 row)
> 
> -- enabling trigger denyaccess
> # alter table emp enable trigger _b24v2_denyaccess;
> ALTER TABLE
> # insert into emp values ('test2',31337);
> ERROR:  Slony-I: Table emp is replicated and cannot be modified on a
> subscriber node - role=0
> # select * from audit.slon_audit;
>  operation |           stamp            |  userid 
> |                       query                      
> -----------+----------------------------+----------+---------------------------------------------------
>  I         | 2016-01-13 06:46:15.417799 | postgres | insert into emp
> values ('TEST dasdasdas',123123);
> (1 row)
> 
> 
> Nothing happend. Any other ideas?
> 

I guess it is related to the alphabetical order of triggers, as they are both
BEFORE triggers.

-- 
St?phane Schildknecht
Contact r?gional PostgreSQL pour l'Europe francophone
Loxodata - Conseil, expertise et formations
06.17.11.37.42


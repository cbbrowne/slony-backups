From david at fetter.org  Tue Apr 14 15:56:05 2015
From: david at fetter.org (David Fetter)
Date: Tue, 14 Apr 2015 15:56:05 -0700
Subject: [Slony1-general] Multiple slons per node pair?
Message-ID: <20150414225605.GB23915@fetter.org>

Folks,

This came up in the context of making slony k-safe for some k>0.

Naively, a simple way to do this would be to have >1 machine, each
running all the slons for a cluster, replacing any machines that fail.

Would Bad Things? happen as a consequence?

Cheers,
David.
-- 
David Fetter <david at fetter.org> http://fetter.org/
Phone: +1 415 235 3778  AIM: dfetter666  Yahoo!: dfetter
Skype: davidfetter      XMPP: david.fetter at gmail.com

Remember to vote!
Consider donating to Postgres: http://www.postgresql.org/about/donate

From ajs at crankycanuck.ca  Tue Apr 14 16:18:28 2015
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Tue, 14 Apr 2015 19:18:28 -0400
Subject: [Slony1-general] Multiple slons per node pair?
In-Reply-To: <20150414225605.GB23915@fetter.org>
References: <20150414225605.GB23915@fetter.org>
Message-ID: <20150414231828.GK43114@crankycanuck.ca>

On Tue, Apr 14, 2015 at 03:56:05PM -0700, David Fetter wrote:
> 
> Naively, a simple way to do this would be to have >1 machine, each
> running all the slons for a cluster, replacing any machines that fail.
> 
> Would Bad Things? happen as a consequence?

I seem to recall doing this by accident some years ago, and getting a
lot of deadlocks (and resulting rollbacks).  I know the whole system
is carefully designed for safety, so I don't think it'll break
anything, but I think you'll get a lot of non-optimal locking that
will block stuff.  Also, your troubleshooting will be a nightmare.

I suspect you'd be much better off to run some sort of watchdog across
machines and start in the event you can't reach through.  If you have
a network problem between the nodes, you still shouldn't break
anything, but it's more likely to work smoothly, I think.

A

-- 
Andrew Sullivan
ajs at crankycanuck.ca


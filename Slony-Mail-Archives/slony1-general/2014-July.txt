From ssinger at ca.afilias.info  Tue Jul  1 10:37:33 2014
From: ssinger at ca.afilias.info (Steve Singer)
Date: Tue, 01 Jul 2014 13:37:33 -0400
Subject: [Slony1-general] manually delete sl_log_x table
In-Reply-To: <CAAMgDX=dXYbK_5X+7wbapx-=Kc8cH9b+VjX7Jc6XcPZDqL4iHQ@mail.gmail.com>
References: <CAAMgDX=KUx8Hty2WJXARWSTtKsnKP2Je=f0VVVcP8hwZyaAuHA@mail.gmail.com>	<53AAE50E.7030101@ca.afilias.info>	<CAAMgDXmMB9gJrxgVuBRnvKMewShy2xiV0kygE2Rv+0JK9pLPrA@mail.gmail.com>	<53AAE9CC.6020706@ca.afilias.info>	<CAAMgDXnpdJYESt3zBpVi8tCe-qJgXSM+e=7xiQXzUxKTDwz9kQ@mail.gmail.com>	<53AB741F.907@ca.afilias.info>	<CAAMgDXmWR_pNdm1cwmXy+TWKnitPki+A_S1gKxfsnpzmz1gKFw@mail.gmail.com>
	<CAAMgDX=dXYbK_5X+7wbapx-=Kc8cH9b+VjX7Jc6XcPZDqL4iHQ@mail.gmail.com>
Message-ID: <53B2F1DD.9000400@ca.afilias.info>

On 06/30/2014 01:05 PM, Soni M wrote:
> it seems a slony process that has <IDLE> in transaction for many times.
> the client address and the user are identical to slony slave.
>
>

Which version of slony are you on?



> On Mon, Jun 30, 2014 at 11:54 PM, Soni M <diptatapa at gmail.com
> <mailto:diptatapa at gmail.com>> wrote:
>
>     On Thu, Jun 26, 2014 at 8:15 AM, Steve Singer
>     <ssinger at ca.afilias.info <mailto:ssinger at ca.afilias.info>> wrote:
>
>
>
>         Which transactions are locking sl_log_2 when slony is in that state?
>
>         The slony log trigger should only be adding rows to sl_log_1 in
>         this state.   If this isn't the case then there is a problem.
>
>         The problem with waiting for the lock is other transactions will
>         the block and queue up behind the cleanup thread/transaction.
>
>
>
>     I saw this query from slony slave :
>
>     fetch 500 from LOG;
>
>     but another time it is
>
>     <IDLE> in transaction
>
>     that has lock on sl_log_2. The <IDLE> in transaction appear much
>     more often.
>
>     --
>     Regards,
>
>     Soni Maula Harriz
>
>
>
>
> --
> Regards,
>
> Soni Maula Harriz


From diptatapa at gmail.com  Tue Jul  1 17:24:21 2014
From: diptatapa at gmail.com (Soni M)
Date: Wed, 2 Jul 2014 07:24:21 +0700
Subject: [Slony1-general] manually delete sl_log_x table
In-Reply-To: <53B2F1DD.9000400@ca.afilias.info>
References: <CAAMgDX=KUx8Hty2WJXARWSTtKsnKP2Je=f0VVVcP8hwZyaAuHA@mail.gmail.com>
	<53AAE50E.7030101@ca.afilias.info>
	<CAAMgDXmMB9gJrxgVuBRnvKMewShy2xiV0kygE2Rv+0JK9pLPrA@mail.gmail.com>
	<53AAE9CC.6020706@ca.afilias.info>
	<CAAMgDXnpdJYESt3zBpVi8tCe-qJgXSM+e=7xiQXzUxKTDwz9kQ@mail.gmail.com>
	<53AB741F.907@ca.afilias.info>
	<CAAMgDXmWR_pNdm1cwmXy+TWKnitPki+A_S1gKxfsnpzmz1gKFw@mail.gmail.com>
	<CAAMgDX=dXYbK_5X+7wbapx-=Kc8cH9b+VjX7Jc6XcPZDqL4iHQ@mail.gmail.com>
	<53B2F1DD.9000400@ca.afilias.info>
Message-ID: <CAAMgDXkuAUo-96hamWtE_DiBEbkG1=0OUA9wmovYxMb1Omheqw@mail.gmail.com>

Master : Ubuntu 10.04 LTS, Postgre 9.1.13, Slony 2.0.7 from Ubuntu Package
Slave : Ubuntu 10.04 LTS, Postgres 9.1.13, Slony 2.0.7 seems build from
source.
DB size 1.5 TB, Master utilize relative high number of temp tables and
relative High number of locks on busy time

DB=# select mode, count(*) from pg_locks group by mode;
           mode           | count
--------------------------+--------
 ExclusiveLock            |    112
 RowShareLock             |     37
 AccessExclusiveLock      | 208577
 RowExclusiveLock         |  33087
 ShareUpdateExclusiveLock |      5
 ShareLock                |  54906
 AccessShareLock          |  93607
(7 rows)

but the slave is relative low on load.

this is the connection from slave that open from May 25th
postgres 14090  0.1  1.1 4512644 230760 ?      Ss   May25  59:08 postgres:
slony_user dbname master_ip_address(58554) idle

On slave, this connection seems always keep on idle status, but on master,
this connection often in "<IDLE> in transaction" status for some minutes
and hold lock on sl_log_2 while transaction are filling up sl_log_1.

Such condition usually happen on server high load time, but on low load it
sometimes happen, but not many and does not affect on replication lag.

On Wed, Jul 2, 2014 at 12:37 AM, Steve Singer <ssinger at ca.afilias.info>
wrote:

> On 06/30/2014 01:05 PM, Soni M wrote:
>
>> it seems a slony process that has <IDLE> in transaction for many times.
>> the client address and the user are identical to slony slave.
>>
>>
>>
> Which version of slony are you on?
>
>>
>>
>


-- 
Regards,

Soni Maula Harriz
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20140702/7bc31293/attachment.htm 

From ssinger at ca.afilias.info  Wed Jul  2 06:33:34 2014
From: ssinger at ca.afilias.info (Steve Singer)
Date: Wed, 02 Jul 2014 09:33:34 -0400
Subject: [Slony1-general] manually delete sl_log_x table
In-Reply-To: <CAAMgDXkuAUo-96hamWtE_DiBEbkG1=0OUA9wmovYxMb1Omheqw@mail.gmail.com>
References: <CAAMgDX=KUx8Hty2WJXARWSTtKsnKP2Je=f0VVVcP8hwZyaAuHA@mail.gmail.com>	<53AAE50E.7030101@ca.afilias.info>	<CAAMgDXmMB9gJrxgVuBRnvKMewShy2xiV0kygE2Rv+0JK9pLPrA@mail.gmail.com>	<53AAE9CC.6020706@ca.afilias.info>	<CAAMgDXnpdJYESt3zBpVi8tCe-qJgXSM+e=7xiQXzUxKTDwz9kQ@mail.gmail.com>	<53AB741F.907@ca.afilias.info>	<CAAMgDXmWR_pNdm1cwmXy+TWKnitPki+A_S1gKxfsnpzmz1gKFw@mail.gmail.com>	<CAAMgDX=dXYbK_5X+7wbapx-=Kc8cH9b+VjX7Jc6XcPZDqL4iHQ@mail.gmail.com>	<53B2F1DD.9000400@ca.afilias.info>
	<CAAMgDXkuAUo-96hamWtE_DiBEbkG1=0OUA9wmovYxMb1Omheqw@mail.gmail.com>
Message-ID: <53B40A2E.4010100@ca.afilias.info>

On 07/01/2014 08:24 PM, Soni M wrote:


What is
select last_value from sl_log_status (it is a sequence) on the master 
when you see those "NOTICE:  Slony-I: could not lock sl_log_2 - sl_log_2 
not truncated" messages?

The sl_log_status value SHOULD be controlling both which (if any) tables 
the cleanup thread tries to lock/truncate and which of the log tables 
slon selects from.  It should be doing it such a way that the cleanup 
thread will never try to lock a table that slon is going to select from. 
Of course, there could be a bug here.

Also you should be aware of bug 167 (
http://www.slony.info/bugzilla/show_bug.cgi?id=167) which exists in 
slony 2.0.x where if replication is behind (your sl_log tables grow 
large) then selecting from sl_log becomes a full table scan making 
replication very slow.  Bug 167 was fixed in 2.1







>
> Master : Ubuntu 10.04 LTS, Postgre 9.1.13, Slony 2.0.7 from Ubuntu Package
> Slave : Ubuntu 10.04 LTS, Postgres 9.1.13, Slony 2.0.7 seems build from
> source.
> DB size 1.5 TB, Master utilize relative high number of temp tables and
> relative High number of locks on busy time
>
> DB=# select mode, count(*) from pg_locks group by mode;
>             mode           | count
> --------------------------+--------
>   ExclusiveLock            |    112
>   RowShareLock             |     37
>   AccessExclusiveLock      | 208577
>   RowExclusiveLock         |  33087
>   ShareUpdateExclusiveLock |      5
>   ShareLock                |  54906
>   AccessShareLock          |  93607
> (7 rows)
> but the slave is relative low on load.
>
> this is the connection from slave that open from May 25th
> postgres 14090  0.1  1.1 4512644 230760 ?      Ss   May25  59:08
> postgres: slony_user dbname master_ip_address(58554) idle
>
> On slave, this connection seems always keep on idle status, but on
> master, this connection often in "<IDLE> in transaction" status for some
> minutes and hold lock on sl_log_2 while transaction are filling up sl_log_1.
>
> Such condition usually happen on server high load time, but on low load
> it sometimes happen, but not many and does not affect on replication lag.
>
> On Wed, Jul 2, 2014 at 12:37 AM, Steve Singer <ssinger at ca.afilias.info
> <mailto:ssinger at ca.afilias.info>> wrote:
>
>     On 06/30/2014 01:05 PM, Soni M wrote:
>
>         it seems a slony process that has <IDLE> in transaction for many
>         times.
>         the client address and the user are identical to slony slave.
>
>
>
>     Which version of slony are you on?
>
>
>
>
>
> --
> Regards,
>
> Soni Maula Harriz


From ssinger at ca.afilias.info  Wed Jul  2 09:02:22 2014
From: ssinger at ca.afilias.info (Steve Singer)
Date: Wed, 02 Jul 2014 12:02:22 -0400
Subject: [Slony1-general] manually delete sl_log_x table
In-Reply-To: <CAAMgDXkuAUo-96hamWtE_DiBEbkG1=0OUA9wmovYxMb1Omheqw@mail.gmail.com>
References: <CAAMgDX=KUx8Hty2WJXARWSTtKsnKP2Je=f0VVVcP8hwZyaAuHA@mail.gmail.com>	<53AAE50E.7030101@ca.afilias.info>	<CAAMgDXmMB9gJrxgVuBRnvKMewShy2xiV0kygE2Rv+0JK9pLPrA@mail.gmail.com>	<53AAE9CC.6020706@ca.afilias.info>	<CAAMgDXnpdJYESt3zBpVi8tCe-qJgXSM+e=7xiQXzUxKTDwz9kQ@mail.gmail.com>	<53AB741F.907@ca.afilias.info>	<CAAMgDXmWR_pNdm1cwmXy+TWKnitPki+A_S1gKxfsnpzmz1gKFw@mail.gmail.com>	<CAAMgDX=dXYbK_5X+7wbapx-=Kc8cH9b+VjX7Jc6XcPZDqL4iHQ@mail.gmail.com>	<53B2F1DD.9000400@ca.afilias.info>
	<CAAMgDXkuAUo-96hamWtE_DiBEbkG1=0OUA9wmovYxMb1Omheqw@mail.gmail.com>
Message-ID: <53B42D0E.9060603@ca.afilias.info>

On 07/01/2014 08:24 PM, Soni M wrote:
>
> Master : Ubuntu 10.04 LTS, Postgre 9.1.13, Slony 2.0.7 from Ubuntu Package
> Slave : Ubuntu 10.04 LTS, Postgres 9.1.13, Slony 2.0.7 seems build from


I should also point out that slony 2.0.x does not properly support PG 
9.1 or higher.  You should use slony 2.1.x or 2.2.x with PG 9.1+.

If you are seeing a lot of transactions being aborted due to 
serialization conflicts then this is because of the issues with PG 9.1 
and slony 2.0 (though it doesn't sound like that is causing this 
particular issue)



> source.
> DB size 1.5 TB, Master utilize relative high number of temp tables and
> relative High number of locks on busy time
>
> DB=# select mode, count(*) from pg_locks group by mode;
>             mode           | count
> --------------------------+--------
>   ExclusiveLock            |    112
>   RowShareLock             |     37
>   AccessExclusiveLock      | 208577
>   RowExclusiveLock         |  33087
>   ShareUpdateExclusiveLock |      5
>   ShareLock                |  54906
>   AccessShareLock          |  93607
> (7 rows)
> but the slave is relative low on load.
>
> this is the connection from slave that open from May 25th
> postgres 14090  0.1  1.1 4512644 230760 ?      Ss   May25  59:08
> postgres: slony_user dbname master_ip_address(58554) idle
>
> On slave, this connection seems always keep on idle status, but on
> master, this connection often in "<IDLE> in transaction" status for some
> minutes and hold lock on sl_log_2 while transaction are filling up sl_log_1.
>
> Such condition usually happen on server high load time, but on low load
> it sometimes happen, but not many and does not affect on replication lag.
>
> On Wed, Jul 2, 2014 at 12:37 AM, Steve Singer <ssinger at ca.afilias.info
> <mailto:ssinger at ca.afilias.info>> wrote:
>
>     On 06/30/2014 01:05 PM, Soni M wrote:
>
>         it seems a slony process that has <IDLE> in transaction for many
>         times.
>         the client address and the user are identical to slony slave.
>
>
>
>     Which version of slony are you on?
>
>
>
>
>
> --
> Regards,
>
> Soni Maula Harriz


From ssinger at ca.afilias.info  Mon Jul  7 18:54:31 2014
From: ssinger at ca.afilias.info (Steve Singer)
Date: Mon, 07 Jul 2014 21:54:31 -0400
Subject: [Slony1-general] Slony 2.2.3 released
Message-ID: <53BB4F57.4030907@ca.afilias.info>

The Slony team is pleased to announce Slony 2.2.3 the next minor release 
of the Slony 2.2.x series

Slony 2.2.3 includes the following changes

  - Bug 338 - Have ddlScript return a bigint instead of a integer
  - fixing  Deadlock with application during minor version slony upgrade
  - Bug 342 FAILOVER fixes for some multi-node configurations
  - Remove HAVE_POSIX_SIGNALS from config.h
  - Bug 344 Do not abort reading slon config values when an unrecognized 
one is encountered


Slony 2.2.3 can be downloaded from from the following URL

http://main.slony.info/downloads/2.2/source/slony1-2.2.3.tar.bz2


From diptatapa at gmail.com  Tue Jul  8 08:06:10 2014
From: diptatapa at gmail.com (Soni M)
Date: Tue, 8 Jul 2014 22:06:10 +0700
Subject: [Slony1-general] manually delete sl_log_x table
In-Reply-To: <53B42D0E.9060603@ca.afilias.info>
References: <CAAMgDX=KUx8Hty2WJXARWSTtKsnKP2Je=f0VVVcP8hwZyaAuHA@mail.gmail.com>
	<53AAE50E.7030101@ca.afilias.info>
	<CAAMgDXmMB9gJrxgVuBRnvKMewShy2xiV0kygE2Rv+0JK9pLPrA@mail.gmail.com>
	<53AAE9CC.6020706@ca.afilias.info>
	<CAAMgDXnpdJYESt3zBpVi8tCe-qJgXSM+e=7xiQXzUxKTDwz9kQ@mail.gmail.com>
	<53AB741F.907@ca.afilias.info>
	<CAAMgDXmWR_pNdm1cwmXy+TWKnitPki+A_S1gKxfsnpzmz1gKFw@mail.gmail.com>
	<CAAMgDX=dXYbK_5X+7wbapx-=Kc8cH9b+VjX7Jc6XcPZDqL4iHQ@mail.gmail.com>
	<53B2F1DD.9000400@ca.afilias.info>
	<CAAMgDXkuAUo-96hamWtE_DiBEbkG1=0OUA9wmovYxMb1Omheqw@mail.gmail.com>
	<53B42D0E.9060603@ca.afilias.info>
Message-ID: <CAAMgDXneq4LxiL=WwZL8=5SKp98EX3G_VuQ0yi=_j+aPsy7H3Q@mail.gmail.com>

Sorry for late response,
currently :
NOTICE:  Slony-I: could not lock sl_log_1 - sl_log_1 not truncated
dbname=# select last_value from sl_log_status;
 last_value
------------
          3
(1 row)

That's what it should be, right?

But now, i see application transaction holding locks on sl_log_1, some
select, insert and update transaction and also the <IDLE> in transaction
just like before. But the row numbers of sl_log_1 not increasing anyway.
The row num is increasing in sl_log_2. Is that normal?

The bug on 2.0.x as You said does happen in our environment, and it happens
when the slave falls further behind the master. I should plan to move to
2.1 or 2.2.



On Wed, Jul 2, 2014 at 11:02 PM, Steve Singer <ssinger at ca.afilias.info>
wrote:

> On 07/01/2014 08:24 PM, Soni M wrote:
>
>>
>> Master : Ubuntu 10.04 LTS, Postgre 9.1.13, Slony 2.0.7 from Ubuntu Package
>> Slave : Ubuntu 10.04 LTS, Postgres 9.1.13, Slony 2.0.7 seems build from
>>
>
>
> I should also point out that slony 2.0.x does not properly support PG 9.1
> or higher.  You should use slony 2.1.x or 2.2.x with PG 9.1+.
>
> If you are seeing a lot of transactions being aborted due to serialization
> conflicts then this is because of the issues with PG 9.1 and slony 2.0
> (though it doesn't sound like that is causing this particular issue)
>
>
>
>  source.
>> DB size 1.5 TB, Master utilize relative high number of temp tables and
>> relative High number of locks on busy time
>>
>> DB=# select mode, count(*) from pg_locks group by mode;
>>             mode           | count
>> --------------------------+--------
>>   ExclusiveLock            |    112
>>   RowShareLock             |     37
>>   AccessExclusiveLock      | 208577
>>   RowExclusiveLock         |  33087
>>   ShareUpdateExclusiveLock |      5
>>   ShareLock                |  54906
>>   AccessShareLock          |  93607
>> (7 rows)
>> but the slave is relative low on load.
>>
>> this is the connection from slave that open from May 25th
>> postgres 14090  0.1  1.1 4512644 230760 ?      Ss   May25  59:08
>> postgres: slony_user dbname master_ip_address(58554) idle
>>
>> On slave, this connection seems always keep on idle status, but on
>> master, this connection often in "<IDLE> in transaction" status for some
>> minutes and hold lock on sl_log_2 while transaction are filling up
>> sl_log_1.
>>
>> Such condition usually happen on server high load time, but on low load
>> it sometimes happen, but not many and does not affect on replication lag.
>>
>> On Wed, Jul 2, 2014 at 12:37 AM, Steve Singer <ssinger at ca.afilias.info
>> <mailto:ssinger at ca.afilias.info>> wrote:
>>
>>     On 06/30/2014 01:05 PM, Soni M wrote:
>>
>>         it seems a slony process that has <IDLE> in transaction for many
>>         times.
>>         the client address and the user are identical to slony slave.
>>
>>
>>
>>     Which version of slony are you on?
>>
>>
>>
>>
>>
>> --
>> Regards,
>>
>> Soni Maula Harriz
>>
>
>


-- 
Regards,

Soni Maula Harriz
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20140708/224b365c/attachment.htm 

From jan at wi3ck.info  Tue Jul  8 08:14:39 2014
From: jan at wi3ck.info (Jan Wieck)
Date: Tue, 8 Jul 2014 11:14:39 -0400
Subject: [Slony1-general] manually delete sl_log_x table
In-Reply-To: <CAAMgDXneq4LxiL=WwZL8=5SKp98EX3G_VuQ0yi=_j+aPsy7H3Q@mail.gmail.com>
References: <CAAMgDX=KUx8Hty2WJXARWSTtKsnKP2Je=f0VVVcP8hwZyaAuHA@mail.gmail.com>
	<53AAE50E.7030101@ca.afilias.info>
	<CAAMgDXmMB9gJrxgVuBRnvKMewShy2xiV0kygE2Rv+0JK9pLPrA@mail.gmail.com>
	<53AAE9CC.6020706@ca.afilias.info>
	<CAAMgDXnpdJYESt3zBpVi8tCe-qJgXSM+e=7xiQXzUxKTDwz9kQ@mail.gmail.com>
	<53AB741F.907@ca.afilias.info>
	<CAAMgDXmWR_pNdm1cwmXy+TWKnitPki+A_S1gKxfsnpzmz1gKFw@mail.gmail.com>
	<CAAMgDX=dXYbK_5X+7wbapx-=Kc8cH9b+VjX7Jc6XcPZDqL4iHQ@mail.gmail.com>
	<53B2F1DD.9000400@ca.afilias.info>
	<CAAMgDXkuAUo-96hamWtE_DiBEbkG1=0OUA9wmovYxMb1Omheqw@mail.gmail.com>
	<53B42D0E.9060603@ca.afilias.info>
	<CAAMgDXneq4LxiL=WwZL8=5SKp98EX3G_VuQ0yi=_j+aPsy7H3Q@mail.gmail.com>
Message-ID: <CAGBW59cga+1Qj=MmRY00N5QSakokHs1KEFk12ZH=_O9JBUpnZg@mail.gmail.com>

Why and what application is holding locks on the Slony log tables?

Jan

--
Jan Wieck
Senior Software Engineer
http://slony.info
On Jul 8, 2014 11:06 AM, "Soni M" <diptatapa at gmail.com> wrote:

> Sorry for late response,
> currently :
> NOTICE:  Slony-I: could not lock sl_log_1 - sl_log_1 not truncated
> dbname=# select last_value from sl_log_status;
>  last_value
> ------------
>           3
> (1 row)
>
> That's what it should be, right?
>
> But now, i see application transaction holding locks on sl_log_1, some
> select, insert and update transaction and also the <IDLE> in transaction
> just like before. But the row numbers of sl_log_1 not increasing anyway.
> The row num is increasing in sl_log_2. Is that normal?
>
> The bug on 2.0.x as You said does happen in our environment, and it
> happens when the slave falls further behind the master. I should plan to
> move to 2.1 or 2.2.
>
>
>
> On Wed, Jul 2, 2014 at 11:02 PM, Steve Singer <ssinger at ca.afilias.info>
> wrote:
>
>> On 07/01/2014 08:24 PM, Soni M wrote:
>>
>>>
>>> Master : Ubuntu 10.04 LTS, Postgre 9.1.13, Slony 2.0.7 from Ubuntu
>>> Package
>>> Slave : Ubuntu 10.04 LTS, Postgres 9.1.13, Slony 2.0.7 seems build from
>>>
>>
>>
>> I should also point out that slony 2.0.x does not properly support PG 9.1
>> or higher.  You should use slony 2.1.x or 2.2.x with PG 9.1+.
>>
>> If you are seeing a lot of transactions being aborted due to
>> serialization conflicts then this is because of the issues with PG 9.1 and
>> slony 2.0 (though it doesn't sound like that is causing this particular
>> issue)
>>
>>
>>
>>  source.
>>> DB size 1.5 TB, Master utilize relative high number of temp tables and
>>> relative High number of locks on busy time
>>>
>>> DB=# select mode, count(*) from pg_locks group by mode;
>>>             mode           | count
>>> --------------------------+--------
>>>   ExclusiveLock            |    112
>>>   RowShareLock             |     37
>>>   AccessExclusiveLock      | 208577
>>>   RowExclusiveLock         |  33087
>>>   ShareUpdateExclusiveLock |      5
>>>   ShareLock                |  54906
>>>   AccessShareLock          |  93607
>>> (7 rows)
>>> but the slave is relative low on load.
>>>
>>> this is the connection from slave that open from May 25th
>>> postgres 14090  0.1  1.1 4512644 230760 ?      Ss   May25  59:08
>>> postgres: slony_user dbname master_ip_address(58554) idle
>>>
>>> On slave, this connection seems always keep on idle status, but on
>>> master, this connection often in "<IDLE> in transaction" status for some
>>> minutes and hold lock on sl_log_2 while transaction are filling up
>>> sl_log_1.
>>>
>>> Such condition usually happen on server high load time, but on low load
>>> it sometimes happen, but not many and does not affect on replication lag.
>>>
>>> On Wed, Jul 2, 2014 at 12:37 AM, Steve Singer <ssinger at ca.afilias.info
>>> <mailto:ssinger at ca.afilias.info>> wrote:
>>>
>>>     On 06/30/2014 01:05 PM, Soni M wrote:
>>>
>>>         it seems a slony process that has <IDLE> in transaction for many
>>>         times.
>>>         the client address and the user are identical to slony slave.
>>>
>>>
>>>
>>>     Which version of slony are you on?
>>>
>>>
>>>
>>>
>>>
>>> --
>>> Regards,
>>>
>>> Soni Maula Harriz
>>>
>>
>>
>
>
> --
> Regards,
>
> Soni Maula Harriz
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20140708/52223a67/attachment.htm 

From ssinger at ca.afilias.info  Wed Jul  9 19:40:45 2014
From: ssinger at ca.afilias.info (Steve Singer)
Date: Wed, 09 Jul 2014 22:40:45 -0400
Subject: [Slony1-general] manually delete sl_log_x table
In-Reply-To: <CAGBW59cga+1Qj=MmRY00N5QSakokHs1KEFk12ZH=_O9JBUpnZg@mail.gmail.com>
References: <CAAMgDX=KUx8Hty2WJXARWSTtKsnKP2Je=f0VVVcP8hwZyaAuHA@mail.gmail.com>	<53AAE50E.7030101@ca.afilias.info>	<CAAMgDXmMB9gJrxgVuBRnvKMewShy2xiV0kygE2Rv+0JK9pLPrA@mail.gmail.com>	<53AAE9CC.6020706@ca.afilias.info>	<CAAMgDXnpdJYESt3zBpVi8tCe-qJgXSM+e=7xiQXzUxKTDwz9kQ@mail.gmail.com>	<53AB741F.907@ca.afilias.info>	<CAAMgDXmWR_pNdm1cwmXy+TWKnitPki+A_S1gKxfsnpzmz1gKFw@mail.gmail.com>	<CAAMgDX=dXYbK_5X+7wbapx-=Kc8cH9b+VjX7Jc6XcPZDqL4iHQ@mail.gmail.com>	<53B2F1DD.9000400@ca.afilias.info>	<CAAMgDXkuAUo-96hamWtE_DiBEbkG1=0OUA9wmovYxMb1Omheqw@mail.gmail.com>	<53B42D0E.9060603@ca.afilias.info>	<CAAMgDXneq4LxiL=WwZL8=5SKp98EX3G_VuQ0yi=_j+aPsy7H3Q@mail.gmail.com>
	<CAGBW59cga+1Qj=MmRY00N5QSakokHs1KEFk12ZH=_O9JBUpnZg@mail.gmail.com>
Message-ID: <53BDFD2D.7010402@ca.afilias.info>

On 07/08/2014 11:14 AM, Jan Wieck wrote:
> Why and what application is holding locks on the Slony log tables?
>

His application will hold locks on the sl_log tables by virtue of them 
inserting data into replicated tables.

The application performs an insert => call the log trigger => inserts 
into sl_log_X which will aquire a non exclusive lock for the duration of 
the transaction.

You can't tell from sl_log if the 'log trigger' got the lock or if the 
application directly used the log tables.

My reading of the code in logswitch_finish for current_status=3 is that 
it tries to get the exclusive lock before determining if the table is 
empty or not.   Does this mean if the slon remoteHelper thread is 
pulling data from the log tables (since with log state=3 it queries both 
tables) it will stop the logswitch from going ahead?



> Jan
>
> --
> Jan Wieck
> Senior Software Engineer
> http://slony.info
>
> On Jul 8, 2014 11:06 AM, "Soni M" <diptatapa at gmail.com
> <mailto:diptatapa at gmail.com>> wrote:
>
>     Sorry for late response,
>     currently :
>     NOTICE:  Slony-I: could not lock sl_log_1 - sl_log_1 not truncated
>     dbname=# select last_value from sl_log_status;
>       last_value
>     ------------
>                3
>     (1 row)
>
>     That's what it should be, right?
>
>     But now, i see application transaction holding locks on sl_log_1,
>     some select, insert and update transaction and also the <IDLE> in
>     transaction just like before. But the row numbers of sl_log_1 not
>     increasing anyway. The row num is increasing in sl_log_2. Is that
>     normal?
>
>     The bug on 2.0.x as You said does happen in our environment, and it
>     happens when the slave falls further behind the master. I should
>     plan to move to 2.1 or 2.2.
>
>
>
>     On Wed, Jul 2, 2014 at 11:02 PM, Steve Singer
>     <ssinger at ca.afilias.info <mailto:ssinger at ca.afilias.info>> wrote:
>
>         On 07/01/2014 08:24 PM, Soni M wrote:
>
>
>             Master : Ubuntu 10.04 LTS, Postgre 9.1.13, Slony 2.0.7 from
>             Ubuntu Package
>             Slave : Ubuntu 10.04 LTS, Postgres 9.1.13, Slony 2.0.7 seems
>             build from
>
>
>
>         I should also point out that slony 2.0.x does not properly
>         support PG 9.1 or higher.  You should use slony 2.1.x or 2.2.x
>         with PG 9.1+.
>
>         If you are seeing a lot of transactions being aborted due to
>         serialization conflicts then this is because of the issues with
>         PG 9.1 and slony 2.0 (though it doesn't sound like that is
>         causing this particular issue)
>
>
>
>             source.
>             DB size 1.5 TB, Master utilize relative high number of temp
>             tables and
>             relative High number of locks on busy time
>
>             DB=# select mode, count(*) from pg_locks group by mode;
>                          mode           | count
>             --------------------------+---__-----
>                ExclusiveLock            |    112
>                RowShareLock             |     37
>                AccessExclusiveLock      | 208577
>                RowExclusiveLock         |  33087
>                ShareUpdateExclusiveLock |      5
>                ShareLock                |  54906
>                AccessShareLock          |  93607
>             (7 rows)
>             but the slave is relative low on load.
>
>             this is the connection from slave that open from May 25th
>             postgres 14090  0.1  1.1 4512644 230760 ?      Ss   May25  59:08
>             postgres: slony_user dbname master_ip_address(58554) idle
>
>             On slave, this connection seems always keep on idle status,
>             but on
>             master, this connection often in "<IDLE> in transaction"
>             status for some
>             minutes and hold lock on sl_log_2 while transaction are
>             filling up sl_log_1.
>
>             Such condition usually happen on server high load time, but
>             on low load
>             it sometimes happen, but not many and does not affect on
>             replication lag.
>
>             On Wed, Jul 2, 2014 at 12:37 AM, Steve Singer
>             <ssinger at ca.afilias.info <mailto:ssinger at ca.afilias.info>
>             <mailto:ssinger at ca.afilias.__info
>             <mailto:ssinger at ca.afilias.info>>> wrote:
>
>                  On 06/30/2014 01:05 PM, Soni M wrote:
>
>                      it seems a slony process that has <IDLE> in
>             transaction for many
>                      times.
>                      the client address and the user are identical to
>             slony slave.
>
>
>
>                  Which version of slony are you on?
>
>
>
>
>
>             --
>             Regards,
>
>             Soni Maula Harriz
>
>
>
>
>
>     --
>     Regards,
>
>     Soni Maula Harriz
>
>     _______________________________________________
>     Slony1-general mailing list
>     Slony1-general at lists.slony.info <mailto:Slony1-general at lists.slony.info>
>     http://lists.slony.info/mailman/listinfo/slony1-general
>


From ssinger at ca.afilias.info  Wed Jul  9 19:43:22 2014
From: ssinger at ca.afilias.info (Steve Singer)
Date: Wed, 09 Jul 2014 22:43:22 -0400
Subject: [Slony1-general] manually delete sl_log_x table
In-Reply-To: <CAAMgDXneq4LxiL=WwZL8=5SKp98EX3G_VuQ0yi=_j+aPsy7H3Q@mail.gmail.com>
References: <CAAMgDX=KUx8Hty2WJXARWSTtKsnKP2Je=f0VVVcP8hwZyaAuHA@mail.gmail.com>	<53AAE50E.7030101@ca.afilias.info>	<CAAMgDXmMB9gJrxgVuBRnvKMewShy2xiV0kygE2Rv+0JK9pLPrA@mail.gmail.com>	<53AAE9CC.6020706@ca.afilias.info>	<CAAMgDXnpdJYESt3zBpVi8tCe-qJgXSM+e=7xiQXzUxKTDwz9kQ@mail.gmail.com>	<53AB741F.907@ca.afilias.info>	<CAAMgDXmWR_pNdm1cwmXy+TWKnitPki+A_S1gKxfsnpzmz1gKFw@mail.gmail.com>	<CAAMgDX=dXYbK_5X+7wbapx-=Kc8cH9b+VjX7Jc6XcPZDqL4iHQ@mail.gmail.com>	<53B2F1DD.9000400@ca.afilias.info>	<CAAMgDXkuAUo-96hamWtE_DiBEbkG1=0OUA9wmovYxMb1Omheqw@mail.gmail.com>	<53B42D0E.9060603@ca.afilias.info>
	<CAAMgDXneq4LxiL=WwZL8=5SKp98EX3G_VuQ0yi=_j+aPsy7H3Q@mail.gmail.com>
Message-ID: <53BDFDCA.7020309@ca.afilias.info>

On 07/08/2014 11:06 AM, Soni M wrote:
> Sorry for late response,
> currently :
> NOTICE:  Slony-I: could not lock sl_log_1 - sl_log_1 not truncated
> dbname=# select last_value from sl_log_status;
>   last_value
> ------------
>            3
> (1 row)
>
> That's what it should be, right?
>
> But now, i see application transaction holding locks on sl_log_1, some
> select, insert and update transaction and also the <IDLE> in transaction
> just like before. But the row numbers of sl_log_1 not increasing anyway.
> The row num is increasing in sl_log_2. Is that normal?
>

Yes in log switch state 3 new rows get inserted into sl_log_2, and the 
slon tries to pull data from both tables.  When all the rows in sl_log_1 
have been replicated (and slon can get that exclusive lock) it truncates 
sl_log_1 and switches the log status to 1.


> The bug on 2.0.x as You said does happen in our environment, and it
> happens when the slave falls further behind the master. I should plan to
> move to 2.1 or 2.2.

I recommend 2.2


>
>
>
> On Wed, Jul 2, 2014 at 11:02 PM, Steve Singer <ssinger at ca.afilias.info
> <mailto:ssinger at ca.afilias.info>> wrote:
>
>     On 07/01/2014 08:24 PM, Soni M wrote:
>
>
>         Master : Ubuntu 10.04 LTS, Postgre 9.1.13, Slony 2.0.7 from
>         Ubuntu Package
>         Slave : Ubuntu 10.04 LTS, Postgres 9.1.13, Slony 2.0.7 seems
>         build from
>
>
>
>     I should also point out that slony 2.0.x does not properly support
>     PG 9.1 or higher.  You should use slony 2.1.x or 2.2.x with PG 9.1+.
>
>     If you are seeing a lot of transactions being aborted due to
>     serialization conflicts then this is because of the issues with PG
>     9.1 and slony 2.0 (though it doesn't sound like that is causing this
>     particular issue)
>
>
>
>         source.
>         DB size 1.5 TB, Master utilize relative high number of temp
>         tables and
>         relative High number of locks on busy time
>
>         DB=# select mode, count(*) from pg_locks group by mode;
>                      mode           | count
>         --------------------------+---__-----
>            ExclusiveLock            |    112
>            RowShareLock             |     37
>            AccessExclusiveLock      | 208577
>            RowExclusiveLock         |  33087
>            ShareUpdateExclusiveLock |      5
>            ShareLock                |  54906
>            AccessShareLock          |  93607
>         (7 rows)
>         but the slave is relative low on load.
>
>         this is the connection from slave that open from May 25th
>         postgres 14090  0.1  1.1 4512644 230760 ?      Ss   May25  59:08
>         postgres: slony_user dbname master_ip_address(58554) idle
>
>         On slave, this connection seems always keep on idle status, but on
>         master, this connection often in "<IDLE> in transaction" status
>         for some
>         minutes and hold lock on sl_log_2 while transaction are filling
>         up sl_log_1.
>
>         Such condition usually happen on server high load time, but on
>         low load
>         it sometimes happen, but not many and does not affect on
>         replication lag.
>
>         On Wed, Jul 2, 2014 at 12:37 AM, Steve Singer
>         <ssinger at ca.afilias.info <mailto:ssinger at ca.afilias.info>
>         <mailto:ssinger at ca.afilias.__info
>         <mailto:ssinger at ca.afilias.info>>> wrote:
>
>              On 06/30/2014 01:05 PM, Soni M wrote:
>
>                  it seems a slony process that has <IDLE> in transaction
>         for many
>                  times.
>                  the client address and the user are identical to slony
>         slave.
>
>
>
>              Which version of slony are you on?
>
>
>
>
>
>         --
>         Regards,
>
>         Soni Maula Harriz
>
>
>
>
>
> --
> Regards,
>
> Soni Maula Harriz


From davecramer at gmail.com  Mon Jul 14 06:16:21 2014
From: davecramer at gmail.com (Dave Cramer)
Date: Mon, 14 Jul 2014 09:16:21 -0400
Subject: [Slony1-general] Slony over very long distances
Message-ID: <CADK3HHK0MFTyYZ05LZkivg4yJDLOEEx_DYA9FEABb+V-17CAmg@mail.gmail.com>

How well does this work. Does anyone have some real world experience with
this ?


Dave Cramer
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20140714/2fea9384/attachment.html 

From ajs at crankycanuck.ca  Mon Jul 14 06:29:57 2014
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Mon, 14 Jul 2014 09:29:57 -0400
Subject: [Slony1-general] Slony over very long distances
In-Reply-To: <CADK3HHK0MFTyYZ05LZkivg4yJDLOEEx_DYA9FEABb+V-17CAmg@mail.gmail.com>
References: <CADK3HHK0MFTyYZ05LZkivg4yJDLOEEx_DYA9FEABb+V-17CAmg@mail.gmail.com>
Message-ID: <A6D9C59F-F1F7-4CB1-A008-4C1E24B8ED61@crankycanuck.ca>

I don't think "distance" is the problem.  "High rtt links" might be one, though: you can have cases where you time out or never catch up.  

-- 
Andrew Sullivan 
Please excuse my clumbsy thums. 

> On Jul 14, 2014, at 9:16, Dave Cramer <davecramer at gmail.com> wrote:
> 
> 
> How well does this work. Does anyone have some real world experience with this ?
> 
> 
> Dave Cramer
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general

From davecramer at gmail.com  Mon Jul 14 06:35:15 2014
From: davecramer at gmail.com (Dave Cramer)
Date: Mon, 14 Jul 2014 09:35:15 -0400
Subject: [Slony1-general] Slony over very long distances
In-Reply-To: <A6D9C59F-F1F7-4CB1-A008-4C1E24B8ED61@crankycanuck.ca>
References: <CADK3HHK0MFTyYZ05LZkivg4yJDLOEEx_DYA9FEABb+V-17CAmg@mail.gmail.com>
	<A6D9C59F-F1F7-4CB1-A008-4C1E24B8ED61@crankycanuck.ca>
Message-ID: <CADK3HHLSbfbaLi=XyEO3cku1M=h_ydYPbnH4CeOm4pu78i_DQQ@mail.gmail.com>

Well distance pretty much translates into high rtt. I am talking about
Toronto to Mumbai or the equivalent

Dave Cramer


On 14 July 2014 09:29, Andrew Sullivan <ajs at crankycanuck.ca> wrote:

> I don't think "distance" is the problem.  "High rtt links" might be one,
> though: you can have cases where you time out or never catch up.
>
> --
> Andrew Sullivan
> Please excuse my clumbsy thums.
>
> > On Jul 14, 2014, at 9:16, Dave Cramer <davecramer at gmail.com> wrote:
> >
> >
> > How well does this work. Does anyone have some real world experience
> with this ?
> >
> >
> > Dave Cramer
> > _______________________________________________
> > Slony1-general mailing list
> > Slony1-general at lists.slony.info
> > http://lists.slony.info/mailman/listinfo/slony1-general
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20140714/a3c560f8/attachment.htm 

From wmoran at potentialtech.com  Mon Jul 14 06:56:44 2014
From: wmoran at potentialtech.com (Bill Moran)
Date: Mon, 14 Jul 2014 09:56:44 -0400
Subject: [Slony1-general] Slony over very long distances
In-Reply-To: <CADK3HHLSbfbaLi=XyEO3cku1M=h_ydYPbnH4CeOm4pu78i_DQQ@mail.gmail.com>
References: <CADK3HHK0MFTyYZ05LZkivg4yJDLOEEx_DYA9FEABb+V-17CAmg@mail.gmail.com>
	<A6D9C59F-F1F7-4CB1-A008-4C1E24B8ED61@crankycanuck.ca>
	<CADK3HHLSbfbaLi=XyEO3cku1M=h_ydYPbnH4CeOm4pu78i_DQQ@mail.gmail.com>
Message-ID: <20140714095644.cd55c53ea64a113a1f89a95e@potentialtech.com>

On Mon, 14 Jul 2014 09:35:15 -0400 Dave Cramer <davecramer at gmail.com> wrote:

> Well distance pretty much translates into high rtt. I am talking about
> Toronto to Mumbai or the equivalent

In my previous job I was involved in lots of Slony replication across the
contenental U.S.  (From east to west coast).  The RTT was seldom a problem.
We did have difficulty occasionally when spikes of activity would back
replication up for a day or more, but these were the exceptions, not the
rule, and they almost always recovered.

That only gives you so much info, though.  Your success/failure is going
to be a factor of how much replication traffic you actually generate, what
kind of actual bandwidth you're able to secure between your two sites, and
how much you can tolerate occasional replication lag if there are spikes of
activity or network problems.

> Dave Cramer
> 
> 
> On 14 July 2014 09:29, Andrew Sullivan <ajs at crankycanuck.ca> wrote:
> 
> > I don't think "distance" is the problem.  "High rtt links" might be one,
> > though: you can have cases where you time out or never catch up.
> >
> > --
> > Andrew Sullivan
> > Please excuse my clumbsy thums.
> >
> > > On Jul 14, 2014, at 9:16, Dave Cramer <davecramer at gmail.com> wrote:
> > >
> > >
> > > How well does this work. Does anyone have some real world experience
> > with this ?
> > >
> > >
> > > Dave Cramer
> > > _______________________________________________
> > > Slony1-general mailing list
> > > Slony1-general at lists.slony.info
> > > http://lists.slony.info/mailman/listinfo/slony1-general
> >


-- 
Bill Moran <wmoran at potentialtech.com>

From jan at wi3ck.info  Mon Jul 14 07:45:25 2014
From: jan at wi3ck.info (Jan Wieck)
Date: Mon, 14 Jul 2014 10:45:25 -0400
Subject: [Slony1-general] Slony over very long distances
In-Reply-To: <CADK3HHLSbfbaLi=XyEO3cku1M=h_ydYPbnH4CeOm4pu78i_DQQ@mail.gmail.com>
References: <CADK3HHK0MFTyYZ05LZkivg4yJDLOEEx_DYA9FEABb+V-17CAmg@mail.gmail.com>	<A6D9C59F-F1F7-4CB1-A008-4C1E24B8ED61@crankycanuck.ca>
	<CADK3HHLSbfbaLi=XyEO3cku1M=h_ydYPbnH4CeOm4pu78i_DQQ@mail.gmail.com>
Message-ID: <53C3ED05.1020206@wi3ck.info>

On 07/14/14 09:35, Dave Cramer wrote:
> Well distance pretty much translates into high rtt. I am talking about
> Toronto to Mumbai or the equivalent

There was a substantial change in communication in version 2.2 where the 
data is pulled via the COPY protocol now as opposed to using a cursor 
and small FETCH operations. This reduces the number of round trips 
required especially when there is a backlog and the system starts 
grouping events together.

You can relatively easy reproduce a WAN scenario in the laboratory using 
WANem, whe Wide Area Network Emulator.

http://wanem.sourceforge.net/

The thing comes as a Knoppix image that is rather easy to set up in a 
virtual machine and use as a router between vlans. You can impose 
bandwidth limits, packet delay (round trip), packet loss, packet 
corruption, packet duplication, packet reordering, idle disconnects, 
random disconnects ... you get the picture.

In my tests a cluster based on 2.2 is mostly affected by bandwidth and 
packet loss due to the delays that can introduce, leading to unused 
bandwidth. High round trip times (delay) are not much of an issue.


Regards,
Jan




>
> Dave Cramer
>
>
> On 14 July 2014 09:29, Andrew Sullivan <ajs at crankycanuck.ca
> <mailto:ajs at crankycanuck.ca>> wrote:
>
>     I don't think "distance" is the problem.  "High rtt links" might be
>     one, though: you can have cases where you time out or never catch up.
>
>     --
>     Andrew Sullivan
>     Please excuse my clumbsy thums.
>
>      > On Jul 14, 2014, at 9:16, Dave Cramer <davecramer at gmail.com
>     <mailto:davecramer at gmail.com>> wrote:
>      >
>      >
>      > How well does this work. Does anyone have some real world
>     experience with this ?
>      >
>      >
>      > Dave Cramer
>      > _______________________________________________
>      > Slony1-general mailing list
>      > Slony1-general at lists.slony.info
>     <mailto:Slony1-general at lists.slony.info>
>      > http://lists.slony.info/mailman/listinfo/slony1-general
>
>
>
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>


-- 
Jan Wieck
Senior Software Engineer
http://slony.info

From cbbrowne at afilias.info  Mon Jul 14 08:03:33 2014
From: cbbrowne at afilias.info (Christopher Browne)
Date: Mon, 14 Jul 2014 11:03:33 -0400
Subject: [Slony1-general] Slony over very long distances
In-Reply-To: <CADK3HHK0MFTyYZ05LZkivg4yJDLOEEx_DYA9FEABb+V-17CAmg@mail.gmail.com>
References: <CADK3HHK0MFTyYZ05LZkivg4yJDLOEEx_DYA9FEABb+V-17CAmg@mail.gmail.com>
Message-ID: <CANfbgba=MdSMUWzEZ9Pqso2W3nZxZfQ+j7ofAb-vyvbg47hyLQ@mail.gmail.com>

We have had the Asia-to-North-America case; it was fine, so long as we had
sufficient bandwidth.

Latency wasn't great, but Slony actually copes with that quite well.

I think we had more troubles with reliability of links (e.g. - they were
passing through enough intermediaries that occasionally connections would
get deranged) than anything else.

Pre-2.2, it was crucially important for the slon servicing each node to be
local, otherwise the round trip times between slon and database would be
troublesome.  The shift to using streaming (e.g. - copying sl_log_{1,2}
around via COPY)  gets rid of that particular round trip issue.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20140714/d57b9ebd/attachment.htm 


From ssinger at ca.afilias.info  Wed Nov  2 07:30:21 2011
From: ssinger at ca.afilias.info (Steve Singer)
Date: Wed, 02 Nov 2011 10:30:21 -0400
Subject: [Slony1-general] Trouble installing Slony on Solaris
In-Reply-To: <1320056223.11405.YahooMailNeo@web121218.mail.ne1.yahoo.com>
References: <1320056223.11405.YahooMailNeo@web121218.mail.ne1.yahoo.com>
Message-ID: <4EB153FD.7020306@ca.afilias.info>

On 11-10-31 06:17 AM, Venkat Nag wrote:
> Hello Everyone,
>
> This is my first post to the Slony Community.
>
> Can someone please help me get a Slony build for Sun Solaris ?
>

What issues are you encountering?

I think I was successfully  able to build recent slony 2.0.7 versions on 
Solaris with both gcc and the sun compiler.



> Thanks
> VBN
>
>
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


From wernergiam at yahoo.com  Wed Nov  2 15:59:07 2011
From: wernergiam at yahoo.com (chern wei giam)
Date: Wed, 2 Nov 2011 15:59:07 -0700 (PDT)
Subject: [Slony1-general] (no subject)
Message-ID: <1320274747.69887.yint-ygo-j2me@web110501.mail.gq1.yahoo.com>

http://ahlussunnah.cl/group/protect/markehjf.htm

From vitaliy.se at gmail.com  Mon Nov  7 13:54:45 2011
From: vitaliy.se at gmail.com (Vitaliy Semochkin)
Date: Tue, 8 Nov 2011 00:54:45 +0300
Subject: [Slony1-general] continue replication in after connection problem
	with slony
Message-ID: <CAHyKpfNs3bx524=GQE=fRq3qcSQrhyr6feiL60Fjs4DH=DCMCA@mail.gmail.com>

Hello,

I have 2 postgresql servers, ONE is used for read and write
operations, while the OTHER is used for read only operations.

I want all updates for several tables on  ONE to be transferred to the OTHER.
In case the ONE or the OTHER goes off line or there is a connection
problems, I want those updates to be transferred as soon as server
goes on line.

Is it possible to perform such replication using Slony?
If it is so, where to dig? ;-)

Thanks in Advance,
Vitaliy S

From vitaliy.se at gmail.com  Mon Nov  7 13:57:10 2011
From: vitaliy.se at gmail.com (Vitaliy Semochkin)
Date: Tue, 8 Nov 2011 00:57:10 +0300
Subject: [Slony1-general] continue replication in after connection problem
 with slony (sorry, if I duplicated the question)
Message-ID: <CAHyKpfNntvfm9PVeeTu9f1h1LNqyD1y7_R9eXT5SsFPHSs87LQ@mail.gmail.com>

Hello,

I have 2 postgresql servers, ONE is used for read and write
operations, while the OTHER is used for read only operations.

I want all updates for several tables on  ONE to be transferred to the OTHER.
In case the ONE or the OTHER goes off line or there is a connection
problems, I want those updates to be transferred as soon as server
goes on line.

Is it possible to perform such replication using Slony?
If it is so, where to dig? ;-)

Thanks in Advance,
Vitaliy S

From cbbrowne at afilias.info  Mon Nov  7 14:24:37 2011
From: cbbrowne at afilias.info (Christopher Browne)
Date: Mon, 7 Nov 2011 17:24:37 -0500
Subject: [Slony1-general] continue replication in after connection
 problem with slony (sorry, if I duplicated the question)
In-Reply-To: <CAHyKpfNntvfm9PVeeTu9f1h1LNqyD1y7_R9eXT5SsFPHSs87LQ@mail.gmail.com>
References: <CAHyKpfNntvfm9PVeeTu9f1h1LNqyD1y7_R9eXT5SsFPHSs87LQ@mail.gmail.com>
Message-ID: <CANfbgbb4CurPTdmtWUoYyzvmv9iXJnquD7GJXsniQpd=kVwBbw@mail.gmail.com>

On Mon, Nov 7, 2011 at 4:57 PM, Vitaliy Semochkin <vitaliy.se at gmail.com> wrote:
> Hello,
>
> I have 2 postgresql servers, ONE is used for read and write
> operations, while the OTHER is used for read only operations.
>
> I want all updates for several tables on ?ONE to be transferred to the OTHER.
> In case the ONE or the OTHER goes off line or there is a connection
> problems, I want those updates to be transferred as soon as server
> goes on line.
>
> Is it possible to perform such replication using Slony?
> If it is so, where to dig? ;-)

Well, what Slony does sounds somewhat like an interpretation of this...

Supposing there are two servers:
 - Node #1, used for read and write, which is defined as the origin
 - Node #2, used only for read access, defined as subscriber/replica

That's a very standard Slony configuration.

If node #1 goes down, then there are two choices:

a) Wait until it comes back.  (e.g. - if the problem is a minor one).

In that case, updates will be transferred from #1 (origin) to #2
(subscriber) as soon as node #1 comes back on line.  (It may be
necessary to restart a slon process too; if it has some sort of
watchdog watching it, that's easy to make happen.  There's a script
for that...)

b) Give up on node #1 (e.g. - if the problem is a major one).

In that case, you need to submit a FAILOVER script (using
slony.info/documentation/2.1/stmtfailover.html) to turn node #2 into
the origin node.

At that point, node #1 is to be treated as destroyed.

There is no c)  :-)

Slony doesn't try to provide multimaster replication; while there are
ways of having *some* traffic going in both directions between nodes,
that needs to involve mutually disjoint sets of tables.

If case a) describes what you're thinking of, then Slony does what you
want.  If you're thinking of a "case c)," then perhaps not so much.

From vbnpg at yahoo.com  Tue Nov  8 03:01:52 2011
From: vbnpg at yahoo.com (Venkat Nag)
Date: Tue, 8 Nov 2011 03:01:52 -0800 (PST)
Subject: [Slony1-general] Trouble installing Slony on Solaris
In-Reply-To: <4EB153FD.7020306@ca.afilias.info>
References: <1320056223.11405.YahooMailNeo@web121218.mail.ne1.yahoo.com>
	<4EB153FD.7020306@ca.afilias.info>
Message-ID: <1320750112.38401.YahooMailNeo@web121214.mail.ne1.yahoo.com>

Hi Steven,

Thanks for the reply !

I faced issues in installing Slony on Solaris.

I tried compiling Slony binaries with Postgres binaries and was able to install it.

Thanks
VB


________________________________
From: Steve Singer <ssinger at ca.afilias.info>
To: Venkat Nag <vbnpg at yahoo.com>
Cc: "slony1-general at lists.slony.info" <slony1-general at lists.slony.info>
Sent: Wednesday, November 2, 2011 8:00 PM
Subject: Re: [Slony1-general] Trouble installing Slony on Solaris

On 11-10-31 06:17 AM, Venkat Nag wrote:
> Hello Everyone,
>
> This is my first post to the Slony Community.
>
> Can someone please help me get a Slony build for Sun Solaris ?
>

What issues are you encountering?

I think I was successfully? able to build recent slony 2.0.7 versions on 
Solaris with both gcc and the sun compiler.



> Thanks
> VBN
>
>
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20111108/2af4c338/attachment.htm 

From vivek at khera.org  Tue Nov  8 08:05:02 2011
From: vivek at khera.org (Vick Khera)
Date: Tue, 8 Nov 2011 11:05:02 -0500
Subject: [Slony1-general] continue replication in after connection
 problem with slony
In-Reply-To: <CAHyKpfNs3bx524=GQE=fRq3qcSQrhyr6feiL60Fjs4DH=DCMCA@mail.gmail.com>
References: <CAHyKpfNs3bx524=GQE=fRq3qcSQrhyr6feiL60Fjs4DH=DCMCA@mail.gmail.com>
Message-ID: <CALd+dcd1sbad8qHqZT=yORU6TuT_DZQQeUqH31zCarNh7TEjhw@mail.gmail.com>

On Mon, Nov 7, 2011 at 4:54 PM, Vitaliy Semochkin <vitaliy.se at gmail.com> wrote:
> Is it possible to perform such replication using Slony?
> If it is so, where to dig? ;-)
>

That's how slony works out of the box.  The only issue you may have is
if there is a slow WAN link between the servers, and you have lots and
lots of updates.  If there is a significant time of disconnection
between the two, the backlog of change may be too great to apply.
Sometimes it is faster to start from scratch in those situations.

From l.rame at griensu.com  Tue Nov  8 12:21:02 2011
From: l.rame at griensu.com (Leonardo =?iso-8859-1?Q?M=2E_Ram=E9?=)
Date: Tue, 8 Nov 2011 17:21:02 -0300
Subject: [Slony1-general] New user question
Message-ID: <20111108202102.GB7215@leonardo-laptop.router31ff80.com>

Hi, we have one application connected to a local PostgreSql server and
we are facing the need to allow a remote site's users to use the
application. As a point-to-point connection is really expensive, we're
looking for other solutions, like replication.

On each site ~25 clients are connected to the server doing reads and
writes, and we would like to synchronize both servers, so, for example
if a new record is added on Site1, in about 15minutes, that record must
appear on Site2, and viceversa.

Is this possible with Slony-I?.

Thanks in advance,
-- 
Leonardo M. Ram?
Medical IT - Griensu S.A.
Av. Col?n 636 - Piso 8 Of. A
X5000EPT -- C?rdoba
Tel.: +54(351)4246924 +54(351)4247788 +54(351)4247979 int. 19
Cel.: +54(351)156629292


From cbbrowne at afilias.info  Tue Nov  8 14:18:29 2011
From: cbbrowne at afilias.info (Christopher Browne)
Date: Tue, 8 Nov 2011 17:18:29 -0500
Subject: [Slony1-general] New user question
In-Reply-To: <20111108202102.GB7215@leonardo-laptop.router31ff80.com>
References: <20111108202102.GB7215@leonardo-laptop.router31ff80.com>
Message-ID: <CANfbgbamuyfFj6gTZPM+diA1YZbuR_Y+qBJ+xgfbFF4OOvSR-A@mail.gmail.com>

On Tue, Nov 8, 2011 at 3:21 PM, Leonardo M. Ram? <l.rame at griensu.com> wrote:
> Hi, we have one application connected to a local PostgreSql server and
> we are facing the need to allow a remote site's users to use the
> application. As a point-to-point connection is really expensive, we're
> looking for other solutions, like replication.
>
> On each site ~25 clients are connected to the server doing reads and
> writes, and we would like to synchronize both servers, so, for example
> if a new record is added on Site1, in about 15minutes, that record must
> appear on Site2, and viceversa.
>
> Is this possible with Slony-I?.

Unfortunately, the "vice versa" part is not possible.

Slony-I is a *single* master to multiple subscribers replication
system; it does not try to address the multimaster problem.

What reasonably works is for site #1 to be the "master," and for that
data to appear reasonably quickly at site #2.

There are ways of approximating multimaster replication with Slony-I,
but it quickly gets pretty involved, and you need to effectively
design that into your application.

From mfwilson at gmail.com  Wed Nov  9 10:19:41 2011
From: mfwilson at gmail.com (Mike Wilson)
Date: Wed, 9 Nov 2011 10:19:41 -0800
Subject: [Slony1-general] fetch 500 from LOG
Message-ID: <5123FC12-8F82-49E7-AEC5-29BAE65C758F@gmail.com>

Seeing "fetch 500 from LOG" almost continuously in my PG logs for a new Slony 2.0.7 install.  The previous version (2.0.3?) didn't show these messages in the PG log.  Researching the issue, historically, this message was usually accompanied by a performance issue.  This isn't the case with my databases though, they appear to be running just as well as ever and the lag between replicated nodes appears to be about the same as the previous version.

I guess my question is what does this message mean in this version of Slony?  Is it an indication of sub-optimal slon parameters?
slon -g 20 $SLON_CLUSTER "host=$HOSTNAME port=$PORT dbname=$DB user=$USER"

And how can I get rid of it if it's not an issue?    

Mike 






From l.rame at griensu.com  Wed Nov  9 11:09:12 2011
From: l.rame at griensu.com (Leonardo =?iso-8859-1?Q?M=2E_Ram=E9?=)
Date: Wed, 9 Nov 2011 16:09:12 -0300
Subject: [Slony1-general] New user question
In-Reply-To: <CANfbgbamuyfFj6gTZPM+diA1YZbuR_Y+qBJ+xgfbFF4OOvSR-A@mail.gmail.com>
References: <20111108202102.GB7215@leonardo-laptop.router31ff80.com>
	<CANfbgbamuyfFj6gTZPM+diA1YZbuR_Y+qBJ+xgfbFF4OOvSR-A@mail.gmail.com>
Message-ID: <20111109190912.GA2979@leonardo-laptop>

On 2011-11-08 17:18:29 -0500, Christopher Browne wrote:
> On Tue, Nov 8, 2011 at 3:21 PM, Leonardo M. Ram? <l.rame at griensu.com> wrote:
> > Hi, we have one application connected to a local PostgreSql server and
> > we are facing the need to allow a remote site's users to use the
> > application. As a point-to-point connection is really expensive, we're
> > looking for other solutions, like replication.
> >
> > On each site ~25 clients are connected to the server doing reads and
> > writes, and we would like to synchronize both servers, so, for example
> > if a new record is added on Site1, in about 15minutes, that record must
> > appear on Site2, and viceversa.
> >
> > Is this possible with Slony-I?.
> 
> Unfortunately, the "vice versa" part is not possible.
> 
> Slony-I is a *single* master to multiple subscribers replication
> system; it does not try to address the multimaster problem.
> 
> What reasonably works is for site #1 to be the "master," and for that
> data to appear reasonably quickly at site #2.
> 
> There are ways of approximating multimaster replication with Slony-I,
> but it quickly gets pretty involved, and you need to effectively
> design that into your application.

Thanks Christopher, I didn't know the types of replication. Now I'm sure
I need multiple-master replication, knowing this I'll take a look at
Burcado.

-- 
Leonardo M. Ram?
Medical IT - Griensu S.A.
Av. Col?n 636 - Piso 8 Of. A
X5000EPT -- C?rdoba
Tel.: +54(351)4246924 +54(351)4247788 +54(351)4247979 int. 19
Cel.: +54(351)156629292


From cbbrowne at afilias.info  Wed Nov  9 15:14:25 2011
From: cbbrowne at afilias.info (Christopher Browne)
Date: Wed, 9 Nov 2011 18:14:25 -0500
Subject: [Slony1-general] Revision to DDL handling
Message-ID: <CANfbgbYTgrAq4S8GuEf=pqZdNK8phdpJB3L2T_7VDYC7L5FeMA@mail.gmail.com>

I have gotten around to poking at fairly old bug #137
<http://www.slony.info/bugzilla/show_bug.cgi?id=137>, which heads
towards a quite different implementation of DDL handling in Slony-I
version 2.2.

Where, in 2.0 and 2.1, the process of applying DDL looked like:

 - Start running a DDL event
    - Take the list of SQL statements out of the event, splitting them
into individual queries
    - For each query
      - Run the query

With some vagueness as to what happens if update activity is being
logged concurrently in sl_log_{1,2}.  (I'm not sure whether the
updates are applied *before* or *after* the DDL; neither is
necessarily the right answer!)

In 2.2, we add a new table, sl_log_script, which is used to capture
the SQL statements with exactly the same transaction and ordering
information used to control ordering of log application of log data in
sl_log_{1,2}.

This changes the semantics a bit, but, we think, in a pretty well
unambiguously better way.

It actually makes it easier to do DDL handling; we have a wrapper
function, ddlCapture(), which drops the DDL into the new table.  A
clever administrator might use exactly the same function to run their
own favorite bit of DDL and have it run exactly as it would have been
had they used slonik EXECUTE SCRIPT.

There is a change to EXECUTE SCRIPT; it becomes rather more meaningful
to use the EXECUTE ONLY ON option, and to have that be a list of
nodes, rather than just a single node.

And here's where a question opens...

The way I have initially implemented the new form of EXECUTE SCRIPT is
to request a specific list of nodes.

Thus:

EXECUTE SCRIPT (set id=1, filename='/tmp/my-ddl-script.sql', event
node=2, execute only on = '2,3,4');

My colleagues have suggested that perhaps we'd like to have the option
of a script running only on the subscribers to a single set.

I imagine this might be handled via a syntax like:
    EXECUTE SCRIPT (set id=1, filename='/tmp/my-ddl-script.sql', event
node=2, execute only on = set nodes);

But I also imagine that this may be overkill.  Creating a syntax
specifically for the case of running just on a certain set's nodes may
be adding a complication that no one really cares to use.

Does anyone feel strongly about this?  If not, then my inclination is
to have just two behaviours:
  a) Run the script on ALL nodes, as a default behaviour
  b) Run on a specified list of nodes, e.g. - EXECUTE ONLY ON='2,3,4'

If anyone badly wants an option c), I'd appreciate hearing so.

Though I'm ready to argue "but if you don't know what your set of
nodes are, I think you're in deep, deep trouble..."

From brianf at consistentstate.com  Wed Nov  9 16:49:08 2011
From: brianf at consistentstate.com (Brian Fehrle)
Date: Wed, 09 Nov 2011 17:49:08 -0700
Subject: [Slony1-general] Upgrade from 1.2 to 2.1 questions.
Message-ID: <4EBB1F84.1010904@consistentstate.com>

Hi all, I have a few questions about upgrading to a newer version of slony.

I have a group of systems that are on slony version 1.2.21, and postgres 
8.4. We'd like to upgrade to the latest slony release, 2.1.0.

First question, has slony 2.1.0 shown to be stable and work well for 
everyone? Would it be smarter to go with the latest of 2.0 series before 
jumping on 2.1, or is 2.1 less of a 'major release' type that I may be 
thinking it is?

Also, upgrading from 1.2.21 straight to 2.1, I see via this page 
(http://slony.info/documentation/2.1/slonyupgrade.html) it seems to 
suggest going the path of just dropping every node from the slony 
cluster, installing the new binaries, then setting it up again from 
scratch on the new version. Is this the best / most suggested upgrade 
path, and is upgrading from 1.2 to 2.1 such a major change that it's 
just not recommended to try to migrate an existing cluster? (it's pretty 
much answered in that page, but would like any other opinions from 
anyone who may have upgraded already).


These seem to be more of opinion based questions, what do you all think?

Thanks in advance,
- Brian F

From brianf at consistentstate.com  Wed Nov  9 17:07:09 2011
From: brianf at consistentstate.com (Brian Fehrle)
Date: Wed, 09 Nov 2011 18:07:09 -0700
Subject: [Slony1-general] Materialized view on replicated tables.
Message-ID: <4EBB23BD.1020804@consistentstate.com>

Hi all,

I've been testing the theory of having a materialized view set up to be 
on two replicated tables in slony. The purpose of the materialized view 
is to replace a standard view that is just dog slow. I got my test 
system working with a few hitches, and would like any feedback / 
thoughts / warnings to see if this is a bad idea to do in the first place.

First off, I'm currently testing in slony version 1.2.21 on postgres 
8.3, but the hope would to be eventually on slony 2.1 and postgres 8.4, 
so anything I do would hopefully be compatable with that setup also.

So in my test environment I set up two base tables, a users table and a 
services table. The users table has a column that is a foreign key 
linked to the services table. I then created a view table that retrieves 
two columns from each table, with a join on that foreign key. I then set 
up 3 separate triggers on the 'users' table that modify all data in my 
view table on any INSERTS, UPDATES, and DELETES.

I set up the DDL for these three tables, including the functions and 
triggers, on two boxes. I then set up a slony cluster on the two 
machines, designating one as the master, and one as the slave. he moment 
I start the two slon daemons, and the initial copy happens to bring the 
slave up to date to the master, the 3 triggers I created on the slave 
table are removed. These triggers are not removed on the slony master, 
but only the slave.

First question, is there a way to not let this happen. I know newer 
versions of slony have an OMIT COPY, but does that also apply to 
removing triggers too? If so, I would still need to get the slave table 
up to date with the master anyways, a whole different issue.

So after this happened, I re-applied my triggers to the slave table, and 
started inserting/updating/deleting data on the master. In this test 
that I set up, the materialized view on the slave was successfully 
updated as I would hope, so everything looks good in my test.

It was mentioned in the postgres IRC that slony handles updates 
differently than I may think. I turned log_min_duration statement to 0 
on the slave so I can catch it, but I actually couldn't find it. The 
update in my test environment worked, but the real environment that this 
may be pushed to will have dozens of triggers on 9 or more tables, so my 
test may not be very handy in confirming that this will even work.

So with his, I have two more questions:
1. My test materialized view is simple, but the real one would be 
complex (9 or more tables with 3 triggers on each possibly). Are there 
any 'gotchas' or 'warnings' that would make me even rethink attempting this?

2. If I preform a switchover from the master to the slave, would the act 
of switching over cause my triggers to disappear like they did when I 
set up the cluster (I haven't had a chance to test this yet on my test 
environment). And if I do a switchover, since the slave (now master) 
view is not technically part of replication, would there be chance of it 
becoming out of sync with the tables it's a view of? Also, when the 
master becomes the slave, the hope would be that the view continues to 
be updated then the tables are updated via slony.

thanks for any thoughts / opinions on this,
- Brian F

From ssinger at ca.afilias.info  Fri Nov 11 05:07:25 2011
From: ssinger at ca.afilias.info (Steve Singer)
Date: Fri, 11 Nov 2011 08:07:25 -0500
Subject: [Slony1-general] fetch 500 from LOG
In-Reply-To: <5123FC12-8F82-49E7-AEC5-29BAE65C758F@gmail.com>
References: <5123FC12-8F82-49E7-AEC5-29BAE65C758F@gmail.com>
Message-ID: <4EBD1E0D.30308@ca.afilias.info>

On 11-11-09 01:19 PM, Mike Wilson wrote:
> Seeing "fetch 500 from LOG" almost continuously in my PG logs for a new Slony 2.0.7 install.  The previous version (2.0.3?) didn't show these messages in the PG log.  Researching the issue, historically, this message was usually accompanied by a performance issue.  This isn't the case with my databases though, they appear to be running just as well as ever and the lag between replicated nodes appears to be about the same as the previous version.
>
> I guess my question is what does this message mean in this version of Slony?  Is it an indication of sub-optimal slon parameters?
> slon -g 20 $SLON_CLUSTER "host=$HOSTNAME port=$PORT dbname=$DB user=$USER"
>
> And how can I get rid of it if it's not an issue?
>
> Mike

What is causing the 'fetch 500' statements to show up in the server log? 
Are you only logging SQL that takes longer than x milliseconds? If so 
how long are your fetch 500 statements taking?  How many rows are in 
your sl_log_1 and sl_log_2?


>
>
>
>
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


From ssinger at ca.afilias.info  Fri Nov 11 05:10:53 2011
From: ssinger at ca.afilias.info (Steve Singer)
Date: Fri, 11 Nov 2011 08:10:53 -0500
Subject: [Slony1-general] Upgrade from 1.2 to 2.1 questions.
In-Reply-To: <4EBB1F84.1010904@consistentstate.com>
References: <4EBB1F84.1010904@consistentstate.com>
Message-ID: <4EBD1EDD.50407@ca.afilias.info>

On 11-11-09 07:49 PM, Brian Fehrle wrote:
> Hi all, I have a few questions about upgrading to a newer version of slony.
>

> I have a group of systems that are on slony version 1.2.21, and postgres
> 8.4. We'd like to upgrade to the latest slony release, 2.1.0.
> Also, upgrading from 1.2.21 straight to 2.1, I see via this page
> (http://slony.info/documentation/2.1/slonyupgrade.html) it seems to
> suggest going the path of just dropping every node from the slony
> cluster, installing the new binaries, then setting it up again from
> scratch on the new version. Is this the best / most suggested upgrade
> path, and is upgrading from 1.2 to 2.1 such a major change that it's
> just not recommended to try to migrate an existing cluster? (it's pretty
> much answered in that page, but would like any other opinions from
> anyone who may have upgraded already).

The *only* option when upgrading from 1.2 to 2.x is to drop slony and 
reinstall + reconfigure it.  If the documentation implies you have some 
other option then we need to make it more clear.

>
>
> These seem to be more of opinion based questions, what do you all think?
>
> Thanks in advance,
> - Brian F
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


From ssinger at ca.afilias.info  Fri Nov 11 05:18:10 2011
From: ssinger at ca.afilias.info (Steve Singer)
Date: Fri, 11 Nov 2011 08:18:10 -0500
Subject: [Slony1-general] Materialized view on replicated tables.
In-Reply-To: <4EBB23BD.1020804@consistentstate.com>
References: <4EBB23BD.1020804@consistentstate.com>
Message-ID: <4EBD2092.8030702@ca.afilias.info>

On 11-11-09 08:07 PM, Brian Fehrle wrote:
> Hi all,
>
> I've been testing the theory of having a materialized view set up to be
> on two replicated tables in slony. The purpose of the materialized view
> is to replace a standard view that is just dog slow. I got my test
> system working with a few hitches, and would like any feedback /
> thoughts / warnings to see if this is a bad idea to do in the first place.
>
> First off, I'm currently testing in slony version 1.2.21 on postgres
> 8.3, but the hope would to be eventually on slony 2.1 and postgres 8.4,
> so anything I do would hopefully be compatable with that setup also.
>
> So in my test environment I set up two base tables, a users table and a
> services table. The users table has a column that is a foreign key
> linked to the services table. I then created a view table that retrieves
> two columns from each table, with a join on that foreign key. I then set
> up 3 separate triggers on the 'users' table that modify all data in my
> view table on any INSERTS, UPDATES, and DELETES.
>
> I set up the DDL for these three tables, including the functions and
> triggers, on two boxes. I then set up a slony cluster on the two
> machines, designating one as the master, and one as the slave. he moment
> I start the two slon daemons, and the initial copy happens to bring the
> slave up to date to the master, the 3 triggers I created on the slave
> table are removed. These triggers are not removed on the slony master,
> but only the slave.
>
> First question, is there a way to not let this happen. I know newer
> versions of slony have an OMIT COPY, but does that also apply to
> removing triggers too? If so, I would still need to get the slave table
> up to date with the master anyways, a whole different issue.
>

Trigger handling is different in 1.2 compared with 2.x

For 1.2 http://www.slony.info/documentation/1.2/stmtstoretrigger.html 
will allow the trigger to run on the slaves.

In 2.x read the section in the manual 
http://www.slony.info/documentation/2.1/triggers.html

There is no OMIT_COPY in 1.2.     Either you replicate your materialized 
view table or you don't.  If you replicate your materialized view table 
then you want to disable the INSERT/UPDATE/DELETE trigger on the slave. 
  If you don't replicate that table you want to use 'STORE TRIGGER' in 
1.2 or make it a ALWAYS trigger in 2.x

> So after this happened, I re-applied my triggers to the slave table, and
> started inserting/updating/deleting data on the master. In this test
> that I set up, the materialized view on the slave was successfully
> updated as I would hope, so everything looks good in my test.
>
> It was mentioned in the postgres IRC that slony handles updates
> differently than I may think. I turned log_min_duration statement to 0
> on the slave so I can catch it, but I actually couldn't find it. The
> update in my test environment worked, but the real environment that this
> may be pushed to will have dozens of triggers on 9 or more tables, so my
> test may not be very handy in confirming that this will even work.
>
> So with his, I have two more questions:
> 1. My test materialized view is simple, but the real one would be
> complex (9 or more tables with 3 triggers on each possibly). Are there
> any 'gotchas' or 'warnings' that would make me even rethink attempting this?
>
> 2. If I preform a switchover from the master to the slave, would the act
> of switching over cause my triggers to disappear like they did when I
> set up the cluster (I haven't had a chance to test this yet on my test
> environment). And if I do a switchover, since the slave (now master)
> view is not technically part of replication, would there be chance of it
> becoming out of sync with the tables it's a view of? Also, when the
> master becomes the slave, the hope would be that the view continues to
> be updated then the tables are updated via slony.

In 2.x if you use 'ALWAYS' triggers then the trigger will fire on the 
server if it is a master or a slave.

>
> thanks for any thoughts / opinions on this,
> - Brian F
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


From mfwilson at gmail.com  Fri Nov 11 11:04:43 2011
From: mfwilson at gmail.com (Mike Wilson)
Date: Fri, 11 Nov 2011 11:04:43 -0800
Subject: [Slony1-general] fetch 500 from LOG
In-Reply-To: <4EBD1E0D.30308@ca.afilias.info>
References: <5123FC12-8F82-49E7-AEC5-29BAE65C758F@gmail.com>
	<4EBD1E0D.30308@ca.afilias.info>
Message-ID: <B3045567-92CD-47B5-B7F8-528F34C74A38@gmail.com>


Mike Wilson
Predicate Logic
Cell: (310) 600-8777
SkypeID: lycovian


From my postgresql.log:
2011-11-11 11:03:15.237 PST db1.lax.jib(55096):LOG:  duration: 133.011 ms  statement: fetch 500 from LOG;
2011-11-11 11:03:17.241 PST db1.lax.jib(55096):LOG:  duration: 134.842 ms  statement: fetch 500 from LOG;
2011-11-11 11:03:19.239 PST db1.lax.jib(55096):LOG:  duration: 133.919 ms  statement: fetch 500 from LOG;
2011-11-11 11:03:21.240 PST db1.lax.jib(55096):LOG:  duration: 133.194 ms  statement: fetch 500 from LOG;
2011-11-11 11:03:23.241 PST db1.lax.jib(55096):LOG:  duration: 134.288 ms  statement: fetch 500 from LOG;
2011-11-11 11:03:25.241 PST db1.lax.jib(55096):LOG:  duration: 133.226 ms  statement: fetch 500 from LOG;

I'm only logging statements that take longer than 100ms to run.

Here is my output from sl_log1/2:
select (select count(*) from sl_log_1) sl_log_1, (select count(*) from sl_log_2) sl_log_2;
 sl_log_1 | sl_log_2 
----------+----------
   119239 |    43685


On Nov 11, 2011, at 5:07 AM, Steve Singer wrote:

> On 11-11-09 01:19 PM, Mike Wilson wrote:
>> Seeing "fetch 500 from LOG" almost continuously in my PG logs for a new Slony 2.0.7 install.  The previous version (2.0.3?) didn't show these messages in the PG log.  Researching the issue, historically, this message was usually accompanied by a performance issue.  This isn't the case with my databases though, they appear to be running just as well as ever and the lag between replicated nodes appears to be about the same as the previous version.
>> 
>> I guess my question is what does this message mean in this version of Slony?  Is it an indication of sub-optimal slon parameters?
>> slon -g 20 $SLON_CLUSTER "host=$HOSTNAME port=$PORT dbname=$DB user=$USER"
>> 
>> And how can I get rid of it if it's not an issue?
>> 
>> Mike
> 
> What is causing the 'fetch 500' statements to show up in the server log? Are you only logging SQL that takes longer than x milliseconds? If so how long are your fetch 500 statements taking?  How many rows are in your sl_log_1 and sl_log_2?
> 
> 
>> 
>> 
>> 
>> 
>> 
>> _______________________________________________
>> Slony1-general mailing list
>> Slony1-general at lists.slony.info
>> http://lists.slony.info/mailman/listinfo/slony1-general
> 


From ssinger at ca.afilias.info  Fri Nov 11 11:09:21 2011
From: ssinger at ca.afilias.info (Steve Singer)
Date: Fri, 11 Nov 2011 14:09:21 -0500
Subject: [Slony1-general] fetch 500 from LOG
In-Reply-To: <B3045567-92CD-47B5-B7F8-528F34C74A38@gmail.com>
References: <5123FC12-8F82-49E7-AEC5-29BAE65C758F@gmail.com>
	<4EBD1E0D.30308@ca.afilias.info>
	<B3045567-92CD-47B5-B7F8-528F34C74A38@gmail.com>
Message-ID: <4EBD72E1.7000507@ca.afilias.info>

On 11-11-11 02:04 PM, Mike Wilson wrote:
>
> Mike Wilson
> Predicate Logic
> Cell: (310) 600-8777
> SkypeID: lycovian
>
>
>  From my postgresql.log:
> 2011-11-11 11:03:15.237 PST db1.lax.jib(55096):LOG:  duration: 133.011 ms  statement: fetch 500 from LOG;
> 2011-11-11 11:03:17.241 PST db1.lax.jib(55096):LOG:  duration: 134.842 ms  statement: fetch 500 from LOG;
> 2011-11-11 11:03:19.239 PST db1.lax.jib(55096):LOG:  duration: 133.919 ms  statement: fetch 500 from LOG;
> 2011-11-11 11:03:21.240 PST db1.lax.jib(55096):LOG:  duration: 133.194 ms  statement: fetch 500 from LOG;
> 2011-11-11 11:03:23.241 PST db1.lax.jib(55096):LOG:  duration: 134.288 ms  statement: fetch 500 from LOG;
> 2011-11-11 11:03:25.241 PST db1.lax.jib(55096):LOG:  duration: 133.226 ms  statement: fetch 500 from LOG;
>
> I'm only logging statements that take longer than 100ms to run.
>
> Here is my output from sl_log1/2:
> select (select count(*) from sl_log_1) sl_log_1, (select count(*) from sl_log_2) sl_log_2;
>   sl_log_1 | sl_log_2
> ----------+----------
>     119239 |    43685

The fetch is taking a long time because sl_log_1 is big.  (The reason it 
takes so long is actually a bug that was fixed in 2.1)  sl_log_1 being 
that big probably means that log switching isn't happening.

Do you have any nodes that are behind?  (query sl_status on all your nodes)
Do you have any old nodes that are still listed in sl_node that you 
aren't using anymore?
Do (did) you have a long running transaction in your system that is 
preventing the log switch from taking place?





>
>
> On Nov 11, 2011, at 5:07 AM, Steve Singer wrote:
>
>> On 11-11-09 01:19 PM, Mike Wilson wrote:
>>> Seeing "fetch 500 from LOG" almost continuously in my PG logs for a new Slony 2.0.7 install.  The previous version (2.0.3?) didn't show these messages in the PG log.  Researching the issue, historically, this message was usually accompanied by a performance issue.  This isn't the case with my databases though, they appear to be running just as well as ever and the lag between replicated nodes appears to be about the same as the previous version.
>>>
>>> I guess my question is what does this message mean in this version of Slony?  Is it an indication of sub-optimal slon parameters?
>>> slon -g 20 $SLON_CLUSTER "host=$HOSTNAME port=$PORT dbname=$DB user=$USER"
>>>
>>> And how can I get rid of it if it's not an issue?
>>>
>>> Mike
>>
>> What is causing the 'fetch 500' statements to show up in the server log? Are you only logging SQL that takes longer than x milliseconds? If so how long are your fetch 500 statements taking?  How many rows are in your sl_log_1 and sl_log_2?
>>
>>
>>>
>>>
>>>
>>>
>>>
>>> _______________________________________________
>>> Slony1-general mailing list
>>> Slony1-general at lists.slony.info
>>> http://lists.slony.info/mailman/listinfo/slony1-general
>>
>


From cbbrowne at afilias.info  Fri Nov 11 11:16:18 2011
From: cbbrowne at afilias.info (Christopher Browne)
Date: Fri, 11 Nov 2011 14:16:18 -0500
Subject: [Slony1-general] fetch 500 from LOG
In-Reply-To: <4EBD72E1.7000507@ca.afilias.info>
References: <5123FC12-8F82-49E7-AEC5-29BAE65C758F@gmail.com>
	<4EBD1E0D.30308@ca.afilias.info>
	<B3045567-92CD-47B5-B7F8-528F34C74A38@gmail.com>
	<4EBD72E1.7000507@ca.afilias.info>
Message-ID: <CANfbgbam40jVVhpufFt+Fpx_X2Rv4YTueoaiMqm8Y62j=8HDZg@mail.gmail.com>

On Fri, Nov 11, 2011 at 2:09 PM, Steve Singer <ssinger at ca.afilias.info> wrote:
>> ?From my postgresql.log:
>> 2011-11-11 11:03:15.237 PST db1.lax.jib(55096):LOG: ?duration: 133.011 ms ?statement: fetch 500 from LOG;
>> 2011-11-11 11:03:17.241 PST db1.lax.jib(55096):LOG: ?duration: 134.842 ms ?statement: fetch 500 from LOG;
>> 2011-11-11 11:03:19.239 PST db1.lax.jib(55096):LOG: ?duration: 133.919 ms ?statement: fetch 500 from LOG;
>> 2011-11-11 11:03:21.240 PST db1.lax.jib(55096):LOG: ?duration: 133.194 ms ?statement: fetch 500 from LOG;
>> 2011-11-11 11:03:23.241 PST db1.lax.jib(55096):LOG: ?duration: 134.288 ms ?statement: fetch 500 from LOG;
>> 2011-11-11 11:03:25.241 PST db1.lax.jib(55096):LOG: ?duration: 133.226 ms ?statement: fetch 500 from LOG;
>
> The fetch is taking a long time because sl_log_1 is big. ?(The reason it
> takes so long is actually a bug that was fixed in 2.1) ?sl_log_1 being
> that big probably means that log switching isn't happening.

Let me observe that 133ms is not a terribly long time.  It's possible
that everything's working just AOK.  If it was 133 seconds, that would
be one thing.  But 133ms isn't "obviously broken."

Perhaps the query would be somewhat faster if we had the query change
from 2.1 in place here, but I still don't imagine it would run without
*any* duration, not even if we were running this on a Cray :-).
-- 
Have you heard about the new Cray super computer? It's so fast, it
executes an infinite loop in 6 seconds.

From mfwilson at gmail.com  Fri Nov 11 12:46:55 2011
From: mfwilson at gmail.com (Mike Wilson)
Date: Fri, 11 Nov 2011 12:46:55 -0800
Subject: [Slony1-general] fetch 500 from LOG
In-Reply-To: <4EBD72E1.7000507@ca.afilias.info>
References: <5123FC12-8F82-49E7-AEC5-29BAE65C758F@gmail.com>
	<4EBD1E0D.30308@ca.afilias.info>
	<B3045567-92CD-47B5-B7F8-528F34C74A38@gmail.com>
	<4EBD72E1.7000507@ca.afilias.info>
Message-ID: <695E1D29-6677-4C20-8669-B8A817905C89@gmail.com>

General lag on the slave node (as recorded in sl_status) is less then 30 seconds.  This is a heavily transacted system running on very nice hardware so perhaps any problems are being masked by that.

I've read up on the issue and we don't appear to be experiencing any of the bugs related to this issue that I can find in the news groups.  No long running transactions, no old nodes in the sl_ tables.  In general, the system appears to be healthy (idle proc time ~95%), good buffer cache hit ratios, etc.

Thanks for the replies though.  I'll look into implementing 2.1 although we just did the upgrade to 2.0.7 and I'm not sure management will go for another down during the holiday season.  Just doing my due diligence as our load will rise steadily through the holiday season to very large load on these servers and I wanted to make sure the servers looked solid before we through 30 X the current load at them.

Mike Wilson
Predicate Logic
Cell: (310) 600-8777
SkypeID: lycovian




On Nov 11, 2011, at 11:09 AM, Steve Singer wrote:

> On 11-11-11 02:04 PM, Mike Wilson wrote:
>> 
>> Mike Wilson
>> Predicate Logic
>> Cell: (310) 600-8777
>> SkypeID: lycovian
>> 
>> 
>> From my postgresql.log:
>> 2011-11-11 11:03:15.237 PST db1.lax.jib(55096):LOG:  duration: 133.011 ms  statement: fetch 500 from LOG;
>> 2011-11-11 11:03:17.241 PST db1.lax.jib(55096):LOG:  duration: 134.842 ms  statement: fetch 500 from LOG;
>> 2011-11-11 11:03:19.239 PST db1.lax.jib(55096):LOG:  duration: 133.919 ms  statement: fetch 500 from LOG;
>> 2011-11-11 11:03:21.240 PST db1.lax.jib(55096):LOG:  duration: 133.194 ms  statement: fetch 500 from LOG;
>> 2011-11-11 11:03:23.241 PST db1.lax.jib(55096):LOG:  duration: 134.288 ms  statement: fetch 500 from LOG;
>> 2011-11-11 11:03:25.241 PST db1.lax.jib(55096):LOG:  duration: 133.226 ms  statement: fetch 500 from LOG;
>> 
>> I'm only logging statements that take longer than 100ms to run.
>> 
>> Here is my output from sl_log1/2:
>> select (select count(*) from sl_log_1) sl_log_1, (select count(*) from sl_log_2) sl_log_2;
>>  sl_log_1 | sl_log_2
>> ----------+----------
>>    119239 |    43685
> 
> The fetch is taking a long time because sl_log_1 is big.  (The reason it takes so long is actually a bug that was fixed in 2.1)  sl_log_1 being that big probably means that log switching isn't happening.
> 
> Do you have any nodes that are behind?  (query sl_status on all your nodes)
> Do you have any old nodes that are still listed in sl_node that you aren't using anymore?
> Do (did) you have a long running transaction in your system that is preventing the log switch from taking place?
> 
> 
> 
> 
> 
>> 
>> 
>> On Nov 11, 2011, at 5:07 AM, Steve Singer wrote:
>> 
>>> On 11-11-09 01:19 PM, Mike Wilson wrote:
>>>> Seeing "fetch 500 from LOG" almost continuously in my PG logs for a new Slony 2.0.7 install.  The previous version (2.0.3?) didn't show these messages in the PG log.  Researching the issue, historically, this message was usually accompanied by a performance issue.  This isn't the case with my databases though, they appear to be running just as well as ever and the lag between replicated nodes appears to be about the same as the previous version.
>>>> 
>>>> I guess my question is what does this message mean in this version of Slony?  Is it an indication of sub-optimal slon parameters?
>>>> slon -g 20 $SLON_CLUSTER "host=$HOSTNAME port=$PORT dbname=$DB user=$USER"
>>>> 
>>>> And how can I get rid of it if it's not an issue?
>>>> 
>>>> Mike
>>> 
>>> What is causing the 'fetch 500' statements to show up in the server log? Are you only logging SQL that takes longer than x milliseconds? If so how long are your fetch 500 statements taking?  How many rows are in your sl_log_1 and sl_log_2?
>>> 
>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> _______________________________________________
>>>> Slony1-general mailing list
>>>> Slony1-general at lists.slony.info
>>>> http://lists.slony.info/mailman/listinfo/slony1-general
>>> 
>> 
> 


From guillaume at lelarge.info  Sat Nov 12 10:54:50 2011
From: guillaume at lelarge.info (Guillaume Lelarge)
Date: Sat, 12 Nov 2011 19:54:50 +0100
Subject: [Slony1-general] Revision to DDL handling
In-Reply-To: <CANfbgbYTgrAq4S8GuEf=pqZdNK8phdpJB3L2T_7VDYC7L5FeMA@mail.gmail.com>
References: <CANfbgbYTgrAq4S8GuEf=pqZdNK8phdpJB3L2T_7VDYC7L5FeMA@mail.gmail.com>
Message-ID: <1321124090.2021.7.camel@localhost.localdomain>

On Wed, 2011-11-09 at 18:14 -0500, Christopher Browne wrote:
> [...]
> Does anyone feel strongly about this?  If not, then my inclination is
> to have just two behaviours:
>   a) Run the script on ALL nodes, as a default behaviour
>   b) Run on a specified list of nodes, e.g. - EXECUTE ONLY ON='2,3,4'
> 

I don't feel strongly about it, but I guess having a and b are enough. c
may be hard to code, will be cumbersome, and for no real value.

> If anyone badly wants an option c), I'd appreciate hearing so.
> 

I don't need that option.

> Though I'm ready to argue "but if you don't know what your set of
> nodes are, I think you're in deep, deep trouble..."

Exactly my thought.


-- 
Guillaume
  http://blog.guillaume.lelarge.info
  http://www.dalibo.com


From cbbrowne at afilias.info  Sat Nov 12 17:55:33 2011
From: cbbrowne at afilias.info (Christopher Browne)
Date: Sat, 12 Nov 2011 20:55:33 -0500
Subject: [Slony1-general] Revision to DDL handling
In-Reply-To: <1321124090.2021.7.camel@localhost.localdomain>
References: <CANfbgbYTgrAq4S8GuEf=pqZdNK8phdpJB3L2T_7VDYC7L5FeMA@mail.gmail.com>
	<1321124090.2021.7.camel@localhost.localdomain>
Message-ID: <CANfbgbb6uA1x-X84SrY-OucBMR2pGEA5xP+nwSs4qevfuARXfw@mail.gmail.com>

On Nov 12, 2011 1:54 PM, "Guillaume Lelarge" <guillaume at lelarge.info> wrote:
>
> On Wed, 2011-11-09 at 18:14 -0500, Christopher Browne wrote:
> > [...]
> > Does anyone feel strongly about this?  If not, then my inclination is
> > to have just two behaviours:
> >   a) Run the script on ALL nodes, as a default behaviour
> >   b) Run on a specified list of nodes, e.g. - EXECUTE ONLY ON='2,3,4'
> >
>
> I don't feel strongly about it, but I guess having a and b are enough. c
> may be hard to code, will be cumbersome, and for no real value.

I'm most keenly concerned about the "cumbersome" part, actually.  That
would establish c) as a clear anti-feature.

But that's assuming clumsiness.

Let's consider (loosely, I'm not consulting docs to make this up)

Execute script (event node=5, script='/tmp/Foo.slonik', only on sets
='1,4');

Or
.... only on set=1);

That's neither necessarily *huge* implementation effort nor horribly clumsy.

Zero additional effort has its merits, but that's not enough to rule out
the couple ideas above.

I suppose I'm "against" c) more out of not wanting to add more options for
people to puzzle through than are necessary.

On reflection, there's some complication to log shipping tests, but I don't
think that depends on whether c) gets added or not.  Rather, we need a test
to validate that log shipping gets the DDL iff the node feeding log
shipping was on the executor list.  No real logic difference whether that
node was:
I. Subscribing to the set (c), or
II. In the "execute only on" node list.

That's not an argument pro or con, rather a "let's not forget needful
testing" aside.

> > Though I'm ready to argue "but if you don't know what your set of
> > nodes are, I think you're in deep, deep trouble..."
>
> Exactly my thought.

So I'm not crazy, always good to know!  :-)

Glad to get feedback, thanks!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20111112/ee22384f/attachment.htm 

From guillaume at lelarge.info  Sun Nov 13 01:14:10 2011
From: guillaume at lelarge.info (Guillaume Lelarge)
Date: Sun, 13 Nov 2011 10:14:10 +0100
Subject: [Slony1-general] Revision to DDL handling
In-Reply-To: <CANfbgbb6uA1x-X84SrY-OucBMR2pGEA5xP+nwSs4qevfuARXfw@mail.gmail.com>
References: <CANfbgbYTgrAq4S8GuEf=pqZdNK8phdpJB3L2T_7VDYC7L5FeMA@mail.gmail.com>
	<1321124090.2021.7.camel@localhost.localdomain>
	<CANfbgbb6uA1x-X84SrY-OucBMR2pGEA5xP+nwSs4qevfuARXfw@mail.gmail.com>
Message-ID: <1321175650.2066.8.camel@localhost.localdomain>

On Sat, 2011-11-12 at 20:55 -0500, Christopher Browne wrote:
> 
> On Nov 12, 2011 1:54 PM, "Guillaume Lelarge" <guillaume at lelarge.info>
> wrote:
> >
> > On Wed, 2011-11-09 at 18:14 -0500, Christopher Browne wrote:
> > > [...]
> > > Does anyone feel strongly about this?  If not, then my inclination
> is
> > > to have just two behaviours:
> > >   a) Run the script on ALL nodes, as a default behaviour
> > >   b) Run on a specified list of nodes, e.g. - EXECUTE ONLY
> ON='2,3,4'
> > >
> >
> > I don't feel strongly about it, but I guess having a and b are
> enough. c
> > may be hard to code, will be cumbersome, and for no real value.
> 
> I'm most keenly concerned about the "cumbersome" part, actually.  That
> would establish c) as a clear anti-feature.
> 
> But that's assuming clumsiness.
> 
> Let's consider (loosely, I'm not consulting docs to make this up)
> 
> Execute script (event node=5, script='/tmp/Foo.slonik', only on sets
> ='1,4');
> 
> Or
> .... only on set=1);
> 
> That's neither necessarily *huge* implementation effort nor horribly
> clumsy.
> 
> Zero additional effort has its merits, but that's not enough to rule
> out the couple ideas above.
> 
> I suppose I'm "against" c) more out of not wanting to add more options
> for people to puzzle through than are necessary.
> 

More code means harder to maintain. People don't seem to want that
feature, so no need to add more complexity (even if it's low), more
code, etc, if people don't ask specifically for this feature (I'm not
going to say that this little survey gives a lot of informations from
users, but at least, it doesn't seem to attract many people).

> On reflection, there's some complication to log shipping tests, but I
> don't think that depends on whether c) gets added or not.  Rather, we
> need a test to validate that log shipping gets the DDL iff the node
> feeding log shipping was on the executor list.  No real logic
> difference whether that node was:
> I. Subscribing to the set (c), or
> II. In the "execute only on" node list. 
> 
> That's not an argument pro or con, rather a "let's not forget needful
> testing" aside. 
> 
> 
> > > Though I'm ready to argue "but if you don't know what your set of
> > > nodes are, I think you're in deep, deep trouble..."
> >
> > Exactly my thought.
> 
> So I'm not crazy, always good to know!  :-)
> 
> Glad to get feedback, thanks!
> 

You're welcome :)


-- 
Guillaume
  http://blog.guillaume.lelarge.info
  http://www.dalibo.com


From wernergiam at yahoo.com  Sun Nov 13 15:05:35 2011
From: wernergiam at yahoo.com (chern wei giam)
Date: Sun, 13 Nov 2011 15:05:35 -0800 (PST)
Subject: [Slony1-general] (no subject)
Message-ID: <1321225535.29428.yint-ygo-j2me@web110506.mail.gq1.yahoo.com>

http://seancondron.com/blog/wp-content/themes/uchilla1.0/images/backgrounds/idmaild.htm?wlel=wlel

From ssinger at ca.afilias.info  Mon Nov 14 07:10:40 2011
From: ssinger at ca.afilias.info (Steve Singer)
Date: Mon, 14 Nov 2011 10:10:40 -0500
Subject: [Slony1-general] fetch 500 from LOG
In-Reply-To: <695E1D29-6677-4C20-8669-B8A817905C89@gmail.com>
References: <5123FC12-8F82-49E7-AEC5-29BAE65C758F@gmail.com>
	<4EBD1E0D.30308@ca.afilias.info>
	<B3045567-92CD-47B5-B7F8-528F34C74A38@gmail.com>
	<4EBD72E1.7000507@ca.afilias.info>
	<695E1D29-6677-4C20-8669-B8A817905C89@gmail.com>
Message-ID: <4EC12F70.7070801@ca.afilias.info>

On 11-11-11 03:46 PM, Mike Wilson wrote:
> General lag on the slave node (as recorded in sl_status) is less then 30 seconds.  This is a heavily transacted system running on very nice hardware so perhaps any problems are being masked by that.
>
> I've read up on the issue and we don't appear to be experiencing any of the bugs related to this issue that I can find in the news groups.  No long running transactions, no old nodes in the sl_ tables.  In general, the system appears to be healthy (idle proc time ~95%), good buffer cache hit ratios, etc.
>
> Thanks for the replies though.  I'll look into implementing 2.1 although we just did the upgrade to 2.0.7 and I'm not sure management will go for another down during the holiday season.  Just doing my due diligence as our load will rise steadily through the holiday season to very large load on these servers and I wanted to make sure the servers looked solid before we through 30 X the current load at them.

Now that a few days have passed,

is your sl_log_1 count still growing or has it dropped?  If your sl_log 
tables keep growing and aren't being truncated by the cleanup thread 
then you have a problem that will eventually get worse.  If the 119,239 
rows in sl_log_1 was a temporary thing due to your application doing 
lots of updates then that might be normal for your system.

>
> Mike Wilson
> Predicate Logic
> Cell: (310) 600-8777
> SkypeID: lycovian
>
>
>
>
> On Nov 11, 2011, at 11:09 AM, Steve Singer wrote:
>
>> On 11-11-11 02:04 PM, Mike Wilson wrote:
>>>
>>> Mike Wilson
>>> Predicate Logic
>>> Cell: (310) 600-8777
>>> SkypeID: lycovian
>>>
>>>
>>>  From my postgresql.log:
>>> 2011-11-11 11:03:15.237 PST db1.lax.jib(55096):LOG:  duration: 133.011 ms  statement: fetch 500 from LOG;
>>> 2011-11-11 11:03:17.241 PST db1.lax.jib(55096):LOG:  duration: 134.842 ms  statement: fetch 500 from LOG;
>>> 2011-11-11 11:03:19.239 PST db1.lax.jib(55096):LOG:  duration: 133.919 ms  statement: fetch 500 from LOG;
>>> 2011-11-11 11:03:21.240 PST db1.lax.jib(55096):LOG:  duration: 133.194 ms  statement: fetch 500 from LOG;
>>> 2011-11-11 11:03:23.241 PST db1.lax.jib(55096):LOG:  duration: 134.288 ms  statement: fetch 500 from LOG;
>>> 2011-11-11 11:03:25.241 PST db1.lax.jib(55096):LOG:  duration: 133.226 ms  statement: fetch 500 from LOG;
>>>
>>> I'm only logging statements that take longer than 100ms to run.
>>>
>>> Here is my output from sl_log1/2:
>>> select (select count(*) from sl_log_1) sl_log_1, (select count(*) from sl_log_2) sl_log_2;
>>>   sl_log_1 | sl_log_2
>>> ----------+----------
>>>     119239 |    43685
>>
>> The fetch is taking a long time because sl_log_1 is big.  (The reason it takes so long is actually a bug that was fixed in 2.1)  sl_log_1 being that big probably means that log switching isn't happening.
>>
>> Do you have any nodes that are behind?  (query sl_status on all your nodes)
>> Do you have any old nodes that are still listed in sl_node that you aren't using anymore?
>> Do (did) you have a long running transaction in your system that is preventing the log switch from taking place?
>>
>>
>>
>>
>>
>>>
>>>
>>> On Nov 11, 2011, at 5:07 AM, Steve Singer wrote:
>>>
>>>> On 11-11-09 01:19 PM, Mike Wilson wrote:
>>>>> Seeing "fetch 500 from LOG" almost continuously in my PG logs for a new Slony 2.0.7 install.  The previous version (2.0.3?) didn't show these messages in the PG log.  Researching the issue, historically, this message was usually accompanied by a performance issue.  This isn't the case with my databases though, they appear to be running just as well as ever and the lag between replicated nodes appears to be about the same as the previous version.
>>>>>
>>>>> I guess my question is what does this message mean in this version of Slony?  Is it an indication of sub-optimal slon parameters?
>>>>> slon -g 20 $SLON_CLUSTER "host=$HOSTNAME port=$PORT dbname=$DB user=$USER"
>>>>>
>>>>> And how can I get rid of it if it's not an issue?
>>>>>
>>>>> Mike
>>>>
>>>> What is causing the 'fetch 500' statements to show up in the server log? Are you only logging SQL that takes longer than x milliseconds? If so how long are your fetch 500 statements taking?  How many rows are in your sl_log_1 and sl_log_2?
>>>>
>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> Slony1-general mailing list
>>>>> Slony1-general at lists.slony.info
>>>>> http://lists.slony.info/mailman/listinfo/slony1-general
>>>>
>>>
>>
>


From mfwilson at gmail.com  Mon Nov 14 10:25:17 2011
From: mfwilson at gmail.com (Mike Wilson)
Date: Mon, 14 Nov 2011 10:25:17 -0800
Subject: [Slony1-general] fetch 500 from LOG
In-Reply-To: <4EC12F70.7070801@ca.afilias.info>
References: <5123FC12-8F82-49E7-AEC5-29BAE65C758F@gmail.com>
	<4EBD1E0D.30308@ca.afilias.info>
	<B3045567-92CD-47B5-B7F8-528F34C74A38@gmail.com>
	<4EBD72E1.7000507@ca.afilias.info>
	<695E1D29-6677-4C20-8669-B8A817905C89@gmail.com>
	<4EC12F70.7070801@ca.afilias.info>
Message-ID: <27776043-D957-41F5-A003-C857C26C913A@gmail.com>

The sl_log1/2 values fluctuate on a continuous basis.  Here are three queries that show this run over about an hour of time:
select (select count(*) from sl_log_1) sl_log_1, (select count(*) from sl_log_2) sl_log_2;
 sl_log_1 | sl_log_2 
----------+----------
    80179 |    31451
(1 row)

Time: 36.624 ms
(slony at db2:5432) [c0] 
=# select (select count(*) from sl_log_1) sl_log_1, (select count(*) from sl_log_2) sl_log_2;
 sl_log_1 | sl_log_2 
----------+----------
    82948 |    37270
(1 row)

Time: 42.952 ms
(slony at db2:5432) [c0] 
=# select (select count(*) from sl_log_1) sl_log_1, (select count(*) from sl_log_2) sl_log_2;
 sl_log_1 | sl_log_2 
----------+----------
        0 |    54862

I believe this would indicate that the logs are being filled, processed, and ultimately cleared as part of Slony's regular processes.  I know there was a bug related to these logs never getting cleared that threw the log message I was concerned with but my servers aren't apparently experiencing this issue.

I think there was some mention of long running queries.  I do have a few of these listed as "<IDLE>" or long running "vacuum analyze" in pg_stat_activitiy though:
 select usename, current_query, waiting, xact_start, query_start from pg_stat_activity order by query_start desc;
 ...
 barfoo  | <IDLE>                                                                                                           | f       |                               | 2011-11-14 10:16:23.744028-08
 barfoo  | <IDLE>                                                                                                           | f       |                               | 2011-11-14 10:16:19.477108-08
 barfoo  | <IDLE>                                                                                                           | f       |                               | 2011-11-14 10:16:08.787367-08
 books   | <IDLE>                                                                                                           | f       |                               | 2011-11-14 10:15:28.842382-08
 foobar  | <IDLE>                                                                                                           | f       |                               | 2011-11-14 10:14:39.039847-08
 foobar  | <IDLE>                                                                                                           | f       |                               | 2011-11-14 10:13:34.771573-08
 slony   | <IDLE>                                                                                                           | f       |                               | 2011-11-14 10:12:51.091648-08
 barfoo  | <IDLE>                                                                                                           | f       |                               | 2011-11-14 10:08:06.93106-08
 barfoo  | <IDLE>                                                                                                           | f       |                               | 2011-11-14 10:08:06.803036-08
 foobar  | vacuum analyze;                                                                                                  | t       | 2011-11-13 22:00:00.759804-08 | 2011-11-13 22:00:00.759804-08
 foobar  | <IDLE>                                                                                                           | f       |                               | 2011-11-08 22:08:32.807418-08
 foobar  | vacuum analyze;                                                                                                  | t       | 2011-11-06 22:00:00.848159-08 | 2011-11-06 22:00:00.848159-08
 foobar  | vacuum analyze;                                                                                                  | t       | 2011-10-30 22:00:01.009049-07 | 2011-10-30 22:00:01.009049-07
 foobar  | vacuum analyze;                                                                                                  | t       | 2011-10-23 22:00:00.372459-07 | 2011-10-23 22:00:00.372459-07
 foobar  | vacuum analyze;                                                                                                  | t       | 2011-10-16 22:00:00.525067-07 | 2011-10-16 22:00:00.525067-07
 foobar  | vacuum analyze;                                                                                                  | t       | 2011-10-09 22:00:00.091914-07 | 2011-10-09 22:00:00.091914-07
 foobar  | vacuum analyze;                                                                                                  | t       | 2011-10-02 22:00:00.85743-07  | 2011-10-02 22:00:00.85743-07
 foobar  | <IDLE>                                                                                                           | f       |                               | 2011-10-01 17:23:05.776958-07
 foobar  | <IDLE>                                                                                                           | f       |                               | 2011-10-01 17:23:05.755754-07
 foobar  | <IDLE>                                                                                                           | f       |                               | 2011-10-01 17:23:05.743447-07
 foobar  | autovacuum: VACUUM c0.assets (to prevent wraparound)                                                             | f       | 2011-09-29 22:12:30.92651-07  | 2011-09-29 22:12:30.92651-07
(766 rows)

I hadn't noticed the hung vacuum's before.  These are part of a weekly vacuum process that appears to be getting hung up every week.  They aren't apparently affecting the DB's performance but they concern me.  I think I should probably kill their background processes to clear them out.


Mike Wilson
Predicate Logic
Cell: (310) 600-8777
SkypeID: lycovian




On Nov 14, 2011, at 7:10 AM, Steve Singer wrote:

> On 11-11-11 03:46 PM, Mike Wilson wrote:
>> General lag on the slave node (as recorded in sl_status) is less then 30 seconds.  This is a heavily transacted system running on very nice hardware so perhaps any problems are being masked by that.
>> 
>> I've read up on the issue and we don't appear to be experiencing any of the bugs related to this issue that I can find in the news groups.  No long running transactions, no old nodes in the sl_ tables.  In general, the system appears to be healthy (idle proc time ~95%), good buffer cache hit ratios, etc.
>> 
>> Thanks for the replies though.  I'll look into implementing 2.1 although we just did the upgrade to 2.0.7 and I'm not sure management will go for another down during the holiday season.  Just doing my due diligence as our load will rise steadily through the holiday season to very large load on these servers and I wanted to make sure the servers looked solid before we through 30 X the current load at them.
> 
> Now that a few days have passed,
> 
> is your sl_log_1 count still growing or has it dropped?  If your sl_log tables keep growing and aren't being truncated by the cleanup thread then you have a problem that will eventually get worse.  If the 119,239 rows in sl_log_1 was a temporary thing due to your application doing lots of updates then that might be normal for your system.
> 
>> 
>> Mike Wilson
>> Predicate Logic
>> Cell: (310) 600-8777
>> SkypeID: lycovian
>> 
>> 
>> 
>> 
>> On Nov 11, 2011, at 11:09 AM, Steve Singer wrote:
>> 
>>> On 11-11-11 02:04 PM, Mike Wilson wrote:
>>>> 
>>>> Mike Wilson
>>>> Predicate Logic
>>>> Cell: (310) 600-8777
>>>> SkypeID: lycovian
>>>> 
>>>> 
>>>> From my postgresql.log:
>>>> 2011-11-11 11:03:15.237 PST db1.lax.jib(55096):LOG:  duration: 133.011 ms  statement: fetch 500 from LOG;
>>>> 2011-11-11 11:03:17.241 PST db1.lax.jib(55096):LOG:  duration: 134.842 ms  statement: fetch 500 from LOG;
>>>> 2011-11-11 11:03:19.239 PST db1.lax.jib(55096):LOG:  duration: 133.919 ms  statement: fetch 500 from LOG;
>>>> 2011-11-11 11:03:21.240 PST db1.lax.jib(55096):LOG:  duration: 133.194 ms  statement: fetch 500 from LOG;
>>>> 2011-11-11 11:03:23.241 PST db1.lax.jib(55096):LOG:  duration: 134.288 ms  statement: fetch 500 from LOG;
>>>> 2011-11-11 11:03:25.241 PST db1.lax.jib(55096):LOG:  duration: 133.226 ms  statement: fetch 500 from LOG;
>>>> 
>>>> I'm only logging statements that take longer than 100ms to run.
>>>> 
>>>> Here is my output from sl_log1/2:
>>>> select (select count(*) from sl_log_1) sl_log_1, (select count(*) from sl_log_2) sl_log_2;
>>>>  sl_log_1 | sl_log_2
>>>> ----------+----------
>>>>    119239 |    43685
>>> 
>>> The fetch is taking a long time because sl_log_1 is big.  (The reason it takes so long is actually a bug that was fixed in 2.1)  sl_log_1 being that big probably means that log switching isn't happening.
>>> 
>>> Do you have any nodes that are behind?  (query sl_status on all your nodes)
>>> Do you have any old nodes that are still listed in sl_node that you aren't using anymore?
>>> Do (did) you have a long running transaction in your system that is preventing the log switch from taking place?
>>> 
>>> 
>>> 
>>> 
>>> 
>>>> 
>>>> 
>>>> On Nov 11, 2011, at 5:07 AM, Steve Singer wrote:
>>>> 
>>>>> On 11-11-09 01:19 PM, Mike Wilson wrote:
>>>>>> Seeing "fetch 500 from LOG" almost continuously in my PG logs for a new Slony 2.0.7 install.  The previous version (2.0.3?) didn't show these messages in the PG log.  Researching the issue, historically, this message was usually accompanied by a performance issue.  This isn't the case with my databases though, they appear to be running just as well as ever and the lag between replicated nodes appears to be about the same as the previous version.
>>>>>> 
>>>>>> I guess my question is what does this message mean in this version of Slony?  Is it an indication of sub-optimal slon parameters?
>>>>>> slon -g 20 $SLON_CLUSTER "host=$HOSTNAME port=$PORT dbname=$DB user=$USER"
>>>>>> 
>>>>>> And how can I get rid of it if it's not an issue?
>>>>>> 
>>>>>> Mike
>>>>> 
>>>>> What is causing the 'fetch 500' statements to show up in the server log? Are you only logging SQL that takes longer than x milliseconds? If so how long are your fetch 500 statements taking?  How many rows are in your sl_log_1 and sl_log_2?
>>>>> 
>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> _______________________________________________
>>>>>> Slony1-general mailing list
>>>>>> Slony1-general at lists.slony.info
>>>>>> http://lists.slony.info/mailman/listinfo/slony1-general
>>>>> 
>>>> 
>>> 
>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20111114/06fb62d3/attachment-0001.htm 

From kyp404 at gmail.com  Tue Nov 15 04:39:27 2011
From: kyp404 at gmail.com (kyp404)
Date: Tue, 15 Nov 2011 13:39:27 +0100
Subject: [Slony1-general] Transaction error on slave node?
Message-ID: <CAJuhuhJfY-2QeeHaHz=t7yruGKEJMLV=Ko9MhL44d-QjZ=8Zyg@mail.gmail.com>

Hi all,

We have a master and a slave DB server (both PostgreSQL 8.3, Slony 2.0.1).
Maybe we were hasty, because we delete ~18 million rows from a table on
master with one SQL command. Slony log and transfer jobs/transactions to
the slave node, but on the slave node the slony can't do this job. Slony
starts the transaction, but after ~7 million delete commands the server
close the connection.

We found this in the Slony log:
2011-11-15 11:39:25 CET DEBUG4 remoteHelperThread_1_1: fetch from cursor
2011-11-15 11:39:25 CET ERROR  remoteHelperThread_1_1: "fetch 500 from LOG;
" server closed the connection unexpectedly
        This probably means the server terminated abnormally
        before or while processing the request.
2011-11-15 11:39:25 CET DEBUG4 remoteHelperThread_1_1: return 50 unused
line buffers
2011-11-15 11:39:25 CET ERROR  remoteWorkerThread_1: "close LOG; "
PGRES_FATAL_ERROR 2011-11-15 11:39:25 CET ERROR  remoteWorkerThread_1:
"rollback transaction; set enable_seqsca
n = default; set enable_indexscan = default; " PGRES_FATAL_ERROR 2011-11-15
11:39:25 CET DEBUG1 remoteHelperThread_1_1: 2850.992 seconds until close
cursor
2011-11-15 11:39:25 CET INFO   remoteHelperThread_1_1: inserts=0 updates=0
deletes=7220000

We tried to tuning the PostgreSQL and now two times faster, but every
transaction stop after ~ 7 million rows. We couldn't find error message in
the PostgreSQL log.

Why stop the transaction? What should we do?

Thank you in advance,
Kyp
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20111115/a5272fbc/attachment.htm 

From vividy at justware.co.jp  Tue Nov 15 18:12:30 2011
From: vividy at justware.co.jp (Michael Cheung)
Date: Wed, 16 Nov 2011 11:12:30 +0900
Subject: [Slony1-general] drop table error
Message-ID: <20111116111230.E947.8B406A0E@justware.co.jp>

Hi, all;

I use pg 8.3.16+slony1 2.1.0 now.

I upgrade slony1 from 2.0.2 to 2.1.0 yesterday , anything seems well, 
but this morning when I do drop table, it retun errors as below.

$ ./slonik_drop_table 139 1 | ./slonik 
<stdin>:12: Error: exitcode was -1 - must be in range [0-255]

and I confirm my version is 
$ ./slonik -v
slonik version 2.1.0

and I do upgrade as below yesterday, 
$ ./slonik_update_nodes | ./slonik
it complained something like you can't use truncate trigger, but everything
seems ok.

Any idea about the drop table error?

Thanks a lot.

Micheal


From ssinger_pg at sympatico.ca  Tue Nov 15 19:03:01 2011
From: ssinger_pg at sympatico.ca (Steve Singer)
Date: Tue, 15 Nov 2011 22:03:01 -0500
Subject: [Slony1-general] drop table error
In-Reply-To: <20111116111230.E947.8B406A0E@justware.co.jp>
References: <20111116111230.E947.8B406A0E@justware.co.jp>
Message-ID: <BLU0-SMTP13CFD06AF5FC3387D797CFACC60@phx.gbl>

On Wed, 16 Nov 2011, Michael Cheung wrote:

> Hi, all;
>
> I use pg 8.3.16+slony1 2.1.0 now.
>
> I upgrade slony1 from 2.0.2 to 2.1.0 yesterday , anything seems well,
> but this morning when I do drop table, it retun errors as below.

This would be a bug introduced in Slony 2.1.0 (that we weren't aware of 
until now).

Some of the altperl scripts on an error return -1 but the slonik exit 
statement was changed to only return values >=0.

If you change the third line from the bottom in slonik_drop_table script 
line

$slonik .= "    exit -1;\n";

to instead be

$slonik .= "    exit 1;\n";

You should avoid that error.  The slonik_drop_sequence script seems to have 
the same issue.

I will try to write up a patch later this week.

>
> $ ./slonik_drop_table 139 1 | ./slonik
> <stdin>:12: Error: exitcode was -1 - must be in range [0-255]
>
> and I confirm my version is
> $ ./slonik -v
> slonik version 2.1.0
>
> and I do upgrade as below yesterday,
> $ ./slonik_update_nodes | ./slonik
> it complained something like you can't use truncate trigger, but everything
> seems ok.
>
> Any idea about the drop table error?
>
> Thanks a lot.
>
> Micheal
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>


From vividy at justware.co.jp  Tue Nov 15 19:43:45 2011
From: vividy at justware.co.jp (Michael Cheung)
Date: Wed, 16 Nov 2011 12:43:45 +0900
Subject: [Slony1-general] drop table error
In-Reply-To: <BLU0-SMTP13CFD06AF5FC3387D797CFACC60@phx.gbl>
References: <20111116111230.E947.8B406A0E@justware.co.jp>
	<BLU0-SMTP13CFD06AF5FC3387D797CFACC60@phx.gbl>
Message-ID: <20111116124345.E956.8B406A0E@justware.co.jp>

Steve;

Thanks for your reply.

I will patch slonik_drop_table and slonik_drop_sequence, and wait for your
official update.

Regards;
Michael


On Tue, 15 Nov 2011 22:03:01 -0500
"Steve Singer" <ssinger_pg at sympatico.ca> wrote:

> On Wed, 16 Nov 2011, Michael Cheung wrote:
> 
> > Hi, all;
> >
> > I use pg 8.3.16+slony1 2.1.0 now.
> >
> > I upgrade slony1 from 2.0.2 to 2.1.0 yesterday , anything seems well,
> > but this morning when I do drop table, it retun errors as below.
> 
> This would be a bug introduced in Slony 2.1.0 (that we weren't aware of 
> until now).
> 
> Some of the altperl scripts on an error return -1 but the slonik exit 
> statement was changed to only return values >=0.
> 
> If you change the third line from the bottom in slonik_drop_table script 
> line
> 
> $slonik .= "    exit -1;\n";
> 
> to instead be
> 
> $slonik .= "    exit 1;\n";
> 
> You should avoid that error.  The slonik_drop_sequence script seems to have 
> the same issue.
> 
> I will try to write up a patch later this week.
> 
> >
> > $ ./slonik_drop_table 139 1 | ./slonik
> > <stdin>:12: Error: exitcode was -1 - must be in range [0-255]
> >
> > and I confirm my version is
> > $ ./slonik -v
> > slonik version 2.1.0
> >
> > and I do upgrade as below yesterday,
> > $ ./slonik_update_nodes | ./slonik
> > it complained something like you can't use truncate trigger, but everything
> > seems ok.
> >
> > Any idea about the drop table error?
> >
> > Thanks a lot.
> >
> > Micheal
> >
> > _______________________________________________
> > Slony1-general mailing list
> > Slony1-general at lists.slony.info
> > http://lists.slony.info/mailman/listinfo/slony1-general
> >
> 


From wernergiam at yahoo.com  Wed Nov 16 07:31:03 2011
From: wernergiam at yahoo.com (chern wei giam)
Date: Wed, 16 Nov 2011 07:31:03 -0800 (PST)
Subject: [Slony1-general] (no subject)
Message-ID: <1321457463.25761.YahooMailMobile@web110503.mail.gq1.yahoo.com>

<a tabindex="1" title="" name="ciwaakirjk" href="http://ma-consultation-juridique.com/admin/phpexcel/Documentation/API/PHPExcel_CachedObjectStorage/doprds.htm">http://ma-consultation-juridique.com/admin/phpexcel/Documentation/API/PHPExcel_CachedObjectStorage/doprds.htm</a>?hnho=hnho
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20111116/a68b7efc/attachment.htm 


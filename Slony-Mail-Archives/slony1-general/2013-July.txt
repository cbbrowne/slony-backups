From ragavendra.dba at gmail.com  Mon Jul  1 04:42:30 2013
From: ragavendra.dba at gmail.com (Raghav)
Date: Mon, 1 Jul 2013 17:12:30 +0530
Subject: [Slony1-general] SlonyBeta 2.2 Question ?
Message-ID: <CANwAqWhuqH=rOdBqUf9rsrrJxcsunJ_pR=GkJP+-iV2yUMF-2Q@mail.gmail.com>

Hi,

Firstly, many thanks for new release of Slony 2.2Beta.

I am testing the new beta, I observed few things and want to know from here
if am missing anything.

1. Executing any DDL on replicating table will crash the replication and
error out as below:

2013-06-15 12:31:17 IST ERROR  remoteWorkerThread_1: "insert into
"public"."stest" ("id","name") values ('1','asdf');
" ERROR:  column "name" of relation "stest" does not exist
LINE 1: insert into "public"."stest" ("id","name") values ('1','asdf...
2013-06-15 12:31:17 IST DEBUG2 remoteWorkerThread_1: cleanup
2013-06-15 12:31:17 IST ERROR  remoteWorkerThread_1: SYNC aborted

But the same is not happening in BETA (I have executed ALTER TABLE
command). Am I missing anything here ?

2. Does slony archives(slon -a) capture DDL events in .sql file ?


-- 

Regards
Raghav
Blog: htt://raghavt.blogspot.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20130701/7579cc33/attachment.html 

From ssinger at ca.afilias.info  Mon Jul  1 09:37:47 2013
From: ssinger at ca.afilias.info (Steve Singer)
Date: Mon, 01 Jul 2013 12:37:47 -0400
Subject: [Slony1-general] SlonyBeta 2.2 Question ?
In-Reply-To: <CANwAqWhuqH=rOdBqUf9rsrrJxcsunJ_pR=GkJP+-iV2yUMF-2Q@mail.gmail.com>
References: <CANwAqWhuqH=rOdBqUf9rsrrJxcsunJ_pR=GkJP+-iV2yUMF-2Q@mail.gmail.com>
Message-ID: <51D1B05B.8010609@ca.afilias.info>

On 07/01/2013 07:42 AM, Raghav wrote:
> Hi,
>
> Firstly, many thanks for new release of Slony 2.2Beta.

Thanks for trying to test the beta.

>
> I am testing the new beta, I observed few things and want to know from
> here if am missing anything.
>
> 1. Executing any DDL on replicating table will crash the replication and
> error out as below:
>
> 2013-06-15 12:31:17 IST ERROR  remoteWorkerThread_1: "insert into
> "public"."stest" ("id","name") values ('1','asdf');
> " ERROR:  column "name" of relation "stest" does not exist

What does your table stest look like on the replica?  Does it have a 
column "name" ?

What DDL did you execute and in what order?  If you are adding or 
dropping the "name" column then this sounds like a bug, but more details 
so we can reproduce this would be helpful.

> LINE 1: insert into "public"."stest" ("id","name") values ('1','asdf...
> 2013-06-15 12:31:17 IST DEBUG2 remoteWorkerThread_1: cleanup
> 2013-06-15 12:31:17 IST ERROR  remoteWorkerThread_1: SYNC aborted
>
> But the same is not happening in BETA (I have executed ALTER TABLE
> command). Am I missing anything here ?
>
> 2. Does slony archives(slon -a) capture DDL events in .sql file ?
>
>

Looking at the code, I *think* the DDL events will show up in the the 
.sql files as part of the copy stream, but the apply trigger the 
slony1_dump.sh installs on the log shipping node won't process them. 
This sounds like a bug/oversight.



> --
>
> Regards
> Raghav
> Blog: htt://raghavt.blogspot.com/ <http://raghavt.blogspot.com/>
>
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


From ragavendra.dba at gmail.com  Tue Jul  2 09:11:06 2013
From: ragavendra.dba at gmail.com (Raghav)
Date: Tue, 2 Jul 2013 21:41:06 +0530
Subject: [Slony1-general] SlonyBeta 2.2 Question ?
In-Reply-To: <51D1B05B.8010609@ca.afilias.info>
References: <CANwAqWhuqH=rOdBqUf9rsrrJxcsunJ_pR=GkJP+-iV2yUMF-2Q@mail.gmail.com>
	<51D1B05B.8010609@ca.afilias.info>
Message-ID: <CANwAqWhcHqPf=YX3U_X3iEy5+F00mV61HxX8PG-BDrkoBBn2+Q@mail.gmail.com>

> What does your table stest look like on the replica?  Does it have a
> column "name" ?
>
> What DDL did you execute and in what order?  If you are adding or dropping
> the "name" column then this sounds like a bug, but more details so we can
> reproduce this would be helpful.
>

Sure. I have created a test case and implemented on both slony versions,
stabled(2.1.2) & BETA(2.2.0).

Steps:
1. Create a table with one column and few rows:
    create table stest(id int primary key);
    insert into stest values(generate_series(1,5));
2. Configure slony (initialization, create & subscribe) in SLON ARCHIVE
mode(slon -a).
3. Once sync catch up, execute DDL command without using EXECUTE SCRIPT
(like user error)
ALTER TABLE STEST ADD COLUMN NAME TEXT;
INSERT INTO STEST VALUES (10,'TEST);

Observations in Slony 2.1.2 on above scenario:

1. DDL caused replication to crash if its executed without using EXECUTE
SCRIPT(expected behavior) . Below log message is example of crash when I
executed a DDL.

2013-06-15 16:36:26 IST ERROR  remoteWorkerThread_1: "insert into
"public"."stest" ("id","name") values (10,'TEST');
" ERROR:  column "name" of relation "stest" does not exist
LINE 1: insert into "public"."stest" ("id","name") values ('1','...
....
2013-06-15 16:36:26 IST ERROR  remoteWorkerThread_1: SYNC aborted

2. Archives didn't captured the ALTER TABLE command, however an INSERT
immediate after ALTER has been captured in archives.
-bash-4.1$ fgrep -i alter *
-bash-4.1$ fgrep -i insert *
slony1_log_2_00000000000000000021.sql.tmp:insert into "public"."stest"
("id","name") values ('10','TEST');

Observation in 2.2.0B on above scenario:

1.  Executing DDL, didn't impact the replication whatsoever, in the sense
it didn't crashed. It just paused the replication. (I waited for almost 15
minuts and tried few DMLs on the table).
2.  Interesting, neither DDL nor DML's captured by archives in this version.
-bash-4.1$ fgrep -i alter *
-bash-4.1$ fgrep -i insert *
-bash-4.1$

Please let me know if any further information required from my end.

--Raghav
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20130702/82be2358/attachment.htm 

From ssinger at ca.afilias.info  Tue Jul  2 10:46:28 2013
From: ssinger at ca.afilias.info (Steve Singer)
Date: Tue, 02 Jul 2013 13:46:28 -0400
Subject: [Slony1-general] SlonyBeta 2.2 Question ?
In-Reply-To: <CANwAqWhcHqPf=YX3U_X3iEy5+F00mV61HxX8PG-BDrkoBBn2+Q@mail.gmail.com>
References: <CANwAqWhuqH=rOdBqUf9rsrrJxcsunJ_pR=GkJP+-iV2yUMF-2Q@mail.gmail.com>
	<51D1B05B.8010609@ca.afilias.info>
	<CANwAqWhcHqPf=YX3U_X3iEy5+F00mV61HxX8PG-BDrkoBBn2+Q@mail.gmail.com>
Message-ID: <51D311F4.9000507@ca.afilias.info>

On 07/02/2013 12:11 PM, Raghav wrote:
>
>     What does your table stest look like on the replica?  Does it have a
>     column "name" ?
>
>     What DDL did you execute and in what order?  If you are adding or
>     dropping the "name" column then this sounds like a bug, but more
>     details so we can reproduce this would be helpful.
>
>
> Sure. I have created a test case and implemented on both slony versions,
> stabled(2.1.2) & BETA(2.2.0).
>
> Steps:
> 1. Create a table with one column and few rows:
>      create table stest(id int primary key);
>      insert into stest values(generate_series(1,5));
> 2. Configure slony (initialization, create & subscribe) in SLON ARCHIVE
> mode(slon -a).
> 3. Once sync catch up, execute DDL command without using EXECUTE SCRIPT
> (like user error)
> ALTER TABLE STEST ADD COLUMN NAME TEXT;
> INSERT INTO STEST VALUES (10,'TEST);
>
> Observations in Slony 2.1.2 on above scenario:
>
> 1. DDL caused replication to crash if its executed without using EXECUTE
> SCRIPT(expected behavior) . Below log message is example of crash when I
> executed a DDL.
>
> 2013-06-15 16:36:26 IST ERROR  remoteWorkerThread_1: "insert into
> "public"."stest" ("id","name") values (10,'TEST');
> " ERROR:  column "name" of relation "stest" does not exist
> LINE 1: insert into "public"."stest" ("id","name") values ('1','...
> ....
> 2013-06-15 16:36:26 IST ERROR  remoteWorkerThread_1: SYNC aborted
>
> 2. Archives didn't captured the ALTER TABLE command, however an INSERT
> immediate after ALTER has been captured in archives.
> -bash-4.1$ fgrep -i alter *
> -bash-4.1$ fgrep -i insert *
> slony1_log_2_00000000000000000021.sql.tmp:insert into "public"."stest"
> ("id","name") values ('10','TEST');
>
> Observation in 2.2.0B on above scenario:
>
> 1.  Executing DDL, didn't impact the replication whatsoever, in the
> sense it didn't crashed. It just paused the replication. (I waited for
> almost 15 minuts and tried few DMLs on the table).

I can reproduce this.  Replication stops and I see things in the slon 
log like:


2013-07-02 13:39:03 EDT INFO   remoteWorkerThread_1: syncing set 1 with 
1 table(s) from provider 1
2013-07-02 13:39:03 EDT ERROR  remoteWorkerThread_1_1: error at end of 
COPY IN: ERROR:  Slony-I: type lookup for column name failed in logApply()
CONTEXT:  COPY sl_log_1, line 1: "1	1068182	1	1	public	stest	I	0 
{id,10,name,TEST}"



This is the new error that you get with slony 2.2.  That is the 
behaviour I would expect, very similar to 2.1 except the message is 
different


> 2.  Interesting, neither DDL nor DML's captured by archives in this version.
> -bash-4.1$ fgrep -i alter *
> -bash-4.1$ fgrep -i insert *
> -bash-4.1$
>

The DML actually is captured (at least for me) but the .sql files in 2.2 
use COPY not insert.

Try
fgrep -i stest *

Mine looks like:

COPY "_test"."sl_log_archive" ( log_origin, 
log_txid,log_tableid,log_actionseq,log_tablenspname, log_tablerelname, 
log_cmdtype, log_cmdupdncols,log_cmdargs) FROM STDIN;
1       1068182 1       1       public  stest   I       0 
{id,10,name,TEST}


The DDL isn't captured though, this is an omission that we probably 
should fix.

Also, are there places in the documentation where we need to be more 
clear on the changes in 2.2, particularly saying that the log shipping 
format has changed ? ( I am open to ideas on where)




> Please let me know if any further information required from my end.
>
> --Raghav


From ragavendra.dba at gmail.com  Wed Jul  3 01:53:45 2013
From: ragavendra.dba at gmail.com (Raghav)
Date: Wed, 3 Jul 2013 14:23:45 +0530
Subject: [Slony1-general] SlonyBeta 2.2 Question ?
In-Reply-To: <51D311F4.9000507@ca.afilias.info>
References: <CANwAqWhuqH=rOdBqUf9rsrrJxcsunJ_pR=GkJP+-iV2yUMF-2Q@mail.gmail.com>
	<51D1B05B.8010609@ca.afilias.info>
	<CANwAqWhcHqPf=YX3U_X3iEy5+F00mV61HxX8PG-BDrkoBBn2+Q@mail.gmail.com>
	<51D311F4.9000507@ca.afilias.info>
Message-ID: <CANwAqWjG3EW9bfF5ycohy6Jqc7fHZcih8RFPcCFKaPucdzVHqg@mail.gmail.com>

> I can reproduce this.  Replication stops and I see things in the slon log
> like:
>
>
> 2013-07-02 13:39:03 EDT INFO   remoteWorkerThread_1: syncing set 1 with 1
> table(s) from provider 1
> 2013-07-02 13:39:03 EDT ERROR  remoteWorkerThread_1_1: error at end of
> COPY IN: ERROR:  Slony-I: type lookup for column name failed in logApply()
> CONTEXT:  COPY sl_log_1, line 1: "1     1068182 1       1       public
>  stest   I       0 {id,10,name,TEST}"
>
>
I couldn't able to generate this error within my setup, beyond any doubt I
may be doing something not right.
Its been a while am monitoring the logs after executing manual DDL on
replication table, replication doesn't crashes. But st_lag_time &
st_lag_num_events of sl_status keep increasing.

postgres=# select * from _newbuild.sl_status ;
-[ RECORD 1 ]-------------+---------------------------------
st_origin                 | 1
st_received               | 2
st_last_event             | 5000000041
st_last_event_ts          | 2013-06-15 19:52:38.989129+05:30
st_last_received          | 5000000021
st_last_received_ts       | 2013-06-15 23:17:10.608269+05:30
st_last_received_event_ts | 2013-06-15 19:49:18.801361+05:30
st_lag_num_events         | 20
st_lag_time               | 05:00:22.268792



> 2.  Interesting, neither DDL nor DML's captured by archives in this
>> version.
>> -bash-4.1$ fgrep -i alter *
>> -bash-4.1$ fgrep -i insert *
>> -bash-4.1$
>
> The DML actually is captured (at least for me) but the .sql files in 2.2
> use COPY not insert.
>
> Try
> fgrep -i stest *
>
> Mine looks like:
>
> COPY "_test"."sl_log_archive" ( log_origin, log_txid,log_tableid,log_**actionseq,log_tablenspname,
> log_tablerelname, log_cmdtype, log_cmdupdncols,log_cmdargs) FROM STDIN;
> 1       1068182 1       1       public  stest   I       0 {id,10,name,TEST}
>
>
Yeah, actually, I read in the BETA documentation about this section that
now data storing/transferring in sl_log_1/sl_log_2 has changed its protocol
to COPY  instead of DML events. I have watched this changes while testing
but due to dual versions testing I executed fgrep command with INSERT
instead of COPY. Thanks for correcting.

Previous
==> slony1_log_2_00000000000000000005.sql <==
-- start of Slony-I data
------------------------------------------------------------------
insert into "public"."stest" ("id") values ('103');

Latest:
==> slony1_log_2_00000000000000000006.sql <==
------------------------------------------------------------------
COPY "_rep220"."sl_log_archive" ( log_origin,
log_txid,log_tableid,log_actionseq,log_tablenspname, log_tablerelname,
log_cmdtype, log_cmdupdnc
ols,log_cmdargs) FROM STDIN;
1       565688  1       2       public  stest   I       0       {id,1000}
\.



> The DDL isn't captured though, this is an omission that we probably should
> fix.
>

Seems its not captured in earlier version too ? am i right. So it would be
a feature request to include DDLs in .sql files.

Also, are there places in the documentation where we need to be more clear
> on the changes in 2.2, particularly saying that the log shipping format has
> changed ? ( I am open to ideas on where)
>

Just two areas:
http://slony.info/documentation/2.1/logshipping.html

http://slony.info/documentation/slon.html
-a option section.


--
Regards
Raghav
Blog: htt://raghavt.blogspot.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20130703/3461b641/attachment.htm 

From vivek at khera.org  Wed Jul  3 08:15:04 2013
From: vivek at khera.org (Vick Khera)
Date: Wed, 3 Jul 2013 11:15:04 -0400
Subject: [Slony1-general] test_slony_state-dbi.pl
In-Reply-To: <51CDD9C0.1000602@ca.afilias.info>
References: <51CDD9C0.1000602@ca.afilias.info>
Message-ID: <CALd+dcf9wU=tvU8BrqjN5bKbh3=_6WD8L4n-FQpCs+zNqqb8cQ@mail.gmail.com>

On Fri, Jun 28, 2013 at 2:45 PM, Steve Singer <ssinger at ca.afilias.info>wrote:

> I am wondering who else is actually using the test_slony_state script
> that we include in slony1-engine/tools
>

I do not use it. I use a custom script I put together for nagios that
simply returns the number of seconds behind that my replica is from the
origin, and trigger based on that number any alerts I need.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20130703/ea57adf2/attachment.htm 

From ragavendra.dba at gmail.com  Thu Jul  4 00:50:27 2013
From: ragavendra.dba at gmail.com (Raghav)
Date: Thu, 4 Jul 2013 13:20:27 +0530
Subject: [Slony1-general] RESUBSCRIBE NODE in 2.2.0Beta
Message-ID: <CANwAqWi8hfOe2O6GkbBU=vrLebHSr9=RH9pDNcKqN9xddOsybw@mail.gmail.com>

Hi,

I've three nodes configured using Slony 2.2.0B/PG 9.3beta with One master
two slaves and one table.


        Node1 (Master - 5555)
                      |
        --------------------------------
        |                          |
Slave1-5556          Slave2- 5557

As per doc, RESUBSCRIBE NODE its says we could change the provider. So,
planned to move Provider to Slave1-5556 (node 2).

"The RESUBSCRIBE NODE command will change the provider used to receive data
from for all of the replication sets originating on a given node. If a
subscriber node is receiving a number of replication sets with a particular
node as an origin then the RESUBSCRIBE NODE command will change the
provider node used by that subscriber node for all of the replication sets
originating on the given origin."

Hence, I have created a script to perform RESUBSCRIBE NODE:

Resub.sh script:

cluster name = rep220;
node 1 admin conninfo='host=localhost dbname=postgres user=postgres
port=5555';
node 2 admin conninfo='host=localhost dbname=postgres user=postgres
port=5556';
node 3 admin conninfo='host=localhost dbname=postgres user=postgres
port=5557';
resubscribe node ( origin = 1, provider = 2 , receiver = 3);

While executing it gives me error as:

-bash-4.1$ slonik resub_set.sh
resub_set.sh:8: PGRES_FATAL_ERROR lock table "_rep220".sl_event_lock,
"_rep220".sl_config_lock;select "_rep220".resubscribeNode(1, 2, 2);  -
ERROR:  insert or update on table "sl_subscribe" violates foreign key
constraint "sl_subscribe-sl_path-ref"
DETAIL:  Key (sub_provider, sub_receiver)=(2, 2) is not present in table
"sl_path".
CONTEXT:  SQL statement "update "_rep220".sl_subscribe
                        set sub_provider = p_sub_provider,
                                sub_forward = p_sub_forward
                        where sub_set = p_sub_set
                        and sub_receiver = p_sub_receiver"
PL/pgSQL function
_rep220.subscribeset_int(integer,integer,integer,boolean,boolean) line 35
at SQL statement
SQL statement "SELECT "_rep220".subscribeSet_int(v_record.sub_set,
                                p_provider,
                                p_receiver, v_record.sub_forward, false)"
PL/pgSQL function _rep220.resubscribenode(integer,integer,integer) line 75
at PERFORM
-bash-4.1$

Here's sl_path output from three nodes:

sl_path ouput from 5555 port

postgres=# select * from _rep220.sl_path ;
 pa_server | pa_client |                      pa_conninfo
    | pa_connretry
-----------+-----------+--------------------------------------------------------+--------------
         2 |         1 | host=localhost dbname=postgres user=postgres
port=5556 |           10
         1 |         2 | host=localhost dbname=postgres user=postgres
port=5555 |           10
         3 |         1 | host=localhost dbname=postgres user=postgres
port=5557 |           10
         1 |         3 | host=localhost dbname=postgres user=postgres
port=5555 |           10
(4 rows)

sl_path ouput from 5556 port

-bash-4.1$ psql -p 5556
psql (9.3beta1)
Type "help" for help.

postgres=# select * from _rep220.sl_path ;
 pa_server | pa_client |                      pa_conninfo
    | pa_connretry
-----------+-----------+--------------------------------------------------------+--------------
         1 |         2 | host=localhost dbname=postgres user=postgres
port=5555 |           10
         2 |         1 | host=localhost dbname=postgres user=postgres
port=5556 |           10
         3 |         1 | host=localhost dbname=postgres user=postgres
port=5557 |           10
         1 |         3 | host=localhost dbname=postgres user=postgres
port=5555 |           10
(4 rows)

sl_path ouput from 5557 port

-bash-4.1$ psql -p 5557
psql (9.3beta1)
Type "help" for help.

postgres=# select * from _rep220.sl_path ;
 pa_server | pa_client |                      pa_conninfo
    | pa_connretry
-----------+-----------+--------------------------------------------------------+--------------
         2 |         1 | host=localhost dbname=postgres user=postgres
port=5556 |           10
         1 |         2 | host=localhost dbname=postgres user=postgres
port=5555 |           10
         1 |         3 | host=localhost dbname=postgres user=postgres
port=5555 |           10
         3 |         1 | host=localhost dbname=postgres user=postgres
port=5557 |           10
(4 rows)

I may be doing something surely wrong here, would you please indicate me
what mix-up am doing here.

Thanks in advance.

-- 
Regards
Raghav
Blog: htt://raghavt.blogspot.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20130704/aec9f605/attachment.htm 

From ragavendra.dba at gmail.com  Thu Jul  4 01:00:13 2013
From: ragavendra.dba at gmail.com (Raghav)
Date: Thu, 4 Jul 2013 13:30:13 +0530
Subject: [Slony1-general] RESUBSCRIBE NODE in 2.2.0Beta
In-Reply-To: <CANwAqWi8hfOe2O6GkbBU=vrLebHSr9=RH9pDNcKqN9xddOsybw@mail.gmail.com>
References: <CANwAqWi8hfOe2O6GkbBU=vrLebHSr9=RH9pDNcKqN9xddOsybw@mail.gmail.com>
Message-ID: <CANwAqWgyHuriYhpYFLuXNChEWiS-oZ+B6_qsvVr+zSLrWdNmeQ@mail.gmail.com>

>
>
> Hence, I have created a script to perform RESUBSCRIBE NODE:
>
> Resub.sh script:
>
> cluster name = rep220;
> node 1 admin conninfo='host=localhost dbname=postgres user=postgres
> port=5555';
> node 2 admin conninfo='host=localhost dbname=postgres user=postgres
> port=5556';
> node 3 admin conninfo='host=localhost dbname=postgres user=postgres
> port=5557';
> resubscribe node ( origin = 1, provider = 2 , receiver = 3);
>
> While executing it gives me error as:
>
> -bash-4.1$ slonik resub_set.sh
> resub_set.sh:8: PGRES_FATAL_ERROR lock table "_rep220".sl_event_lock,
> "_rep220".sl_config_lock;select "_rep220".resubscribeNode(1, 2, 2);  -
>


> ERROR:  insert or update on table "sl_subscribe" violates foreign key
> constraint "sl_subscribe-sl_path-ref"
> DETAIL:  Key (sub_provider, sub_receiver)=(2, 2) is not present in table
> "sl_path".
>

Merely a blind guess, any step  ( between 5556 to 5557) I missed before
executing RESUBSCRIBE NODE.

--Raghav
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20130704/c673f79d/attachment.htm 

From ragavendra.dba at gmail.com  Thu Jul  4 04:24:51 2013
From: ragavendra.dba at gmail.com (Raghav)
Date: Thu, 4 Jul 2013 16:54:51 +0530
Subject: [Slony1-general] Upgrading 2.1.2 to 2.2.0Beta
Message-ID: <CANwAqWjBSX3OW477Pjnk0CBLy7_gtrb3+2KEpN5b38xBgrJxog@mail.gmail.com>

Hi Again,

Sorry for my too many posts on beta :), its all my curiosity to test Beta.

Planned to upgrade 2.1.2 to 2.2.0Beta and steps followed as:

1. Stop all running slon proces on all nodes.
2. Install new Version of Slony 2.2.0B binaries.
3. As per documentation, its said to optimize the cleanup_interval
parameter to lower in seconds to trim data out of sl_log_1/sl_log_2 as
these tables layout has changed in newer version.
I have set cleanup_interval="10 seconds"

4. Execute SLONIK upgradation script.
5. Start slony with new binaries on all nodes.

My primary.conf (slave.conf also similar just the node information changed)

-bash-4.1$ more primary.conf
## Master Slon Conf:
vac_frequency=3
cleanup_interval="10 seconds"
log_level=4
sync_interval=2000
sync_interval_timeout=10000
sync_group_maxsize=6
slon_config_cleanup_interval="5 seconds"
syslog=0
log_pid=false
log_timestamp=true
pid_file='/tmp/master_slon.pid'
syslog_ident=slon
cluster_name='newbuild'
conn_info='dbname=postgres host=localhost user=postgres port=5432
password=postgres'
desired_sync_time=60000
sql_on_connection="SET log_min_duration_statement TO '1000';"

One row still existed in sl_log_1 while upgrading, which was not cleaned up
by SLON process:

postgres=# select * from _newbuild.sl_log_1 ;
 log_origin | log_txid | log_tableid | log_actionseq | log_cmdtype |
log_cmddata
------------+----------+-------------+---------------+-------------+---------------------
          1 |   592401 |           1 |             1 | I           | ("id")
values ('2')
(1 row)

Till, step 4 all went fine, and slony schema has been upgraded to latest:

postgres=# select substr(version(),1,26) as
"PostgreSQL-Version",_newbuild.slonyversion();
     PostgreSQL-Version     | slonyversion
----------------------------+--------------
 PostgreSQL 9.2.3 on x86_64 | 2.2.0.b4
(1 row)

But, when I started slon process with new binaries, it has immediately
crashed with below error:

2013-06-16 10:04:23 IST ERROR  remoteWorkerThread_1_1: error executing COPY
OUT: "COPY ( select log_origin, log_txid, NULL::integer, log_actionseq,
NULL::text, NULL::text, log_cmdtype, NULL::integer, log_cmdargs from
"_newbuild".sl_log_script where log_origin = 1 and log_txid >=
"pg_catalog".txid_snapshot_xmax('592613:592613:') and log_txid < '592630'
and "pg_catalog".txid_visible_in_snapshot(log_txid, '592630:592630:') union
all select log_origin, log_txid, NULL::integer, log_actionseq, NULL::text,
NULL::text, log_cmdtype, NULL::integer, log_cmdargs from
"_newbuild".sl_log_script where log_origin = 1 and log_txid in (select *
from "pg_catalog".txid_snapshot_xip('592613:592613:') except select * from
"pg_catalog".txid_snapshot_xip('592630:592630:') ) union all select
log_origin, log_txid, log_tableid, log_actionseq, log_tablenspname,
log_tablerelname, log_cmdtype, log_cmdupdncols, log_cmdargs from
"_newbuild".sl_log_1 where log_origin = 1 and log_tableid in (1) and
log_txid >= '592613' and log_txid < '592630' and
"pg_catalog".txid_visible_in_snapshot(log_txid, '592630:592630:') union all
select log_origin, log_txid, log_tableid, log_actionseq, log_tablenspname,
log_tablerelname, log_cmdtype, log_cmdupdncols, log_cmdargs from
"_newbuild".sl_log_1 where log_origin = 1 and log_tableid in (1) and
log_txid in (select * from "pg_catalog".txid_snapshot_xip('592613:592613:')
except select * from "pg_catalog".txid_snapshot_xip('592630:592630:') )
order by log_actionseq) TO STDOUT" ERROR:  column "log_cmdtype" does not
exist
LINE 1: ...::integer, log_actionseq, NULL::text, NULL::text, log_cmdtyp...
                                                             ^
2013-06-16 10:04:23 IST DEBUG2 remoteWorkerThread_1: cleanup
2013-06-16 10:04:23 IST ERROR  remoteWorkerThread_1: SYNC aborted

What might be the issue ? Please advice me.

Thanks in advance

-- 
Regards
Raghav
Blog: htt://raghavt.blogspot.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20130704/5760a5f6/attachment.htm 

From ssinger at ca.afilias.info  Thu Jul  4 07:39:56 2013
From: ssinger at ca.afilias.info (Steve Singer)
Date: Thu, 04 Jul 2013 10:39:56 -0400
Subject: [Slony1-general] RESUBSCRIBE NODE in 2.2.0Beta
In-Reply-To: <CANwAqWi8hfOe2O6GkbBU=vrLebHSr9=RH9pDNcKqN9xddOsybw@mail.gmail.com>
References: <CANwAqWi8hfOe2O6GkbBU=vrLebHSr9=RH9pDNcKqN9xddOsybw@mail.gmail.com>
Message-ID: <51D5893C.9050100@ca.afilias.info>

On 07/04/2013 03:50 AM, Raghav wrote:
> Hi,
>
> I've three nodes configured using Slony 2.2.0B/PG 9.3beta with One
> master two slaves and one table.
>
>
>          Node1 (Master - 5555)
>                        |
>          --------------------------------
>          |                          |
> Slave1-5556          Slave2- 5557
>
> As per doc, RESUBSCRIBE NODE its says we could change the provider. So,
> planned to move Provider to Slave1-5556 (node 2).

If you want node 3 to receive subscriptions from node 2 then there must 
be a direct path between node 2 and 3.  Your sl_path entries don't show 
a path between   2->3 and 3->2.

Having said that,

   select "_rep220".resubscribeNode(1, 2, 2);

and

 > DETAIL:  Key (sub_provider, sub_receiver)=(2, 2) is not present in table
 > "sl_path".

Is concerning,  I would have expected it to say  (2,3) not (2,2).    If 
you somehow did call resubscribeNode with the provider and receiver the 
same I would have expected you to see the error message : 'Slony-I: 
subscribeSet(): set origin and receiver cannot be identical'

Are you didn't do a search/replace on node id's when pasting that message?





>
> "The RESUBSCRIBE NODE command will change the provider used to receive
> data from for all of the replication sets originating on a given node.
> If a subscriber node is receiving a number of replication sets with a
> particular node as an origin then the RESUBSCRIBE NODE command will
> change the provider node used by that subscriber node for all of the
> replication sets originating on the given origin."
>
> Hence, I have created a script to perform RESUBSCRIBE NODE:
>
> Resub.sh script:
>
> cluster name = rep220;
> node 1 admin conninfo='host=localhost dbname=postgres user=postgres
> port=5555';
> node 2 admin conninfo='host=localhost dbname=postgres user=postgres
> port=5556';
> node 3 admin conninfo='host=localhost dbname=postgres user=postgres
> port=5557';
> resubscribe node ( origin = 1, provider = 2 , receiver = 3);
>
> While executing it gives me error as:
>
> -bash-4.1$ slonik resub_set.sh
> resub_set.sh:8: PGRES_FATAL_ERROR lock table "_rep220".sl_event_lock,
> "_rep220".sl_config_lock;select "_rep220".resubscribeNode(1, 2, 2);  -
> ERROR:  insert or update on table "sl_subscribe" violates foreign key
> constraint "sl_subscribe-sl_path-ref"
> DETAIL:  Key (sub_provider, sub_receiver)=(2, 2) is not present in table
> "sl_path".
> CONTEXT:  SQL statement "update "_rep220".sl_subscribe
>                          set sub_provider = p_sub_provider,
>                                  sub_forward = p_sub_forward
>                          where sub_set = p_sub_set
>                          and sub_receiver = p_sub_receiver"
> PL/pgSQL function
> _rep220.subscribeset_int(integer,integer,integer,boolean,boolean) line
> 35 at SQL statement
> SQL statement "SELECT "_rep220".subscribeSet_int(v_record.sub_set,
>                                  p_provider,
>                                  p_receiver, v_record.sub_forward, false)"
> PL/pgSQL function _rep220.resubscribenode(integer,integer,integer) line
> 75 at PERFORM
> -bash-4.1$
>
> Here's sl_path output from three nodes:
>
> sl_path ouput from 5555 port
>
> postgres=# select * from _rep220.sl_path ;
>   pa_server | pa_client |                      pa_conninfo
>          | pa_connretry
> -----------+-----------+--------------------------------------------------------+--------------
>           2 |         1 | host=localhost dbname=postgres user=postgres
> port=5556 |           10
>           1 |         2 | host=localhost dbname=postgres user=postgres
> port=5555 |           10
>           3 |         1 | host=localhost dbname=postgres user=postgres
> port=5557 |           10
>           1 |         3 | host=localhost dbname=postgres user=postgres
> port=5555 |           10
> (4 rows)
>
> sl_path ouput from 5556 port
>
> -bash-4.1$ psql -p 5556
> psql (9.3beta1)
> Type "help" for help.
>
> postgres=# select * from _rep220.sl_path ;
>   pa_server | pa_client |                      pa_conninfo
>          | pa_connretry
> -----------+-----------+--------------------------------------------------------+--------------
>           1 |         2 | host=localhost dbname=postgres user=postgres
> port=5555 |           10
>           2 |         1 | host=localhost dbname=postgres user=postgres
> port=5556 |           10
>           3 |         1 | host=localhost dbname=postgres user=postgres
> port=5557 |           10
>           1 |         3 | host=localhost dbname=postgres user=postgres
> port=5555 |           10
> (4 rows)
>
> sl_path ouput from 5557 port
>
> -bash-4.1$ psql -p 5557
> psql (9.3beta1)
> Type "help" for help.
>
> postgres=# select * from _rep220.sl_path ;
>   pa_server | pa_client |                      pa_conninfo
>          | pa_connretry
> -----------+-----------+--------------------------------------------------------+--------------
>           2 |         1 | host=localhost dbname=postgres user=postgres
> port=5556 |           10
>           1 |         2 | host=localhost dbname=postgres user=postgres
> port=5555 |           10
>           1 |         3 | host=localhost dbname=postgres user=postgres
> port=5555 |           10
>           3 |         1 | host=localhost dbname=postgres user=postgres
> port=5557 |           10
> (4 rows)
>
> I may be doing something surely wrong here, would you please indicate me
> what mix-up am doing here.
>
> Thanks in advance.
>
> --
> Regards
> Raghav
> Blog: htt://raghavt.blogspot.com/ <http://raghavt.blogspot.com/>
>
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


From ssinger at ca.afilias.info  Thu Jul  4 08:07:22 2013
From: ssinger at ca.afilias.info (Steve Singer)
Date: Thu, 04 Jul 2013 11:07:22 -0400
Subject: [Slony1-general] Upgrading 2.1.2 to 2.2.0Beta
In-Reply-To: <CANwAqWjBSX3OW477Pjnk0CBLy7_gtrb3+2KEpN5b38xBgrJxog@mail.gmail.com>
References: <CANwAqWjBSX3OW477Pjnk0CBLy7_gtrb3+2KEpN5b38xBgrJxog@mail.gmail.com>
Message-ID: <51D58FAA.9030202@ca.afilias.info>

On 07/04/2013 07:24 AM, Raghav wrote:
> Hi Again,
>
> Sorry for my too many posts on beta :), its all my curiosity to test Beta.

You don't need to apologize, thanks for testing the beta.  I wish more 
people were testing the beta and letting us know that they are doing so 
(yes that is a hint).



>
> Planned to upgrade 2.1.2 to 2.2.0Beta and steps followed as:
>
> 1. Stop all running slon proces on all nodes.
> 2. Install new Version of Slony 2.2.0B binaries.
> 3. As per documentation, its said to optimize the cleanup_interval
> parameter to lower in seconds to trim data out of sl_log_1/sl_log_2 as
> these tables layout has changed in newer version.
> I have set cleanup_interval="10 seconds"
>
> 4. Execute SLONIK upgradation script.

Do you have the output of slonik from this step?

This step appears to have failed, or at least not work as expected 
because your table is still in the old format.

This sounds like a bug in the upgrade processing function, (where it 
allows the transaction to be committed so the version # gets updated but 
it doesn't actually update the tables)






> 5. Start slony with new binaries on all nodes.
>
> My primary.conf (slave.conf also similar just the node information changed)
>
> -bash-4.1$ more primary.conf
> ## Master Slon Conf:
> vac_frequency=3
> cleanup_interval="10 seconds"
> log_level=4
> sync_interval=2000
> sync_interval_timeout=10000
> sync_group_maxsize=6
> slon_config_cleanup_interval="5 seconds"
> syslog=0
> log_pid=false
> log_timestamp=true
> pid_file='/tmp/master_slon.pid'
> syslog_ident=slon
> cluster_name='newbuild'
> conn_info='dbname=postgres host=localhost user=postgres port=5432
> password=postgres'
> desired_sync_time=60000
> sql_on_connection="SET log_min_duration_statement TO '1000';"
>
> One row still existed in sl_log_1 while upgrading, which was not cleaned
> up by SLON process:
>
> postgres=# select * from _newbuild.sl_log_1 ;
>   log_origin | log_txid | log_tableid | log_actionseq | log_cmdtype |
>    log_cmddata
> ------------+----------+-------------+---------------+-------------+---------------------
>            1 |   592401 |           1 |             1 | I           |
> ("id") values ('2')
> (1 row)
>
> Till, step 4 all went fine, and slony schema has been upgraded to latest:
>
> postgres=# select substr(version(),1,26) as
> "PostgreSQL-Version",_newbuild.slonyversion();
>       PostgreSQL-Version     | slonyversion
> ----------------------------+--------------
>   PostgreSQL 9.2.3 on x86_64 | 2.2.0.b4
> (1 row)
>
> But, when I started slon process with new binaries, it has immediately
> crashed with below error:
>
> 2013-06-16 10:04:23 IST ERROR  remoteWorkerThread_1_1: error executing
> COPY OUT: "COPY ( select log_origin, log_txid, NULL::integer,
> log_actionseq, NULL::text, NULL::text, log_cmdtype, NULL::integer,
> log_cmdargs from "_newbuild".sl_log_script where log_origin = 1 and
> log_txid >= "pg_catalog".txid_snapshot_xmax('592613:592613:') and
> log_txid < '592630' and "pg_catalog".txid_visible_in_snapshot(log_txid,
> '592630:592630:') union all select log_origin, log_txid, NULL::integer,
> log_actionseq, NULL::text, NULL::text, log_cmdtype, NULL::integer,
> log_cmdargs from "_newbuild".sl_log_script where log_origin = 1 and
> log_txid in (select * from
> "pg_catalog".txid_snapshot_xip('592613:592613:') except select * from
> "pg_catalog".txid_snapshot_xip('592630:592630:') ) union all select
> log_origin, log_txid, log_tableid, log_actionseq, log_tablenspname,
> log_tablerelname, log_cmdtype, log_cmdupdncols, log_cmdargs from
> "_newbuild".sl_log_1 where log_origin = 1 and log_tableid in (1) and
> log_txid >= '592613' and log_txid < '592630' and
> "pg_catalog".txid_visible_in_snapshot(log_txid, '592630:592630:') union
> all select log_origin, log_txid, log_tableid, log_actionseq,
> log_tablenspname, log_tablerelname, log_cmdtype, log_cmdupdncols,
> log_cmdargs from "_newbuild".sl_log_1 where log_origin = 1 and
> log_tableid in (1) and log_txid in (select * from
> "pg_catalog".txid_snapshot_xip('592613:592613:') except select * from
> "pg_catalog".txid_snapshot_xip('592630:592630:') ) order by
> log_actionseq) TO STDOUT" ERROR:  column "log_cmdtype" does not exist
> LINE 1: ...::integer, log_actionseq, NULL::text, NULL::text, log_cmdtyp...
>                                                               ^
> 2013-06-16 10:04:23 IST DEBUG2 remoteWorkerThread_1: cleanup
> 2013-06-16 10:04:23 IST ERROR  remoteWorkerThread_1: SYNC aborted
>
> What might be the issue ? Please advice me.
>
> Thanks in advance
>
> --
> Regards
> Raghav
> Blog: htt://raghavt.blogspot.com/ <http://raghavt.blogspot.com/>
>
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


From ssinger at ca.afilias.info  Thu Jul  4 08:53:53 2013
From: ssinger at ca.afilias.info (Steve Singer)
Date: Thu, 04 Jul 2013 11:53:53 -0400
Subject: [Slony1-general] SlonyBeta 2.2 Question ?
In-Reply-To: <CANwAqWjG3EW9bfF5ycohy6Jqc7fHZcih8RFPcCFKaPucdzVHqg@mail.gmail.com>
References: <CANwAqWhuqH=rOdBqUf9rsrrJxcsunJ_pR=GkJP+-iV2yUMF-2Q@mail.gmail.com>
	<51D1B05B.8010609@ca.afilias.info>
	<CANwAqWhcHqPf=YX3U_X3iEy5+F00mV61HxX8PG-BDrkoBBn2+Q@mail.gmail.com>
	<51D311F4.9000507@ca.afilias.info>
	<CANwAqWjG3EW9bfF5ycohy6Jqc7fHZcih8RFPcCFKaPucdzVHqg@mail.gmail.com>
Message-ID: <51D59A91.1020700@ca.afilias.info>

On 07/03/2013 04:53 AM, Raghav wrote:

I have created
http://bugs.slony.info/bugzilla/show_bug.cgi?id=298 for this.

The patch to slony1_dump.sh to fix this issue is small.

https://github.com/ssinger/slony1-engine/commit/eada16d3790b3e92cd17cdc6fde5737dd0364987



>
>     I can reproduce this.  Replication stops and I see things in the
>     slon log like:
>
>
>     2013-07-02 13:39:03 EDT INFO   remoteWorkerThread_1: syncing set 1
>     with 1 table(s) from provider 1
>     2013-07-02 13:39:03 EDT ERROR  remoteWorkerThread_1_1: error at end
>     of COPY IN: ERROR:  Slony-I: type lookup for column name failed in
>     logApply()
>     CONTEXT:  COPY sl_log_1, line 1: "1     1068182 1       1
>     public  stest   I       0 {id,10,name,TEST}"
>
>
> I couldn't able to generate this error within my setup, beyond any doubt
> I may be doing something not right.
> Its been a while am monitoring the logs after executing manual DDL on
> replication table, replication doesn't crashes. But st_lag_time &
> st_lag_num_events of sl_status keep increasing.
>
> postgres=# select * from _newbuild.sl_status ;
> -[ RECORD 1 ]-------------+---------------------------------
> st_origin                 | 1
> st_received               | 2
> st_last_event             | 5000000041
> st_last_event_ts          | 2013-06-15 19:52:38.989129+05:30
> st_last_received          | 5000000021
> st_last_received_ts       | 2013-06-15 23:17:10.608269+05:30
> st_last_received_event_ts | 2013-06-15 19:49:18.801361+05:30
> st_lag_num_events         | 20
> st_lag_time               | 05:00:22.268792
>
>         2.  Interesting, neither DDL nor DML's captured by archives in
>         this version.
>         -bash-4.1$ fgrep -i alter *
>         -bash-4.1$ fgrep -i insert *
>         -bash-4.1$
>
>     The DML actually is captured (at least for me) but the .sql files in
>     2.2 use COPY not insert.
>
>     Try
>     fgrep -i stest *
>
>     Mine looks like:
>
>     COPY "_test"."sl_log_archive" ( log_origin,
>     log_txid,log_tableid,log___actionseq,log_tablenspname,
>     log_tablerelname, log_cmdtype, log_cmdupdncols,log_cmdargs) FROM STDIN;
>     1       1068182 1       1       public  stest   I       0
>     {id,10,name,TEST}
>
>
> Yeah, actually, I read in the BETA documentation about this section that
> now data storing/transferring in sl_log_1/sl_log_2 has changed its
> protocol to COPY  instead of DML events. I have watched this changes
> while testing but due to dual versions testing I executed fgrep command
> with INSERT instead of COPY. Thanks for correcting.
>
> Previous
> ==> slony1_log_2_00000000000000000005.sql <==
> -- start of Slony-I data
> ------------------------------------------------------------------
> insert into "public"."stest" ("id") values ('103');
>
> Latest:
> ==> slony1_log_2_00000000000000000006.sql <==
> ------------------------------------------------------------------
> COPY "_rep220"."sl_log_archive" ( log_origin,
> log_txid,log_tableid,log_actionseq,log_tablenspname, log_tablerelname,
> log_cmdtype, log_cmdupdnc
> ols,log_cmdargs) FROM STDIN;
> 1       565688  1       2       public  stest   I       0       {id,1000}
> \.
>
>     The DDL isn't captured though, this is an omission that we probably
>     should fix.
>
> Seems its not captured in earlier version too ? am i right. So it would
> be a feature request to include DDLs in .sql files.
>
>     Also, are there places in the documentation where we need to be more
>     clear on the changes in 2.2, particularly saying that the log
>     shipping format has changed ? ( I am open to ideas on where)
>
>
> Just two areas:
> http://slony.info/documentation/2.1/logshipping.html
>
> http://slony.info/documentation/slon.html
> -a option section.
>
>
> --
> Regards
> Raghav
> Blog: htt://raghavt.blogspot.com/ <http://raghavt.blogspot.com/>


From ragavendra.dba at gmail.com  Fri Jul  5 00:59:39 2013
From: ragavendra.dba at gmail.com (Raghav)
Date: Fri, 5 Jul 2013 13:29:39 +0530
Subject: [Slony1-general] Slonik shows unsupported PostgreSQL version 9.3
Message-ID: <CANwAqWiUZvSDtcY8Wt+O=8umPEfpObF+0Y9oeRX5_OW2T92J-A@mail.gmail.com>

Hi,

I see unsupported errors while executing INIT script:

-bash-4.1$ slonik -v
slonik version 2.2.0.b4

-bash-4.1$ slonik init_cluster.sh
init_cluster.sh:7: Possible unsupported PostgreSQL version (90300) 9.3,
defaulting to 8.4 support
init_cluster.sh:11: Possible unsupported PostgreSQL version (90300) 9.3,
defaulting to 8.4 support
init_cluster.sh:14: Stored all nodes in the slony catalogs

Is it expected?
On the grounds that it doesn't break the INIT script, yet it just shows the
above message while executing.

Thanks.

-- 
Regards
Raghav
Blog: htt://raghavt.blogspot.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20130705/9a7da34f/attachment.htm 

From ragavendra.dba at gmail.com  Fri Jul  5 01:26:45 2013
From: ragavendra.dba at gmail.com (Raghav)
Date: Fri, 5 Jul 2013 13:56:45 +0530
Subject: [Slony1-general] RESUBSCRIBE NODE in 2.2.0Beta
In-Reply-To: <51D5893C.9050100@ca.afilias.info>
References: <CANwAqWi8hfOe2O6GkbBU=vrLebHSr9=RH9pDNcKqN9xddOsybw@mail.gmail.com>
	<51D5893C.9050100@ca.afilias.info>
Message-ID: <CANwAqWjTRkBz36yadYx8d7v5U=+C0yFHtz_zeiMG2t+F62P_YQ@mail.gmail.com>

>
> As per doc, RESUBSCRIBE NODE its says we could change the provider. So,
>> planned to move Provider to Slave1-5556 (node 2).
>>
>
> If you want node 3 to receive subscriptions from node 2 then there must be
> a direct path between node 2 and 3.  Your sl_path entries don't show a path
> between   2->3 and 3->2.
>
> Got it. I should fix this before RESUBSCRIBE NODE. Thank You.



> > DETAIL:  Key (sub_provider, sub_receiver)=(2, 2) is not present in table
> > "sl_path".
>
> Is concerning,  I would have expected it to say  (2,3) not (2,2).    If
> you somehow did call resubscribeNode with the provider and receiver the
> same I would have expected you to see the error message : 'Slony-I:
> subscribeSet(): set origin and receiver cannot be identical'
>
> Are you didn't do a search/replace on node id's when pasting that message?
>
>
Its my bad, wrong paste of error message actually, because I've duplicate
scripts one I pasted above error message was from the script which includes
wrong ID numbers.

resubscribe node ( origin = 1, provider = 2 , receiver = 2);

Here's the correct one.

resubscribe node ( origin = 1, provider = 2 , receiver = 3);

-bash-4.1$ slonik resub_set.sh
resub_set.sh:8: PGRES_FATAL_ERROR lock table "_rep220".sl_event_lock,
"_rep220".sl_config_lock;select "_rep220".resubscribeNode(1, 2, 3);  -
ERROR:  insert or update on table "sl_subscribe" violates foreign key
constraint "sl_subscribe-sl_path-ref"
DETAIL:  Key (sub_provider, sub_receiver)=(2, 3) is not present in table
"sl_path".
CONTEXT:  SQL statement "update "_rep220".sl_subscribe
                        set sub_provider = p_sub_provider,
                                sub_forward = p_sub_forward
                        where sub_set = p_sub_set
                        and sub_receiver = p_sub_receiver"
PL/pgSQL function
_rep220.subscribeset_int(integer,integer,integer,boolean,boolean) line 35
at SQL statement
SQL statement "SELECT "_rep220".subscribeSet_int(v_record.sub_set,
                                p_provider,
                                p_receiver, v_record.sub_forward, false)"
PL/pgSQL function _rep220.resubscribenode(integer,integer,integer) line 75
at PERFORM
-bash-4.1$
-bash-4.1$

I will fix this as mentioned. Thank you.

--Raghav
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20130705/b5d9e3b3/attachment.htm 

From ssinger at ca.afilias.info  Fri Jul  5 05:17:35 2013
From: ssinger at ca.afilias.info (Steve Singer)
Date: Fri, 05 Jul 2013 08:17:35 -0400
Subject: [Slony1-general] Slonik shows unsupported PostgreSQL version 9.3
In-Reply-To: <CANwAqWiUZvSDtcY8Wt+O=8umPEfpObF+0Y9oeRX5_OW2T92J-A@mail.gmail.com>
References: <CANwAqWiUZvSDtcY8Wt+O=8umPEfpObF+0Y9oeRX5_OW2T92J-A@mail.gmail.com>
Message-ID: <51D6B95F.4020802@ca.afilias.info>

On 07/05/2013 03:59 AM, Raghav wrote:
> Hi,
>
> I see unsupported errors while executing INIT script:
>
> -bash-4.1$ slonik -v
> slonik version 2.2.0.b4
>
> -bash-4.1$ slonik init_cluster.sh
> init_cluster.sh:7: Possible unsupported PostgreSQL version (90300) 9.3,
> defaulting to 8.4 support
> init_cluster.sh:11: Possible unsupported PostgreSQL version (90300) 9.3,
> defaulting to 8.4 support
> init_cluster.sh:14: Stored all nodes in the slony catalogs
>
> Is it expected?
> On the grounds that it doesn't break the INIT script, yet it just shows
> the above message while executing.
>

Yes we usually say "Possible unsupported version" until a PG major 
version is actually released.  I fixed a few things with 2.2 and PG 9.3 
a few months back but as far as I know there are no outstanding issues.



> Thanks.
>
> --
> Regards
> Raghav
> Blog: htt://raghavt.blogspot.com/ <http://raghavt.blogspot.com/>
>
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


From ragavendra.dba at gmail.com  Mon Jul  8 23:37:57 2013
From: ragavendra.dba at gmail.com (Raghav)
Date: Tue, 9 Jul 2013 12:07:57 +0530
Subject: [Slony1-general] DML count in sl_apply_stats
Message-ID: <CANwAqWhKi7fYrJHU0R3ZhAg-jN9ABdbMTYt4+BdeHJtBT5rJKw@mail.gmail.com>

Hi,

insert into stest values(generate_series(1,100));
or
insert into stest values (101),(102),(103);

How does above two SQL statements treated and counted in
sl_apply_stats.as_num_insert column ?

I feel it should be considered as one INSERT statement, no ?,
But it has multiplied the count even with generate_series.

Test case:

postgres=# select as_num_insert from _rep220.sl_apply_stats ;     //before
insert
 as_num_insert
---------------
           0
(1 row)

postgres=# insert into stest values (generate_series(1,100));
INSERT 0 100

postgres=# select as_num_insert from _rep220.sl_apply_stats ;
 as_num_insert
---------------
           100
(1 row)

postgres=# insert into stest values (101),(102),(103);
INSERT 0 3

postgres=# select as_num_insert from _rep220.sl_apply_stats ;
 as_num_insert
---------------
           103
(1 row)


-- 
Regards
Raghav
Blog: htt://raghavt.blogspot.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20130709/9c5b7907/attachment.htm 

From janwieck at yahoo.com  Tue Jul  9 04:59:00 2013
From: janwieck at yahoo.com (Jan Wieck)
Date: Tue, 09 Jul 2013 07:59:00 -0400
Subject: [Slony1-general] DML count in sl_apply_stats
Message-ID: <1jrt5tngoabuqccyfs5j95dg.1373370691553@email.android.com>

Slony operates row based. It has no idea how many client side statements have created those rows. Or if any row was inserted, updated or deleted as a direct result of a client query, a stored procedure, a trigger or a cascaded foreign key operation.


Jan

--
Anyone who trades liberty for security deserves neither 
liberty nor security. -- Benjamin Franklin

Raghav <ragavendra.dba at gmail.com> wrote:

>Hi,
>
>insert into stest values(generate_series(1,100));
>or
>insert into stest values (101),(102),(103);
>
>How does above two SQL statements treated and counted in
>sl_apply_stats.as_num_insert column ?
>
>I feel it should be considered as one INSERT statement, no ?,
>But it has multiplied the count even with generate_series.
>
>Test case:
>
>postgres=# select as_num_insert from _rep220.sl_apply_stats ;     //before
>insert
> as_num_insert
>---------------
>           0
>(1 row)
>
>postgres=# insert into stest values (generate_series(1,100));
>INSERT 0 100
>
>postgres=# select as_num_insert from _rep220.sl_apply_stats ;
> as_num_insert
>---------------
>           100
>(1 row)
>
>postgres=# insert into stest values (101),(102),(103);
>INSERT 0 3
>
>postgres=# select as_num_insert from _rep220.sl_apply_stats ;
> as_num_insert
>---------------
>           103
>(1 row)
>
>
>-- 
>Regards
>Raghav
>Blog: htt://raghavt.blogspot.com/
>
>_______________________________________________
>Slony1-general mailing list
>Slony1-general at lists.slony.info
>http://lists.slony.info/mailman/listinfo/slony1-general
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20130709/595cd448/attachment.htm 

From ragavendra.dba at gmail.com  Tue Jul  9 09:14:42 2013
From: ragavendra.dba at gmail.com (Raghav)
Date: Tue, 9 Jul 2013 21:44:42 +0530
Subject: [Slony1-general] DML count in sl_apply_stats
In-Reply-To: <1jrt5tngoabuqccyfs5j95dg.1373370691553@email.android.com>
References: <1jrt5tngoabuqccyfs5j95dg.1373370691553@email.android.com>
Message-ID: <CANwAqWijx+i8mCZpDn17b+NwSR=tK3=CTKnwg1Jg38DwkvrTDg@mail.gmail.com>

On Tue, Jul 9, 2013 at 5:29 PM, Jan Wieck <janwieck at yahoo.com> wrote:

> Slony operates row based. It has no idea how many client side statements
> have created those rows. Or if any row was inserted, updated or deleted as
> a direct result of a client query, a stored procedure, a trigger or a
> cascaded foreign key operation.
>
> Thanks.

--Raghav
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20130709/00c98d89/attachment.htm 

From e1819465 at ceng.metu.edu.tr  Wed Jul 10 04:58:43 2013
From: e1819465 at ceng.metu.edu.tr (MEHMET CUNEYIT KIRIS)
Date: Wed, 10 Jul 2013 14:58:43 +0300
Subject: [Slony1-general] Upgrading PostgreSQL 8.1.18 to 9.0.12 via Slony1
	On the Same Host
Message-ID: <87ddc4b7a83b3044d07207b966291a9b@ceng.metu.edu.tr>

Hi,

I'm trying to upgrade our Postgresql 8.1.18 to 9.x using Slony 1.2.21. 
We have PostgreSQL 8.1.18 server&client on CentOS 5 i386 . And also,We 
have installed PostgreSQL 9.0.12 server&client on the same machine (with 
different port),works perfectly. I want to replicate our 8.x database to 
9.x database and then removing old version of PostgreSQL. Is there a way 
to do this replication on the same host via slony1 ? If there is, please 
explain with a sample .
If there is not a way ,could you please give me another idea to upgrade 
PostgreSQL 8.1.18 to 9.x with minimal downtime ?

Thank You

From robert.wysocki at unity.pl  Mon Jul 22 02:15:52 2013
From: robert.wysocki at unity.pl (Robert Wysocki)
Date: Mon, 22 Jul 2013 11:15:52 +0200
Subject: [Slony1-general] EXECUTE SCRIPT and DML
Message-ID: <1374484552.4545.77.camel@s-rwysocki>

Hi,

After upgrading test environment to slony 2.1.2 from slony 2.0.7 I
noticed, that previously flawless procedure done many times with EXECUTE
SCRIPT like:

CREATE TABLE ....;
INSERT INTO audit VALUES ('new table');

now fails with "duplicated primary key" error on slave nodes.

How should this be done with slony > 2.1.2? I would like to avoid
splitting it into DDL done with EXECUTE SCRIPT and DML done with psql.

Regards,
-- 
Robert Wysocki
administrator system?w linuksowych
administrator baz danych
Grupa Unity | ul. Przedmiejska 6-10, 54-201 Wroc?aw
ul. Conrada 55B, 31-357 Krak?w | ul. Z?ota 59, 00-120 Warszawa



From ssinger at ca.afilias.info  Mon Jul 22 13:27:25 2013
From: ssinger at ca.afilias.info (Steve Singer)
Date: Mon, 22 Jul 2013 16:27:25 -0400
Subject: [Slony1-general] EXECUTE SCRIPT and DML
In-Reply-To: <1374484552.4545.77.camel@s-rwysocki>
References: <1374484552.4545.77.camel@s-rwysocki>
Message-ID: <51ED95AD.2070901@ca.afilias.info>

On 07/22/2013 05:15 AM, Robert Wysocki wrote:
> Hi,
>
> After upgrading test environment to slony 2.1.2 from slony 2.0.7 I
> noticed, that previously flawless procedure done many times with EXECUTE
> SCRIPT like:
>
> CREATE TABLE ....;
> INSERT INTO audit VALUES ('new table');
>
> now fails with "duplicated primary key" error on slave nodes.
>
> How should this be done with slony>  2.1.2? I would like to avoid
> splitting it into DDL done with EXECUTE SCRIPT and DML done with psql.
>
> Regards,

It might help if you told us exactly what slonik EXECUTE SCRIPT command 
you were running and what your cluster looks like.

The slony log triggers should not fire if the set id in your execute 
script has an origin node equal to your event node.




From cbbrowne at afilias.info  Mon Jul 22 14:37:05 2013
From: cbbrowne at afilias.info (Christopher Browne)
Date: Mon, 22 Jul 2013 17:37:05 -0400
Subject: [Slony1-general] EXECUTE SCRIPT and DML
In-Reply-To: <51ED95AD.2070901@ca.afilias.info>
References: <1374484552.4545.77.camel@s-rwysocki>
	<51ED95AD.2070901@ca.afilias.info>
Message-ID: <CANfbgbaiQq-0eEHObrEkVSDxUprMQx--dE1y9b_A=owijvOjTw@mail.gmail.com>

The behaviour should be a bit further different...

The log triggers are supposed to be suppressed on *all* nodes when DDL/DML
is being run via EXECUTE SCRIPT by virtue of having the GUC set to "local".

In effect, what's to happen is...

- Start of EXECUTE SCRIPT processing:
   set session_replication_role to local;

 - Process DDL/DML statements

- set session_replication_role to replica;

That's the code in both 2.0 and 2.1 branches. (See
src/backend/remote_worker.c, look for the case statement processing
"DDL_SCRIPT".)

In master (pre-2.2), we're not explicitly setting the role for DDL; that
*should* be OK as the reference in dbutil.c is, I think, invoked when
running a connection to a subscriber.

cbbrowne at cbbrowne ~/P/slony1-engine.master> ack-grep
session_replication_role
src/slonik/dbutil.c
166:                             "SET session_replication_role TO local; ");

src/slon/remote_worker.c
353:                                            "set
session_replication_role = replica; ");
4958:                            "set session_replication_role to
replica;\n"

src/slony_logshipper/parser.y
327:                                                    "set
session_replication_role to replica;") < 0)

src/slony_logshipper/scan.l
135:session_replication_role { return K_SESSION_ROLE;   }

tools/slony1_dump.sh
301:set session_replication_role='replica';

doc/adminguide/triggers.sgml
23:<para> A new GUC variable, <envar>session_replication_role</envar>

doc/adminguide/security.sgml
51:<para> set the session_replication_role to replica</para>

The equivalent against 2.1 provides something rather more like 2.0, and
sets the role to "local" appropriately.

Here's what's in 2.1:

cbbrowne at cbbrowne ~/P/s/src> ack-grep session_replication_role
slonik/dbutil.c
166:                                            "SET
session_replication_role TO local; ");

slon/remote_worker.c
386:                                            "set
session_replication_role = replica; ",
1474:
 "set session_replication_role to local; "
1543:                                                            "set
session_replication_role to replica; ",
1566:                                                   if
(archive_append_str(node, "set session_replication_role to local;\n") < 0)
1570:                                                   if
(archive_append_str(node, "set session_replication_role to replica;\n") < 0)
5589:                            "set session_replication_role to
replica;\n"

backend/slony1_funcs.sql
3360:           execute 'create temp table
_slony1_saved_session_replication_role (
3362:           execute 'insert into _slony1_saved_session_replication_role
3364:                                   where name =
''session_replication_role'';';
3366:                   execute 'set session_replication_role to local;';
3400:                   'select setting from
_slony1_saved_session_replication_role' loop
3401:                   v_query := 'set session_replication_role to ' ||
v_row.setting;
3404:           execute 'drop table _slony1_saved_session_replication_role';

slony_logshipper/parser.y
327:                                                    "set
session_replication_role to replica;") < 0)

slony_logshipper/scan.l
135:session_replication_role { return K_SESSION_ROLE;   }

The relevant bits in 2.0 seem identical to 2.1.  (My ack-grep run finds the
very same code.)

It seems to me that we should ensure we have a regression test that does
both DDL and DML, to make sure that we process both properly, as that
should work OK.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20130722/ded7711b/attachment.htm 

From robert.wysocki at unity.pl  Tue Jul 23 00:27:47 2013
From: robert.wysocki at unity.pl (Robert Wysocki)
Date: Tue, 23 Jul 2013 09:27:47 +0200
Subject: [Slony1-general] EXECUTE SCRIPT and DML
In-Reply-To: <CANfbgbaiQq-0eEHObrEkVSDxUprMQx--dE1y9b_A=owijvOjTw@mail.gmail.com>
References: <1374484552.4545.77.camel@s-rwysocki>
	<51ED95AD.2070901@ca.afilias.info>
	<CANfbgbaiQq-0eEHObrEkVSDxUprMQx--dE1y9b_A=owijvOjTw@mail.gmail.com>
Message-ID: <1374564467.4545.95.camel@s-rwysocki>

Dnia 2013-07-22, pon o godzinie 17:37 -0400, Christopher Browne pisze:
> The behaviour should be a bit further different...
> 
> 
> The log triggers are supposed to be suppressed on *all* nodes when
> DDL/DML is being run via EXECUTE SCRIPT by virtue of having the GUC
> set to "local".
> 
> 
> In effect, what's to happen is...
> 
> 
> - Start of EXECUTE SCRIPT processing:
>    set session_replication_role to local; 
> 
> 
>  - Process DDL/DML statements
> 
> 
> - set session_replication_role to replica;
> 
Thanks for answers. I've managed to narrow it down to one case:
SELECT from one table run with slonik_execute_script calls a function
which in turn INSERTs into another table. Both tables are in the same
replication set.

In the node log I have:
2013-05-23 12:01:58 CEST CONFIG remoteWorkerThread_1: DDL Statement 17:
[

INSERT INTO euro_audit.b24_messages_aud(
                    id, rev, revtype, 
                    page_label, "content", wysiwygable,
                    content_for_mobile_active, content_for_mobile, 
                    note, message_type_id)
        SELECT id,  getRevId('Inicjalizacja wersjonowania','MESSAGE'),
0, 
                                page_label, "content", wysiwygable, 
                                content_for_mobile_active,
content_for_mobile,
                                note, message_type_id
          FROM euro.b24_messages 
          WHERE page_label =
'not-added-services-shop-delivery-encouragement-message';]
2013-05-23 12:01:58 CEST ERROR  DDL Statement failed - PGRES_FATAL_ERROR

In postgres log at the receiver end I have:
[2013-05-23 12:01:58 CEST] slony1 at 10.1.12.21(39802):si_euro [21146]
519de916.529a/11:3799790 ERROR:  duplicate key value violates unique
constraint "revisions_pkey"
[2013-05-23 12:01:58 CEST] slony1 at 10.1.12.21(39802):si_euro [21146]
519de916.529a/12:3799790 DETAIL:  Key (id)=(1) already exists.
[2013-05-23 12:01:58 CEST] slony1 at 10.1.12.21(39802):si_euro [21146]
519de916.529a/13:3799790 CONTEXT:  SQL statement "INSERT INTO
euro_audit.revisions(

The function in question:
si_euro=# \sf getrevid (text,text)
CREATE OR REPLACE FUNCTION public.getrevid(rev_comment text,
audit_class_name text)
 RETURNS bigint
 LANGUAGE plpgsql
AS $function$
                DECLARE
                    rev_id bigint := 0;

BEGIN
                    
                            IF audit_class_name IS NULL OR 
                                    audit_class_name NOT SIMILAR TO
'(ARTICLE|CMS_PAGE|DEFINITION|EMAIL|IP_RULE
                                     |MESSAGE|PRODUCT_PROMOTION_PRICE|
SHOP_IN_SHOP_BANNER|SHOP_IN_SHOP
                                     |STATUS_CODE|SYSTEM_PARAMETER|
XSL_DEFINITION|BANNER|SHOP)'
                           THEN RAISE EXCEPTION 'Wywo?anie getRevId(%,%)
przerwane. Taki audit_class_name nie istnieje - patrz
AuditableEntityClasses',rev_comment, audit_class_name;

END IF;

INSERT INTO euro_audit.revisions(
                            "comment", "timestamp", user_name,
class_name)
                    VALUES (rev_comment,  extract('epoch' from
CURRENT_TIMESTAMP) * 1000, 'System', audit_class_name);

rev_id = currval('euro_audit.revisions_id_seq');

return rev_id;

END;

$function$


Other DML statements done with slonik_execute_script do _not_ produce
such errors. Is it possible that function execution does not obey
session_replication_role settings?

Regards,
-- 
Robert Wysocki
administrator system?w linuksowych
administrator baz danych
Grupa Unity | ul. Przedmiejska 6-10, 54-201 Wroc?aw
ul. Conrada 55B, 31-357 Krak?w | ul. Z?ota 59, 00-120 Warszawa


From rnancy at afilias.info  Tue Jul 23 11:13:03 2013
From: rnancy at afilias.info (Rose Nancy)
Date: Tue, 23 Jul 2013 14:13:03 -0400
Subject: [Slony1-general] Slony Watchdog failed starting up the child process
Message-ID: <51EEC7AF.1040409@afilias.info>

Hi All,

At the server startup,  my slony daemon crashed with the following error

FATAL localListenThread: "select "_xxxx".cleanupNodelock(); insert into 
"_xxxx".sl_nodelock values ( 9151, 0,
"pg_catalog".pg_backend_pid()); " - ERROR: duplicate key value violates 
unique constraint "sl_nodelock-pkey"
DETAIL: Key (nl_nodeid, nl_conncnt)=(9151, 0) already exists.
2013-07-23 07:10:16 UTC FATAL Do you already have a slon running against 
this node?
2013-07-23 07:10:16 UTC FATAL Or perhaps a residual idle backend 
connection from a dead slon?
2013-07-23 07:10:16 UTC DEBUG2 slon_abort() from pid=1699
2013-07-23 07:10:16 UTC FATAL main: localListenThread did not start
2013-07-23 07:10:16 UTC CONFIG slon: child terminated signal: 9; pid: 
1699, current worker pid: 1699
2013-07-23 07:10:16 UTC INFO slon: done

I know the origin of the duplicate key error, but I expected the 
Watchdog to try every 10s to start the daemon again.
In my case it seems like the watchdog process died with the child process.

What is the expected behaviour of the Watchdog slony process in this case?


Thanks.

-- 
Rose Nancy


From cbbrowne at afilias.info  Tue Jul 23 12:08:32 2013
From: cbbrowne at afilias.info (Christopher Browne)
Date: Tue, 23 Jul 2013 15:08:32 -0400
Subject: [Slony1-general] Slony Watchdog failed starting up the child
	process
In-Reply-To: <CANfbgbaFYAyRyYXNJ0H7fPTX89OGvBjsBQWhCFbRx-tAe4aqig@mail.gmail.com>
References: <51EEC7AF.1040409@afilias.info>
	<CANfbgbaFYAyRyYXNJ0H7fPTX89OGvBjsBQWhCFbRx-tAe4aqig@mail.gmail.com>
Message-ID: <CANfbgbb+gXd2R-LdvbhWEoN3rt_FmNHuoq5mf8wvjrj1vaKcBg@mail.gmail.com>

My intuition from seeing it say "FATAL" is that that's indicating "death of
process," and that there's not much coming back from it.

This behaviour is pretty consistent with what happens with a Postgres
postmaster; if the attempt to start up fails due to seeming already to have
a postmaster, it doesn't retry, pg_ctl immediately gives up.

By the way, is this possibly because of a zombied old connection that got
disconnected due to firewall glitch or such?  If so, you should probably
see about lowering the TCP keepalive parameters both in the slon.conf file
and in postgresql.conf

(On postgresql.conf, see tcp_keepalives_(idle|interval|count), and on
slon.conf, see tcp_keepalive, tcp_keepalive_(idle|interval|count).)


On Tue, Jul 23, 2013 at 3:07 PM, Christopher Browne
<cbbrowne at afilias.info>wrote:

> My intuition from seeing it say "FATAL" is that that's indicating "death
> of process," and that there's not much coming back from it.
>
> This behaviour is pretty consistent with what happens with a Postgres
> postmaster; if the attempt to start up fails due to seeming already to have
> a postmaster, it doesn't retry, pg_ctl immediately gives up.
>
> By the way, is this possibly because of a zombied old connection that got
> disconnected due to firewall glitch or such?  If so, you should probably
> see about lowering the TCP keepalive parameters both in the slon.conf file
> and in postgresql.conf
>
> (On postgresql.conf, see tcp_keepalives_(idle|interval|count), and on
> slon.conf, see tcp_keepalive, tcp_keepalive_(idle|interval|count).)
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20130723/eeffe7d5/attachment.htm 

From ssinger at ca.afilias.info  Tue Jul 23 12:22:39 2013
From: ssinger at ca.afilias.info (Steve Singer)
Date: Tue, 23 Jul 2013 15:22:39 -0400
Subject: [Slony1-general] Slony Watchdog failed starting up the child
 process
In-Reply-To: <CANfbgbb+gXd2R-LdvbhWEoN3rt_FmNHuoq5mf8wvjrj1vaKcBg@mail.gmail.com>
References: <51EEC7AF.1040409@afilias.info>
	<CANfbgbaFYAyRyYXNJ0H7fPTX89OGvBjsBQWhCFbRx-tAe4aqig@mail.gmail.com>
	<CANfbgbb+gXd2R-LdvbhWEoN3rt_FmNHuoq5mf8wvjrj1vaKcBg@mail.gmail.com>
Message-ID: <51EED7FF.20404@ca.afilias.info>

On 07/23/2013 03:08 PM, Christopher Browne wrote:
> My intuition from seeing it say "FATAL" is that that's indicating "death
> of process," and that there's not much coming back from it.
>
> This behaviour is pretty consistent with what happens with a Postgres
> postmaster; if the attempt to start up fails due to seeming already to
> have a postmaster, it doesn't retry, pg_ctl immediately gives up.
>

This came up a few years ago with bug #132.

http://git.postgresql.org/gitweb/?p=slony1-engine.git;a=commit;h=acd46819bad1613764708b138ebcfa895467ac51

Changed slon to behave as Rose expected, retry to get the node lock 
every few seconds.

A few weeks later we modified this to only retry getting the node lock 
in response to a slon requested restart and not retry if the initial 
start fails. 
http://git.postgresql.org/gitweb/?p=slony1-engine.git;a=commit;h=7d3e6659542ad337feb2fbe39f05b780c37afe97

I don't really remember the discussion around this change and exactly 
why we didn't like my original patch, possibly for reasons like you 
argue above, if slon keeps looping it never really 'starts' and it is 
hard to detect that.




> By the way, is this possibly because of a zombied old connection that
> got disconnected due to firewall glitch or such?  If so, you should
> probably see about lowering the TCP keepalive parameters both in the
> slon.conf file and in postgresql.conf
>
> (On postgresql.conf, see tcp_keepalives_(idle|interval|count), and on
> slon.conf, see tcp_keepalive, tcp_keepalive_(idle|interval|count).)
>
>

No matter how low you make the postgresql.conf settings it is always 
possible for the replacement slon to start before the postgresql detects 
the timeout. I don't know how low you can make the tcp timeout settings 
before it has other side-effects.

One option is to push the issue to whatever is starting the slon and let 
it retry (which is what we do now).  Another option is to let slon loop 
x times trying to get the node-lock before giving up, but we didn't seem 
to like that 3 years ago.




> On Tue, Jul 23, 2013 at 3:07 PM, Christopher Browne
> <cbbrowne at afilias.info <mailto:cbbrowne at afilias.info>> wrote:
>
>     My intuition from seeing it say "FATAL" is that that's indicating
>     "death of process," and that there's not much coming back from it.
>
>     This behaviour is pretty consistent with what happens with a
>     Postgres postmaster; if the attempt to start up fails due to seeming
>     already to have a postmaster, it doesn't retry, pg_ctl immediately
>     gives up.
>
>     By the way, is this possibly because of a zombied old connection
>     that got disconnected due to firewall glitch or such?  If so, you
>     should probably see about lowering the TCP keepalive parameters both
>     in the slon.conf file and in postgresql.conf
>
>     (On postgresql.conf, see tcp_keepalives_(idle|interval|count), and
>     on slon.conf, see tcp_keepalive, tcp_keepalive_(idle|interval|count).)
>
>
>
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


From rnancy at afilias.info  Tue Jul 23 12:21:14 2013
From: rnancy at afilias.info (Rose Nancy)
Date: Tue, 23 Jul 2013 15:21:14 -0400
Subject: [Slony1-general] Slony Watchdog failed starting up the child
 process
In-Reply-To: <CANfbgbaFYAyRyYXNJ0H7fPTX89OGvBjsBQWhCFbRx-tAe4aqig@mail.gmail.com>
References: <51EEC7AF.1040409@afilias.info>
	<CANfbgbaFYAyRyYXNJ0H7fPTX89OGvBjsBQWhCFbRx-tAe4aqig@mail.gmail.com>
Message-ID: <51EED7AA.1070900@afilias.info>

Hi Chris,

On 13-07-23 03:07 PM, Christopher Browne wrote:
> My intuition from seeing it say "FATAL" is that that's indicating 
> "death of process," and that there's not much coming back from it.
>
> This behaviour is pretty consistent with what happens with a Postgres 
> postmaster; if the attempt to start up fails due to seeming already to 
> have a postmaster, it doesn't retry, pg_ctl immediately gives up.

In my case the slons are running in a separate server which I rebooted.
>
> By the way, is this possibly because of a zombied old connection that 
> got disconnected due to firewall glitch or such?  If so, you should 
> probably see about lowering the TCP keepalive parameters both in the 
> slon.conf file and in postgresql.conf
You're right, the duplicated key error was caused by a zombie old 
connection that got disconnected due to the slony server reboot.

Thanks.

-- 
Rose Nancy
DBA - Afilias Canada Corp.
Office: 416-673-4082
Mobile: 647-669-3295.


From JanWieck at Yahoo.com  Tue Jul 23 12:34:30 2013
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Tue, 23 Jul 2013 15:34:30 -0400
Subject: [Slony1-general] Slony Watchdog failed starting up the child
 process
In-Reply-To: <51EED7AA.1070900@afilias.info>
References: <51EEC7AF.1040409@afilias.info>
	<CANfbgbaFYAyRyYXNJ0H7fPTX89OGvBjsBQWhCFbRx-tAe4aqig@mail.gmail.com>
	<51EED7AA.1070900@afilias.info>
Message-ID: <51EEDAC6.7080302@Yahoo.com>

On 07/23/13 15:21, Rose Nancy wrote:
> Hi Chris,
> 
> On 13-07-23 03:07 PM, Christopher Browne wrote:
>> My intuition from seeing it say "FATAL" is that that's indicating 
>> "death of process," and that there's not much coming back from it.
>>
>> This behaviour is pretty consistent with what happens with a Postgres 
>> postmaster; if the attempt to start up fails due to seeming already to 
>> have a postmaster, it doesn't retry, pg_ctl immediately gives up.
> 
> In my case the slons are running in a separate server which I rebooted.
>>
>> By the way, is this possibly because of a zombied old connection that 
>> got disconnected due to firewall glitch or such?  If so, you should 
>> probably see about lowering the TCP keepalive parameters both in the 
>> slon.conf file and in postgresql.conf
> You're right, the duplicated key error was caused by a zombie old 
> connection that got disconnected due to the slony server reboot.

Which is something that TCP keepalives should clean out after a while.

My recollection of the discussion, that led to the current behavior, is
that we had several options.

A) have it retry no matter what. In the case of a zombie that doesn't
time out, that doesn't help, but at least it creates a constant stream
of error messages.

B) Treat the first connection attempt different, so that the system
startup script or a later manual invocation will signal a problem.

C) Kick the existing (assumed to be dead) slon out (by killing its
backend). But if you really have two slons, that are alive and possibly
running on different systems, they will keep stabbing each other in the
back and eventually never get anything accomplished.


We chose B) at that time.


I am open for new ideas.


Jan

-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From ssinger at ca.afilias.info  Wed Jul 24 15:21:47 2013
From: ssinger at ca.afilias.info (Steve Singer)
Date: Wed, 24 Jul 2013 18:21:47 -0400
Subject: [Slony1-general] EXECUTE SCRIPT and DML
In-Reply-To: <1374564467.4545.95.camel@s-rwysocki>
References: <1374484552.4545.77.camel@s-rwysocki>
	<51ED95AD.2070901@ca.afilias.info>
	<CANfbgbaiQq-0eEHObrEkVSDxUprMQx--dE1y9b_A=owijvOjTw@mail.gmail.com>
	<1374564467.4545.95.camel@s-rwysocki>
Message-ID: <51F0537B.6040207@ca.afilias.info>

On 07/23/2013 03:27 AM, Robert Wysocki wrote:

Could the problem be with your sequences?

I was able to reproduce a test case that looked something like this

EXECUTE SCRIPT(SQL='insert into table5 (data) values ('9');', event node=1);

This worked okay on my origin giving me a row:

7 | seven
8 | 9

where the first row already existed.

But when this SQL executed on the replica

COPY IN: ERROR:  duplicate key value violates unique constraint 
"table5_pkey"
db3:java.lang.UNIXProcess at 6542bece - DETAIL:  Key (id)=(7) already exists.

We don't update + replicate the sequence value updates at the start of a 
EXECUTE_SCRIPT event (apparently).




> Dnia 2013-07-22, pon o godzinie 17:37 -0400, Christopher Browne pisze:
>> The behaviour should be a bit further different...
>>
>>
>> The log triggers are supposed to be suppressed on *all* nodes when
>> DDL/DML is being run via EXECUTE SCRIPT by virtue of having the GUC
>> set to "local".
>>
>>
>> In effect, what's to happen is...
>>
>>
>> - Start of EXECUTE SCRIPT processing:
>>     set session_replication_role to local;
>>
>>
>>   - Process DDL/DML statements
>>
>>
>> - set session_replication_role to replica;
>>
> Thanks for answers. I've managed to narrow it down to one case:
> SELECT from one table run with slonik_execute_script calls a function
> which in turn INSERTs into another table. Both tables are in the same
> replication set.
>
> In the node log I have:
> 2013-05-23 12:01:58 CEST CONFIG remoteWorkerThread_1: DDL Statement 17:
> [
>
> INSERT INTO euro_audit.b24_messages_aud(
>                      id, rev, revtype,
>                      page_label, "content", wysiwygable,
>                      content_for_mobile_active, content_for_mobile,
>                      note, message_type_id)
>          SELECT id,  getRevId('Inicjalizacja wersjonowania','MESSAGE'),
> 0,
>                                  page_label, "content", wysiwygable,
>                                  content_for_mobile_active,
> content_for_mobile,
>                                  note, message_type_id
>            FROM euro.b24_messages
>            WHERE page_label =
> 'not-added-services-shop-delivery-encouragement-message';]
> 2013-05-23 12:01:58 CEST ERROR  DDL Statement failed - PGRES_FATAL_ERROR
>
> In postgres log at the receiver end I have:
> [2013-05-23 12:01:58 CEST] slony1 at 10.1.12.21(39802):si_euro [21146]
> 519de916.529a/11:3799790 ERROR:  duplicate key value violates unique
> constraint "revisions_pkey"
> [2013-05-23 12:01:58 CEST] slony1 at 10.1.12.21(39802):si_euro [21146]
> 519de916.529a/12:3799790 DETAIL:  Key (id)=(1) already exists.
> [2013-05-23 12:01:58 CEST] slony1 at 10.1.12.21(39802):si_euro [21146]
> 519de916.529a/13:3799790 CONTEXT:  SQL statement "INSERT INTO
> euro_audit.revisions(
>
> The function in question:
> si_euro=# \sf getrevid (text,text)
> CREATE OR REPLACE FUNCTION public.getrevid(rev_comment text,
> audit_class_name text)
>   RETURNS bigint
>   LANGUAGE plpgsql
> AS $function$
>                  DECLARE
>                      rev_id bigint := 0;
>
> BEGIN
>
>                              IF audit_class_name IS NULL OR
>                                      audit_class_name NOT SIMILAR TO
> '(ARTICLE|CMS_PAGE|DEFINITION|EMAIL|IP_RULE
>                                       |MESSAGE|PRODUCT_PROMOTION_PRICE|
> SHOP_IN_SHOP_BANNER|SHOP_IN_SHOP
>                                       |STATUS_CODE|SYSTEM_PARAMETER|
> XSL_DEFINITION|BANNER|SHOP)'
>                             THEN RAISE EXCEPTION 'Wywo?anie getRevId(%,%)
> przerwane. Taki audit_class_name nie istnieje - patrz
> AuditableEntityClasses',rev_comment, audit_class_name;
>
> END IF;
>
> INSERT INTO euro_audit.revisions(
>                              "comment", "timestamp", user_name,
> class_name)
>                      VALUES (rev_comment,  extract('epoch' from
> CURRENT_TIMESTAMP) * 1000, 'System', audit_class_name);
>
> rev_id = currval('euro_audit.revisions_id_seq');
>
> return rev_id;
>
> END;
>
> $function$
>
>
> Other DML statements done with slonik_execute_script do _not_ produce
> such errors. Is it possible that function execution does not obey
> session_replication_role settings?
>
> Regards,


From ssinger at ca.afilias.info  Thu Jul 25 08:17:42 2013
From: ssinger at ca.afilias.info (Steve Singer)
Date: Thu, 25 Jul 2013 11:17:42 -0400
Subject: [Slony1-general] EXECUTE SCRIPT and DML
In-Reply-To: <CANfbgbaiQq-0eEHObrEkVSDxUprMQx--dE1y9b_A=owijvOjTw@mail.gmail.com>
References: <1374484552.4545.77.camel@s-rwysocki>
	<51ED95AD.2070901@ca.afilias.info>
	<CANfbgbaiQq-0eEHObrEkVSDxUprMQx--dE1y9b_A=owijvOjTw@mail.gmail.com>
Message-ID: <51F14196.80606@ca.afilias.info>

On 07/22/2013 05:37 PM, Christopher Browne wrote:
> The behaviour should be a bit further different...
>

>
> In master (pre-2.2), we're not explicitly setting the role for DDL; that
> *should* be OK as the reference in dbutil.c is, I think, invoked when
> running a connection to a subscriber.
>
> cbbrowne at cbbrowne ~/P/slony1-engine.master> ack-grep
> session_replication_role
> src/slonik/dbutil.c
> 166: "SET session_replication_role TO local; ");
>
> src/slon/remote_worker.c
> 353: "set session_replication_role = replica; ");
> 4958: "set session_replication_role to replica;\n"


I am a bit unclear why you this this *should* be okay in master? As far 
as I can tell from the above code snippet when the remote_worker calls 
the stored functions to execute the DDL_SCRIPT session replication_role 
is replica this different than when slonik invoked it on the event node 
(where session replication_role was local according to above). The 
DDL_SCRIPT will behave differently with respect to any normal user-added 
triggers on the tables.

I think the above paragraph describes a bug we've introduced into 2.2 
which is different than Robert's issue of a duplicate key error in 2.1

I have changes to the testddl regression test that reproduces this which 
I will attach to a bugzilla bug shortly.

>
> src/slony_logshipper/parser.y
> 327: "set session_replication_role to replica;") < 0)
>
> src/slony_logshipper/scan.l
> 135:session_replication_role { return K_SESSION_ROLE;   }
>
> tools/slony1_dump.sh
> 301:set session_replication_role='replica';
>
> doc/adminguide/triggers.sgml
> 23:<para> A new GUC variable, <envar>session_replication_role</envar>
>
> doc/adminguide/security.sgml
> 51:<para> set the session_replication_role to replica</para>
>
> The equivalent against 2.1 provides something rather more like 2.0, and
> sets the role to "local" appropriately.
>
> Here's what's in 2.1:
>
> cbbrowne at cbbrowne ~/P/s/src> ack-grep session_replication_role
> slonik/dbutil.c
> 166: "SET session_replication_role TO local; ");
>
> slon/remote_worker.c
> 386: "set session_replication_role = replica; ",
> 1474: "set session_replication_role to local; "
> 1543: "set session_replication_role to replica; ",
> 1566:                                                   if
> (archive_append_str(node, "set session_replication_role to local;\n") < 0)
> 1570:                                                   if
> (archive_append_str(node, "set session_replication_role to replica;\n") < 0)
> 5589: "set session_replication_role to replica;\n"
>
> backend/slony1_funcs.sql
> 3360:           execute 'create temp table
> _slony1_saved_session_replication_role (
> 3362:           execute 'insert into _slony1_saved_session_replication_role
> 3364:                                   where name =
> ''session_replication_role'';';
> 3366:                   execute 'set session_replication_role to local;';
> 3400: 'select setting from _slony1_saved_session_replication_role' loop
> 3401:                   v_query := 'set session_replication_role to ' ||
> v_row.setting;
> 3404:           execute 'drop table _slony1_saved_session_replication_role';
>
> slony_logshipper/parser.y
> 327: "set session_replication_role to replica;") < 0)
>
> slony_logshipper/scan.l
> 135:session_replication_role { return K_SESSION_ROLE;   }
>
> The relevant bits in 2.0 seem identical to 2.1.  (My ack-grep run finds
> the very same code.)
>
> It seems to me that we should ensure we have a regression test that does
> both DDL and DML, to make sure that we process both properly, as that
> should work OK.


From ssinger at ca.afilias.info  Thu Jul 25 13:55:32 2013
From: ssinger at ca.afilias.info (Steve Singer)
Date: Thu, 25 Jul 2013 16:55:32 -0400
Subject: [Slony1-general] EXECUTE SCRIPT and DML
In-Reply-To: <51F0537B.6040207@ca.afilias.info>
References: <1374484552.4545.77.camel@s-rwysocki>
	<51ED95AD.2070901@ca.afilias.info>
	<CANfbgbaiQq-0eEHObrEkVSDxUprMQx--dE1y9b_A=owijvOjTw@mail.gmail.com>
	<1374564467.4545.95.camel@s-rwysocki>
	<51F0537B.6040207@ca.afilias.info>
Message-ID: <51F190C4.30003@ca.afilias.info>

On 07/24/2013 06:21 PM, Steve Singer wrote:


FYI,  The problem that I was able to replicate is an issue with slony 
2.2  (bug 304) but isn't a problem with 2.1.


Perhaps you aren't replicating one of your sequences?



> On 07/23/2013 03:27 AM, Robert Wysocki wrote:
>
> Could the problem be with your sequences?
>
> I was able to reproduce a test case that looked something like this
>
> EXECUTE SCRIPT(SQL='insert into table5 (data) values ('9');', event
> node=1);
>
> This worked okay on my origin giving me a row:
>
> 7 | seven
> 8 | 9
>
> where the first row already existed.
>
> But when this SQL executed on the replica
>
> COPY IN: ERROR: duplicate key value violates unique constraint
> "table5_pkey"
> db3:java.lang.UNIXProcess at 6542bece - DETAIL: Key (id)=(7) already exists.
>
> We don't update + replicate the sequence value updates at the start of a
> EXECUTE_SCRIPT event (apparently).
>
>
>
>
>> Dnia 2013-07-22, pon o godzinie 17:37 -0400, Christopher Browne pisze:
>>> The behaviour should be a bit further different...
>>>
>>>
>>> The log triggers are supposed to be suppressed on *all* nodes when
>>> DDL/DML is being run via EXECUTE SCRIPT by virtue of having the GUC
>>> set to "local".
>>>
>>>
>>> In effect, what's to happen is...
>>>
>>>
>>> - Start of EXECUTE SCRIPT processing:
>>> set session_replication_role to local;
>>>
>>>
>>> - Process DDL/DML statements
>>>
>>>
>>> - set session_replication_role to replica;
>>>
>> Thanks for answers. I've managed to narrow it down to one case:
>> SELECT from one table run with slonik_execute_script calls a function
>> which in turn INSERTs into another table. Both tables are in the same
>> replication set.
>>
>> In the node log I have:
>> 2013-05-23 12:01:58 CEST CONFIG remoteWorkerThread_1: DDL Statement 17:
>> [
>>
>> INSERT INTO euro_audit.b24_messages_aud(
>> id, rev, revtype,
>> page_label, "content", wysiwygable,
>> content_for_mobile_active, content_for_mobile,
>> note, message_type_id)
>> SELECT id, getRevId('Inicjalizacja wersjonowania','MESSAGE'),
>> 0,
>> page_label, "content", wysiwygable,
>> content_for_mobile_active,
>> content_for_mobile,
>> note, message_type_id
>> FROM euro.b24_messages
>> WHERE page_label =
>> 'not-added-services-shop-delivery-encouragement-message';]
>> 2013-05-23 12:01:58 CEST ERROR DDL Statement failed - PGRES_FATAL_ERROR
>>
>> In postgres log at the receiver end I have:
>> [2013-05-23 12:01:58 CEST] slony1 at 10.1.12.21(39802):si_euro [21146]
>> 519de916.529a/11:3799790 ERROR: duplicate key value violates unique
>> constraint "revisions_pkey"
>> [2013-05-23 12:01:58 CEST] slony1 at 10.1.12.21(39802):si_euro [21146]
>> 519de916.529a/12:3799790 DETAIL: Key (id)=(1) already exists.
>> [2013-05-23 12:01:58 CEST] slony1 at 10.1.12.21(39802):si_euro [21146]
>> 519de916.529a/13:3799790 CONTEXT: SQL statement "INSERT INTO
>> euro_audit.revisions(
>>
>> The function in question:
>> si_euro=# \sf getrevid (text,text)
>> CREATE OR REPLACE FUNCTION public.getrevid(rev_comment text,
>> audit_class_name text)
>> RETURNS bigint
>> LANGUAGE plpgsql
>> AS $function$
>> DECLARE
>> rev_id bigint := 0;
>>
>> BEGIN
>>
>> IF audit_class_name IS NULL OR
>> audit_class_name NOT SIMILAR TO
>> '(ARTICLE|CMS_PAGE|DEFINITION|EMAIL|IP_RULE
>> |MESSAGE|PRODUCT_PROMOTION_PRICE|
>> SHOP_IN_SHOP_BANNER|SHOP_IN_SHOP
>> |STATUS_CODE|SYSTEM_PARAMETER|
>> XSL_DEFINITION|BANNER|SHOP)'
>> THEN RAISE EXCEPTION 'Wywo?anie getRevId(%,%)
>> przerwane. Taki audit_class_name nie istnieje - patrz
>> AuditableEntityClasses',rev_comment, audit_class_name;
>>
>> END IF;
>>
>> INSERT INTO euro_audit.revisions(
>> "comment", "timestamp", user_name,
>> class_name)
>> VALUES (rev_comment, extract('epoch' from
>> CURRENT_TIMESTAMP) * 1000, 'System', audit_class_name);
>>
>> rev_id = currval('euro_audit.revisions_id_seq');
>>
>> return rev_id;
>>
>> END;
>>
>> $function$
>>
>>
>> Other DML statements done with slonik_execute_script do _not_ produce
>> such errors. Is it possible that function execution does not obey
>> session_replication_role settings?
>>
>> Regards,
>


From robert.wysocki at unity.pl  Thu Jul 25 22:55:26 2013
From: robert.wysocki at unity.pl (Robert Wysocki)
Date: Fri, 26 Jul 2013 07:55:26 +0200
Subject: [Slony1-general] EXECUTE SCRIPT and DML
In-Reply-To: <51F0537B.6040207@ca.afilias.info>
References: <1374484552.4545.77.camel@s-rwysocki>
	<51ED95AD.2070901@ca.afilias.info>
	<CANfbgbaiQq-0eEHObrEkVSDxUprMQx--dE1y9b_A=owijvOjTw@mail.gmail.com>
	<1374564467.4545.95.camel@s-rwysocki>
	<51F0537B.6040207@ca.afilias.info>
Message-ID: <1374818126.4545.116.camel@s-rwysocki>

Dnia 2013-07-24, ?ro o godzinie 18:21 -0400, Steve Singer pisze:
> On 07/23/2013 03:27 AM, Robert Wysocki wrote:
> 
> Could the problem be with your sequences?
> 
> I was able to reproduce a test case that looked something like this
> 
> EXECUTE SCRIPT(SQL='insert into table5 (data) values ('9');', event node=1);
> 
> This worked okay on my origin giving me a row:
> 
> 7 | seven
> 8 | 9
> 
> where the first row already existed.
> 
> But when this SQL executed on the replica
> 
> COPY IN: ERROR:  duplicate key value violates unique constraint 
> "table5_pkey"
> db3:java.lang.UNIXProcess at 6542bece - DETAIL:  Key (id)=(7) already exists.
> 
> We don't update + replicate the sequence value updates at the start of a 
> EXECUTE_SCRIPT event (apparently).

This probably is what's causing it - especially that we do not replicate
this particular sequence - but I wander how is it that it worked (and is
still working on prod) with slony <= 2.0.7?

Regards,
-- 
Robert Wysocki
administrator system?w linuksowych
administrator baz danych
Grupa Unity | ul. Przedmiejska 6-10, 54-201 Wroc?aw
ul. Conrada 55B, 31-357 Krak?w | ul. Z?ota 59, 00-120 Warszawa


From robert.wysocki at unity.pl  Fri Jul 26 00:02:00 2013
From: robert.wysocki at unity.pl (Robert Wysocki)
Date: Fri, 26 Jul 2013 09:02:00 +0200
Subject: [Slony1-general] EXECUTE SCRIPT and DML
In-Reply-To: <1374818126.4545.116.camel@s-rwysocki>
References: <1374484552.4545.77.camel@s-rwysocki>
	<51ED95AD.2070901@ca.afilias.info>
	<CANfbgbaiQq-0eEHObrEkVSDxUprMQx--dE1y9b_A=owijvOjTw@mail.gmail.com>
	<1374564467.4545.95.camel@s-rwysocki>	<51F0537B.6040207@ca.afilias.info>
	<1374818126.4545.116.camel@s-rwysocki>
Message-ID: <1374822120.4545.122.camel@s-rwysocki>

Dnia 2013-07-26, pi? o godzinie 07:55 +0200, Robert Wysocki pisze:

> This probably is what's causing it - especially that we do not replicate
> this particular sequence - but I wander how is it that it worked (and is
> still working on prod) with slony <= 2.0.7?

I've just confirmed it with slony 2.1.3:

scenario:
replicated table testseq (id serial, data text), no sequence replication

test case #1:
psql> insert into testseq ( data ) values ( 'test' );
replicated OK, same id on both ends

test case #2:
echo "insert into testseq ( data ) values ( 'execute script test' );"
>/tmp/testsql
slonik_execute_script 1 /tmp/testsql | slonik
replication failed, duplicated id error

test case #3:
sequence testseq_id_seq added to replication set
slonik_execute_script 1 /tmp/testsql | slonik
replicated OK

Regards,
-- 
Robert Wysocki
administrator system?w linuksowych
administrator baz danych
Grupa Unity | ul. Przedmiejska 6-10, 54-201 Wroc?aw
ul. Conrada 55B, 31-357 Krak?w | ul. Z?ota 59, 00-120 Warszawa


From robert.wysocki at unity.pl  Fri Jul 26 01:13:39 2013
From: robert.wysocki at unity.pl (Robert Wysocki)
Date: Fri, 26 Jul 2013 10:13:39 +0200
Subject: [Slony1-general] EXECUTE SCRIPT and DML
In-Reply-To: <1374822120.4545.122.camel@s-rwysocki>
References: <1374484552.4545.77.camel@s-rwysocki>
	<51ED95AD.2070901@ca.afilias.info>
	<CANfbgbaiQq-0eEHObrEkVSDxUprMQx--dE1y9b_A=owijvOjTw@mail.gmail.com>
	<1374564467.4545.95.camel@s-rwysocki>	<51F0537B.6040207@ca.afilias.info>
	<1374818126.4545.116.camel@s-rwysocki>
	<1374822120.4545.122.camel@s-rwysocki>
Message-ID: <1374826419.4545.124.camel@s-rwysocki>

Dnia 2013-07-26, pi? o godzinie 09:02 +0200, Robert Wysocki pisze:
> Dnia 2013-07-26, pi? o godzinie 07:55 +0200, Robert Wysocki pisze:
> 
> > This probably is what's causing it - especially that we do not replicate
> > this particular sequence - but I wander how is it that it worked (and is
> > still working on prod) with slony <= 2.0.7?
> 
> I've just confirmed it with slony 2.1.3:
> 
> scenario:
> replicated table testseq (id serial, data text), no sequence replication
> 
> test case #1:
> psql> insert into testseq ( data ) values ( 'test' );
> replicated OK, same id on both ends
> 
> test case #2:
> echo "insert into testseq ( data ) values ( 'execute script test' );"
> >/tmp/testsql
> slonik_execute_script 1 /tmp/testsql | slonik
> replication failed, duplicated id error
> 
> test case #3:
> sequence testseq_id_seq added to replication set
> slonik_execute_script 1 /tmp/testsql | slonik
> replicated OK

And now I confirmed that test case #2 works fine (replication OK without
the need to include sequence in replication set) with slony 2.0.4

Regards,
-- 
Robert Wysocki
administrator system?w linuksowych
administrator baz danych
Grupa Unity | ul. Przedmiejska 6-10, 54-201 Wroc?aw
ul. Conrada 55B, 31-357 Krak?w | ul. Z?ota 59, 00-120 Warszawa


From ssinger at ca.afilias.info  Fri Jul 26 11:24:13 2013
From: ssinger at ca.afilias.info (Steve Singer)
Date: Fri, 26 Jul 2013 14:24:13 -0400
Subject: [Slony1-general] EXECUTE SCRIPT and DML
In-Reply-To: <1374826419.4545.124.camel@s-rwysocki>
References: <1374484552.4545.77.camel@s-rwysocki>
	<51ED95AD.2070901@ca.afilias.info>
	<CANfbgbaiQq-0eEHObrEkVSDxUprMQx--dE1y9b_A=owijvOjTw@mail.gmail.com>
	<1374564467.4545.95.camel@s-rwysocki>	<51F0537B.6040207@ca.afilias.info>
	<1374818126.4545.116.camel@s-rwysocki>
	<1374822120.4545.122.camel@s-rwysocki>
	<1374826419.4545.124.camel@s-rwysocki>
Message-ID: <51F2BECD.6050604@ca.afilias.info>

On 07/26/2013 04:13 AM, Robert Wysocki wrote:
> Dnia 2013-07-26, pi? o godzinie 09:02 +0200, Robert Wysocki pisze:
>> Dnia 2013-07-26, pi? o godzinie 07:55 +0200, Robert Wysocki pisze:
>>
>>> This probably is what's causing it - especially that we do not replicate
>>> this particular sequence - but I wander how is it that it worked (and is
>>> still working on prod) with slony<= 2.0.7?
>>
>> I've just confirmed it with slony 2.1.3:
>>
>> scenario:
>> replicated table testseq (id serial, data text), no sequence replication
>>
>> test case #1:
>> psql>  insert into testseq ( data ) values ( 'test' );
>> replicated OK, same id on both ends
>>
>> test case #2:
>> echo "insert into testseq ( data ) values ( 'execute script test' );"
>>> /tmp/testsql
>> slonik_execute_script 1 /tmp/testsql | slonik
>> replication failed, duplicated id error
>>
>> test case #3:
>> sequence testseq_id_seq added to replication set
>> slonik_execute_script 1 /tmp/testsql | slonik
>> replicated OK
>
> And now I confirmed that test case #2 works fine (replication OK without
> the need to include sequence in replication set) with slony 2.0.4
>

Really?
I just tried this with slony 2.0.7 and it does not work (I doubt this 
has changed between 2.0.4 and 2.0.7)


2013-07-26 14:19:03 EDTCONFIG remoteWorkerThread_1: DDL request with 2 
statements
2013-07-26 14:19:03 EDTCONFIG remoteWorkerThread_1: DDL Statement 0: 
[insert into testseq ( data ) values ( 'execute script test' );]
2013-07-26 14:19:03 EDTERROR  DDL Statement failed - PGRES_FATAL_ERROR
2013-07-26 14:19:03 EDTCONFIG slon: child terminated signal: 9; pid: 
13988, current worker pid: 13988



However, each time slon attempts to run the execute script the default 
nextval() on the replica it will advance the current value of the 
sequence on the replica (because sequence operations don't get rolled 
back) so after a couple of attempts the excute script will work on the 
replica.

I suspect this is what your seeing in your test.  Repeat your test case 
#1 on 2.0.4 but instead of inserting 1 row, insert 100 rows with psql 
and let them replicate.  I think you will then find that it takes a lot 
longer for the execute script on the replica to 'appear to work'





> Regards,


From ssinger at ca.afilias.info  Fri Jul 26 15:25:32 2013
From: ssinger at ca.afilias.info (Steve Singer)
Date: Fri, 26 Jul 2013 18:25:32 -0400
Subject: [Slony1-general] Slony 2.2.0 beta 5
Message-ID: <51F2F75C.4080903@ca.afilias.info>

Slony 2.2.0 beta 5 has been released.

This beta includes the following fixes from beta 4:

    * Fixes for FAILOVER
    * Make test_slony_state-dbi.pl work with PG 9.2
    * log shipping apply trigger will apply EXECUTE SCRIPT changes
    * MOVE SET could previously pull data from the old origin with the 
wrong SYNC (Bug 299)
    * Eliminate memory leaks in slon
    * Fixes for the 2.1 -> 2.2 upgrade procedure
    * Documentation updates

This beta includes a few known regressions with EXECUTE SCRIPT (bugs 304 
and 305).  Please help us test and report any additional issues. I am 
hoping to have a release candidate in a few weeks with an official 
release before the end of September but that depends on how successful 
further testing is.


Key features of the 2.2.0 release include:

* The storage and transport and application of the slony log 
(sl_log_1/sl_log_2) has changed providing performance improvements. Data 
is now stored in a different format and the postgresql COPY protocol and 
triggers are used to replicate and apply changes to replicas.

* DDL handling with the EXECUTE SCRIPT command has changed.  The DDL is 
no longer stored as a special event in sl_event but is instead stored in 
sl_log_script and is processed as part of a SYNC event inline with data 
changes. DDL can also be specified inline

* FAILOVER has been reworked to be more reliable but not all nodes can 
be used as failover targets.

* A RESUBSCRIBE NODE command was added because the provider of a 
subscribed set can no longer be changed with the SUBSCRIBE SET command 
in some cases.  All sets from a particular origin must send data to 
receivers through the same path/forwarder nodes. This must remain  true 
during cluster reshaping.

Download
-------------
http://www.slony.info/downloads/2.2/source/slony1-2.2.0.b5.tar.bz2
http://www.slony.info/downloads/2.2/source/slony1-2.2.0.b5-docs.tar.bz2

Full release notes:
http://git.postgresql.org/gitweb/?p=slony1-engine.git;a=blob_plain;f=RELEASE;h=27db3f3295e0be60e0bacb34471ad302c49f252e;hb=refs/heads/master

